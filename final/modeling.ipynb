{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rootofdata/kostat_AI_contest/blob/main/%5BFinal%5D_modeling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwZgHJgDBdWd"
      },
      "source": [
        "# 256->512 ver. CNN-LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_UetIdNBdWq",
        "outputId": "1c18c913-1790-47ea-ec45-e3aa0e5c168d",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gensim in c:\\users\\seo\\anaconda3\\lib\\site-packages (4.1.2)\n",
            "Requirement already satisfied: Cython==0.29.23 in c:\\users\\seo\\anaconda3\\lib\\site-packages (from gensim) (0.29.23)\n",
            "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\seo\\anaconda3\\lib\\site-packages (from gensim) (1.5.2)\n",
            "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\seo\\anaconda3\\lib\\site-packages (from gensim) (1.22.3)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\seo\\anaconda3\\lib\\site-packages (from gensim) (5.2.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yDTA2wLCkx1P"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IEEjEQugjjUt"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from gensim.models import word2vec\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rttwJXTfEFO3"
      },
      "source": [
        "# 함수 및 데이터 로드"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yw9wEXBymBYw"
      },
      "outputs": [],
      "source": [
        "def compute_pca(X: np.ndarray, n_components: int=2) -> np.ndarray:\n",
        "\n",
        "    X_demeaned = X - X.mean(axis=0)\n",
        "\n",
        "    # calculate the covariance matrix\n",
        "    covariance_matrix = np.cov(X_demeaned, rowvar=False)\n",
        "\n",
        "    # calculate eigenvectors & eigenvalues of the covariance matrix\n",
        "    eigen_vals, eigen_vecs = np.linalg.eigh(covariance_matrix)\n",
        "\n",
        "    # sort eigenvalue in increasing order (get the indices from the sort)\n",
        "    idx_sorted = np.argsort(eigen_vals)\n",
        "\n",
        "    # reverse the order so that it's from highest to lowest.\n",
        "    idx_sorted_decreasing = list(reversed(idx_sorted))\n",
        "\n",
        "    # sort the eigen values by idx_sorted_decreasing\n",
        "    eigen_vals_sorted = eigen_vals[idx_sorted_decreasing]\n",
        "\n",
        "    # sort eigenvectors using the idx_sorted_decreasing indices\n",
        "    eigen_vecs_sorted = eigen_vecs[:, idx_sorted_decreasing]\n",
        "\n",
        "    # select the first n eigenvectors (n is desired dimension\n",
        "    # of rescaled data array, or dims_rescaled_data)\n",
        "    # once again, make sure to get all the rows and only slice the columns\n",
        "    eigen_vecs_subset = eigen_vecs_sorted[:, :n_components]\n",
        "\n",
        "    # transform the data by multiplying the transpose of the eigenvectors \n",
        "    # with the transpose of the de-meaned data\n",
        "    # Then take the transpose of that product.\n",
        "    X_reduced = np.dot(eigen_vecs_subset.T, X_demeaned.T).T\n",
        "    return X_reduced"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Iky1oa5lx-Z"
      },
      "outputs": [],
      "source": [
        "def get_vector(word):\n",
        "    if word in word2vec_model:\n",
        "        return word2vec_model[word]\n",
        "    else:\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yJKQjm2ajufW"
      },
      "outputs": [],
      "source": [
        "word2vec_model = word2vec.Word2Vec.load('/content/drive/MyDrive/통계청_AI경진대회/final/data/train_final.model2')\n",
        "word2vec_model = word2vec_model.wv\n",
        "submission = pd.read_csv('/content/drive/MyDrive/통계청_AI경진대회/모델 개발용 자료/모델 개발용 자료.csv',header = 1)\n",
        "data = pd.read_csv('/content/drive/MyDrive/통계청_AI경진대회/실습용 자료/실습용 자료.csv',header = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F3EtSp-xkPwv"
      },
      "outputs": [],
      "source": [
        "train = []\n",
        "with open('/content/drive/MyDrive/통계청_AI경진대회/final/data/train_final2','rb') as f:\n",
        "    train = pickle.load(f)\n",
        "max_len = max(len(l) for l in train)\n",
        "\n",
        "test = []\n",
        "with open('/content/drive/MyDrive/통계청_AI경진대회/final/data/submission_final2','rb') as f:\n",
        "    test = pickle.load(f)\n",
        "max_len2 = max(len(l) for l in test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QxPgSvrtsX6g",
        "outputId": "26845bba-0b06-44cb-8041-8e487533efc9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1000495\n"
          ]
        }
      ],
      "source": [
        "print(len(train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DO8hH_K9kpfG",
        "outputId": "0a549131-d1cb-4c52-95b7-e9f001602b43"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(53, 49)"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "max_len, max_len2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4DYK3aq71Jf3"
      },
      "source": [
        "# embedding Matrix-> pca"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tcPlspsg1ML2",
        "outputId": "7655f9eb-88ad-4168-dd1d-7b1f7ebfab74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "단어 집합 : 37117\n"
          ]
        }
      ],
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(train[:-495])\n",
        "vocab_size = len(tokenizer.word_index) + 1 # 패딩을 고려하여 +1\n",
        "print('단어 집합 :',vocab_size)\n",
        "\n",
        "X_encoded = tokenizer.texts_to_sequences(train[:-495])\n",
        "#print('정수 인코딩 결과 :',X_encoded.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "sDvS3mD8BdXO",
        "outputId": "4ddd245e-9577-48f3-8f1d-97b9209745b9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>digit_3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>952</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>472</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>467</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>475</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>872</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999995</th>\n",
              "      <td>134</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999996</th>\n",
              "      <td>424</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999997</th>\n",
              "      <td>474</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999998</th>\n",
              "      <td>856</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999999</th>\n",
              "      <td>561</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000000 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        digit_3\n",
              "0           952\n",
              "1           472\n",
              "2           467\n",
              "3           475\n",
              "4           872\n",
              "...         ...\n",
              "999995      134\n",
              "999996      424\n",
              "999997      474\n",
              "999998      856\n",
              "999999      561\n",
              "\n",
              "[1000000 rows x 1 columns]"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a1=pd.DataFrame(data['digit_3'])\n",
        "y = a1\n",
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17oaLYan1VQ2",
        "outputId": "90524bb2-30c6-4de6-9782-fe55aa0440ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['101' '102' '103' '104' '105' '106' '107' '108' '11' '111' '112' '12'\n",
            " '120' '131' '132' '133' '134' '139' '14' '141' '142' '143' '144' '151'\n",
            " '152' '161' '162' '163' '171' '172' '179' '181' '182' '191' '192' '20'\n",
            " '201' '202' '203' '204' '205' '211' '212' '213' '221' '222' '231' '232'\n",
            " '233' '239' '241' '242' '243' '251' '252' '259' '261' '262' '263' '264'\n",
            " '265' '266' '271' '272' '273' '274' '281' '282' '283' '284' '285' '289'\n",
            " '291' '292' '301' '302' '303' '304' '31' '311' '312' '313' '319' '32'\n",
            " '320' '331' '332' '333' '334' '339' '340' '351' '352' '353' '360' '370'\n",
            " '381' '382' '383' '390' '411' '412' '421' '422' '423' '424' '425' '426'\n",
            " '451' '452' '453' '461' '462' '463' '464' '465' '466' '467' '468' '471'\n",
            " '472' '473' '474' '475' '476' '477' '478' '479' '491' '492' '493' '494'\n",
            " '495' '501' '502' '51' '511' '512' '521' '529' '551' '559' '561' '562'\n",
            " '581' '582' '591' '592' '601' '602' '61' '611' '612' '62' '620' '631'\n",
            " '639' '641' '642' '649' '651' '652' '653' '661' '662' '681' '682' '701'\n",
            " '702' '71' '711' '712' '713' '714' '715' '716' '72' '721' '729' '731'\n",
            " '732' '733' '739' '741' '742' '743' '751' '752' '753' '759' '761' '762'\n",
            " '763' '764' '80' '841' '842' '843' '844' '845' '851' '852' '853' '854'\n",
            " '855' '856' '857' '861' '862' '863' '869' '871' '872' '901' '902' '911'\n",
            " '912' '941' '942' '949' '951' '952' '953' '961' '969']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\SEO\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  return f(**kwargs)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "import tensorflow as tf\n",
        "\n",
        "y_train = y.astype(str)\n",
        "\n",
        "le = LabelEncoder()\n",
        "le.fit(y_train)\n",
        "print(le.classes_)\n",
        "labels = le.classes_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vOx8adfTBdXP",
        "outputId": "3c1ce4f0-63d2-4ca3-d2dc-896e65be5315"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['101' '102' '103' '104' '105' '106' '107' '108' '11' '111' '112' '12'\n",
            " '120' '131' '132' '133' '134' '139' '14' '141' '142' '143' '144' '151'\n",
            " '152' '161' '162' '163' '171' '172' '179' '181' '182' '191' '192' '20'\n",
            " '201' '202' '203' '204' '205' '211' '212' '213' '221' '222' '231' '232'\n",
            " '233' '239' '241' '242' '243' '251' '252' '259' '261' '262' '263' '264'\n",
            " '265' '266' '271' '272' '273' '274' '281' '282' '283' '284' '285' '289'\n",
            " '291' '292' '301' '302' '303' '304' '31' '311' '312' '313' '319' '32'\n",
            " '320' '331' '332' '333' '334' '339' '340' '351' '352' '353' '360' '370'\n",
            " '381' '382' '383' '390' '411' '412' '421' '422' '423' '424' '425' '426'\n",
            " '451' '452' '453' '461' '462' '463' '464' '465' '466' '467' '468' '471'\n",
            " '472' '473' '474' '475' '476' '477' '478' '479' '491' '492' '493' '494'\n",
            " '495' '501' '502' '51' '511' '512' '521' '529' '551' '559' '561' '562'\n",
            " '581' '582' '591' '592' '601' '602' '61' '611' '612' '62' '620' '631'\n",
            " '639' '641' '642' '649' '651' '652' '653' '661' '662' '681' '682' '701'\n",
            " '702' '71' '711' '712' '713' '714' '715' '716' '72' '721' '729' '731'\n",
            " '732' '733' '739' '741' '742' '743' '751' '752' '753' '759' '761' '762'\n",
            " '763' '764' '80' '841' '842' '843' '844' '845' '851' '852' '853' '854'\n",
            " '855' '856' '857' '861' '862' '863' '869' '871' '872' '901' '902' '911'\n",
            " '912' '941' '942' '949' '951' '952' '953' '961' '969']\n",
            "(1000000, 225)\n"
          ]
        }
      ],
      "source": [
        "print(labels)\n",
        "y_train = le.transform(y_train)\n",
        "y_train = tf.keras.utils.to_categorical(y_train)\n",
        "print(y_train.shape) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aRI2oQDI1acs",
        "outputId": "1586edd1-55fc-41ed-ac36-3209fb29f075"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "패딩 결과 :\n",
            "[[  92   18   87 ...    0    0    0]\n",
            " [1141  183  147 ...    0    0    0]\n",
            " [  38  462  331 ...    0    0    0]\n",
            " ...\n",
            " [  42   14    0 ...    0    0    0]\n",
            " [ 562    0    0 ...    0    0    0]\n",
            " [  30 1177    0 ...    0    0    0]]\n",
            "y_train numclass (1000000, 225)\n"
          ]
        }
      ],
      "source": [
        "X_train = pad_sequences(X_encoded, maxlen=max_len, padding='post')\n",
        "print('패딩 결과 :')\n",
        "print(X_train)\n",
        "print('y_train numclass',y_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "utvDwoI-1e9c",
        "outputId": "645b853d-c1a4-444a-bad4-89c5a1b97a00"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "임베딩 행렬의 크기(shape) : (37117, 100)\n"
          ]
        }
      ],
      "source": [
        "# numclass = data['digit_3'].nunique()\n",
        "\n",
        "embedding_matrix = np.zeros((vocab_size, 100))\n",
        "print('임베딩 행렬의 크기(shape) :',np.shape(embedding_matrix))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uXixGTMY1lSf"
      },
      "outputs": [],
      "source": [
        "for word, index in tokenizer.word_index.items():\n",
        "    # 단어와 맵핑되는 사전 훈련된 임베딩 벡터값\n",
        "    vector_value = get_vector(word)\n",
        "    if vector_value is not None:\n",
        "        embedding_matrix[index] = vector_value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zzq1n6r2BdXS"
      },
      "source": [
        "## PCA 100 -> 50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UOJExvCV1pdM"
      },
      "outputs": [],
      "source": [
        "X = embedding_matrix\n",
        "X_reduced = compute_pca(X, n_components=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ymJy12crBdXT"
      },
      "outputs": [],
      "source": [
        "y_train = y_train.astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICUNuko7BdXT",
        "outputId": "aee47e42-e0d3-44c1-e630-ce3039ed36c7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(37117, 50)"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_reduced.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CcSHf1vN2uuU"
      },
      "outputs": [],
      "source": [
        "del(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3teURNLKBdXU"
      },
      "source": [
        "# fine tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-rhG1VLTBdXU",
        "outputId": "1ced3a91-7ba8-4ab0-994a-b99774bda3e6",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: optuna in c:\\users\\seo\\anaconda3\\lib\\site-packages (2.10.0)\n",
            "Requirement already satisfied: scipy!=1.4.0 in c:\\users\\seo\\anaconda3\\lib\\site-packages (from optuna) (1.5.2)\n",
            "Requirement already satisfied: colorlog in c:\\users\\seo\\anaconda3\\lib\\site-packages (from optuna) (6.6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\seo\\anaconda3\\lib\\site-packages (from optuna) (20.4)\n",
            "Requirement already satisfied: PyYAML in c:\\users\\seo\\anaconda3\\lib\\site-packages (from optuna) (5.3.1)\n",
            "Requirement already satisfied: alembic in c:\\users\\seo\\anaconda3\\lib\\site-packages (from optuna) (1.7.7)\n",
            "Requirement already satisfied: tqdm in c:\\users\\seo\\anaconda3\\lib\\site-packages (from optuna) (4.50.2)\n",
            "Requirement already satisfied: numpy in c:\\users\\seo\\anaconda3\\lib\\site-packages (from optuna) (1.22.3)\n",
            "Requirement already satisfied: cliff in c:\\users\\seo\\anaconda3\\lib\\site-packages (from optuna) (3.10.1)\n",
            "Requirement already satisfied: sqlalchemy>=1.1.0 in c:\\users\\seo\\anaconda3\\lib\\site-packages (from optuna) (1.3.20)\n",
            "Requirement already satisfied: cmaes>=0.8.2 in c:\\users\\seo\\anaconda3\\lib\\site-packages (from optuna) (0.8.2)\n",
            "Requirement already satisfied: colorama; sys_platform == \"win32\" in c:\\users\\seo\\anaconda3\\lib\\site-packages (from colorlog->optuna) (0.4.4)\n",
            "Requirement already satisfied: six in c:\\users\\seo\\anaconda3\\lib\\site-packages (from packaging>=20.0->optuna) (1.15.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\seo\\anaconda3\\lib\\site-packages (from packaging>=20.0->optuna) (2.4.7)\n",
            "Requirement already satisfied: importlib-resources; python_version < \"3.9\" in c:\\users\\seo\\anaconda3\\lib\\site-packages (from alembic->optuna) (5.6.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.9\" in c:\\users\\seo\\anaconda3\\lib\\site-packages (from alembic->optuna) (4.11.3)\n",
            "Requirement already satisfied: Mako in c:\\users\\seo\\anaconda3\\lib\\site-packages (from alembic->optuna) (1.2.0)\n",
            "Requirement already satisfied: cmd2>=1.0.0 in c:\\users\\seo\\anaconda3\\lib\\site-packages (from cliff->optuna) (2.4.0)\n",
            "Requirement already satisfied: autopage>=0.4.0 in c:\\users\\seo\\anaconda3\\lib\\site-packages (from cliff->optuna) (0.5.0)\n",
            "Requirement already satisfied: stevedore>=2.0.1 in c:\\users\\seo\\anaconda3\\lib\\site-packages (from cliff->optuna) (3.5.0)\n",
            "Requirement already satisfied: pbr!=2.1.0,>=2.0.0 in c:\\users\\seo\\anaconda3\\lib\\site-packages (from cliff->optuna) (5.8.1)\n",
            "Requirement already satisfied: PrettyTable>=0.7.2 in c:\\users\\seo\\anaconda3\\lib\\site-packages (from cliff->optuna) (3.2.0)\n",
            "Requirement already satisfied: zipp>=3.1.0; python_version < \"3.10\" in c:\\users\\seo\\anaconda3\\lib\\site-packages (from importlib-resources; python_version < \"3.9\"->alembic->optuna) (3.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in c:\\users\\seo\\anaconda3\\lib\\site-packages (from Mako->alembic->optuna) (1.1.1)\n",
            "Requirement already satisfied: wcwidth>=0.1.7 in c:\\users\\seo\\anaconda3\\lib\\site-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n",
            "Requirement already satisfied: pyperclip>=1.6 in c:\\users\\seo\\anaconda3\\lib\\site-packages (from cmd2>=1.0.0->cliff->optuna) (1.8.2)\n",
            "Requirement already satisfied: pyreadline3; sys_platform == \"win32\" in c:\\users\\seo\\anaconda3\\lib\\site-packages (from cmd2>=1.0.0->cliff->optuna) (3.4.1)\n",
            "Requirement already satisfied: attrs>=16.3.0 in c:\\users\\seo\\anaconda3\\lib\\site-packages (from cmd2>=1.0.0->cliff->optuna) (20.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dAJ_I_fs1uFU"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Input, Activation, Dropout, LSTM, Dense,Conv1D,MaxPooling1D,Embedding,Flatten\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import utils\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "def build_cnn_lstm2(recurrent_dropout = 0.5,dropout=0.5,):\n",
        "    with tf.device('/gpu:0'):\n",
        "        model = Sequential()\n",
        "\n",
        "        model.add(Input(shape=(max_len,)))\n",
        "        e = Embedding(vocab_size,output_dim =50,  weights=[X_reduced], input_length=max_len, trainable=False)\n",
        "        model.add(e)\n",
        "\n",
        "        model.add(Conv1D(filters=64, kernel_size=3, padding='same', activation='relu'))\n",
        "        model.add(MaxPooling1D(pool_size=2))\n",
        "        model.add(Dropout(dropout))\n",
        "\n",
        "        model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
        "        model.add(MaxPooling1D(pool_size=2))\n",
        "\n",
        "        model.add(LSTM(256, recurrent_dropout=recurrent_dropout,activation='tanh',kernel_initializer=\"he_normal\",unroll=True,return_sequences=True))\n",
        "        model.add(Dropout(dropout))\n",
        "\n",
        "        model.add(LSTM(512, recurrent_dropout=recurrent_dropout,activation='tanh',kernel_initializer=\"he_normal\",unroll=True))\n",
        "        model.add(Dropout(dropout))\n",
        "\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(y_train.shape[1], activation='softmax'))\n",
        "        # adam = tf.keras.optimizers.Adam(learning_rate = 1e-5)\n",
        "        \n",
        "\n",
        "        return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9vigO9OrBdXW"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import StratifiedKFold , KFold\n",
        "is_holdout = False\n",
        "n_splits = 5\n",
        "cv = KFold(n_splits=n_splits, shuffle=True)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate = 8.382620250945622e-05)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "atDtX6uWvdBF",
        "outputId": "963ce96e-7452-44a2-c15e-285446581592",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Epoch 1/40\n",
            "7548/7548 [==============================] - 489s 64ms/step - loss: 1.7611 - accuracy: 0.5748 - val_loss: 0.9440 - val_accuracy: 0.7571\n",
            "Epoch 2/40\n",
            "7548/7548 [==============================] - 465s 62ms/step - loss: 1.1057 - accuracy: 0.7163 - val_loss: 0.7665 - val_accuracy: 0.7985\n",
            "Epoch 3/40\n",
            "7548/7548 [==============================] - 468s 62ms/step - loss: 0.9581 - accuracy: 0.7518 - val_loss: 0.6892 - val_accuracy: 0.8188\n",
            "Epoch 4/40\n",
            "7548/7548 [==============================] - 467s 62ms/step - loss: 0.8843 - accuracy: 0.7704 - val_loss: 0.6471 - val_accuracy: 0.8298\n",
            "Epoch 5/40\n",
            "7548/7548 [==============================] - 466s 62ms/step - loss: 0.8377 - accuracy: 0.7821 - val_loss: 0.6202 - val_accuracy: 0.8367\n",
            "Epoch 6/40\n",
            "7548/7548 [==============================] - 469s 62ms/step - loss: 0.8041 - accuracy: 0.7899 - val_loss: 0.6026 - val_accuracy: 0.8408\n",
            "Epoch 7/40\n",
            "7548/7548 [==============================] - 467s 62ms/step - loss: 0.7833 - accuracy: 0.7953 - val_loss: 0.5885 - val_accuracy: 0.8447\n",
            "Epoch 8/40\n",
            "7548/7548 [==============================] - 469s 62ms/step - loss: 0.7638 - accuracy: 0.8002 - val_loss: 0.5741 - val_accuracy: 0.8481\n",
            "Epoch 9/40\n",
            "7548/7548 [==============================] - 468s 62ms/step - loss: 0.7493 - accuracy: 0.8034 - val_loss: 0.5668 - val_accuracy: 0.8495\n",
            "Epoch 10/40\n",
            "7548/7548 [==============================] - 467s 62ms/step - loss: 0.7371 - accuracy: 0.8068 - val_loss: 0.5571 - val_accuracy: 0.8522\n",
            "Epoch 11/40\n",
            "7548/7548 [==============================] - 466s 62ms/step - loss: 0.7270 - accuracy: 0.8091 - val_loss: 0.5492 - val_accuracy: 0.8540\n",
            "Epoch 12/40\n",
            "7548/7548 [==============================] - 469s 62ms/step - loss: 0.7171 - accuracy: 0.8121 - val_loss: 0.5443 - val_accuracy: 0.8555\n",
            "Epoch 13/40\n",
            "7548/7548 [==============================] - 471s 62ms/step - loss: 0.7102 - accuracy: 0.8135 - val_loss: 0.5387 - val_accuracy: 0.8564\n",
            "Epoch 14/40\n",
            "7548/7548 [==============================] - 469s 62ms/step - loss: 0.7034 - accuracy: 0.8148 - val_loss: 0.5344 - val_accuracy: 0.8576\n",
            "Epoch 15/40\n",
            "7548/7548 [==============================] - 467s 62ms/step - loss: 0.6967 - accuracy: 0.8168 - val_loss: 0.5309 - val_accuracy: 0.8586\n",
            "Epoch 16/40\n",
            "7548/7548 [==============================] - 466s 62ms/step - loss: 0.6907 - accuracy: 0.8183 - val_loss: 0.5261 - val_accuracy: 0.8599\n",
            "Epoch 17/40\n",
            "7548/7548 [==============================] - 468s 62ms/step - loss: 0.6871 - accuracy: 0.8192 - val_loss: 0.5234 - val_accuracy: 0.8606\n",
            "Epoch 18/40\n",
            "7548/7548 [==============================] - 469s 62ms/step - loss: 0.6813 - accuracy: 0.8209 - val_loss: 0.5199 - val_accuracy: 0.8614\n",
            "Epoch 19/40\n",
            "7548/7548 [==============================] - 465s 62ms/step - loss: 0.6767 - accuracy: 0.8215 - val_loss: 0.5199 - val_accuracy: 0.8618\n",
            "Epoch 20/40\n",
            "7548/7548 [==============================] - 463s 61ms/step - loss: 0.6733 - accuracy: 0.8224 - val_loss: 0.5150 - val_accuracy: 0.8623\n",
            "Epoch 21/40\n",
            "7548/7548 [==============================] - 468s 62ms/step - loss: 0.6696 - accuracy: 0.8233 - val_loss: 0.5144 - val_accuracy: 0.8626\n",
            "Epoch 22/40\n",
            "7548/7548 [==============================] - 468s 62ms/step - loss: 0.6669 - accuracy: 0.8241 - val_loss: 0.5122 - val_accuracy: 0.8637\n",
            "Epoch 23/40\n",
            "7548/7548 [==============================] - 468s 62ms/step - loss: 0.6627 - accuracy: 0.8250 - val_loss: 0.5078 - val_accuracy: 0.8642\n",
            "Epoch 24/40\n",
            "7548/7548 [==============================] - 468s 62ms/step - loss: 0.6607 - accuracy: 0.8255 - val_loss: 0.5082 - val_accuracy: 0.8650\n",
            "Epoch 25/40\n",
            "7548/7548 [==============================] - 467s 62ms/step - loss: 0.6574 - accuracy: 0.8263 - val_loss: 0.5058 - val_accuracy: 0.8651\n",
            "Epoch 26/40\n",
            "7548/7548 [==============================] - 465s 62ms/step - loss: 0.6564 - accuracy: 0.8267 - val_loss: 0.5051 - val_accuracy: 0.8657\n",
            "Epoch 27/40\n",
            "7548/7548 [==============================] - 466s 62ms/step - loss: 0.6547 - accuracy: 0.8274 - val_loss: 0.5021 - val_accuracy: 0.8659\n",
            "Epoch 28/40\n",
            "7548/7548 [==============================] - 468s 62ms/step - loss: 0.6518 - accuracy: 0.8278 - val_loss: 0.5021 - val_accuracy: 0.8658\n",
            "Epoch 29/40\n",
            "7548/7548 [==============================] - 467s 62ms/step - loss: 0.6493 - accuracy: 0.8282 - val_loss: 0.5004 - val_accuracy: 0.8664\n",
            "Epoch 30/40\n",
            "7548/7548 [==============================] - 472s 63ms/step - loss: 0.6463 - accuracy: 0.8290 - val_loss: 0.4986 - val_accuracy: 0.8666\n",
            "Epoch 31/40\n",
            "7548/7548 [==============================] - 465s 62ms/step - loss: 0.6445 - accuracy: 0.8295 - val_loss: 0.4991 - val_accuracy: 0.8668\n",
            "Epoch 32/40\n",
            "7548/7548 [==============================] - 467s 62ms/step - loss: 0.6421 - accuracy: 0.8302 - val_loss: 0.4956 - val_accuracy: 0.8670\n",
            "Epoch 33/40\n",
            "7548/7548 [==============================] - 464s 62ms/step - loss: 0.6409 - accuracy: 0.8306 - val_loss: 0.4974 - val_accuracy: 0.8673\n",
            "Epoch 34/40\n",
            "7548/7548 [==============================] - 467s 62ms/step - loss: 0.6397 - accuracy: 0.8305 - val_loss: 0.4935 - val_accuracy: 0.8679\n",
            "Epoch 35/40\n",
            "7548/7548 [==============================] - 464s 61ms/step - loss: 0.6374 - accuracy: 0.8313 - val_loss: 0.4943 - val_accuracy: 0.8676\n",
            "Epoch 36/40\n",
            "7548/7548 [==============================] - 465s 62ms/step - loss: 0.6371 - accuracy: 0.8315 - val_loss: 0.4931 - val_accuracy: 0.8681\n",
            "Epoch 37/40\n",
            "7548/7548 [==============================] - 463s 61ms/step - loss: 0.6340 - accuracy: 0.8318 - val_loss: 0.4900 - val_accuracy: 0.8685\n",
            "Epoch 38/40\n",
            "7548/7548 [==============================] - 466s 62ms/step - loss: 0.6328 - accuracy: 0.8325 - val_loss: 0.4895 - val_accuracy: 0.8685\n",
            "Epoch 39/40\n",
            "7548/7548 [==============================] - 465s 62ms/step - loss: 0.6305 - accuracy: 0.8328 - val_loss: 0.4894 - val_accuracy: 0.8687\n",
            "Epoch 40/40\n",
            "7548/7548 [==============================] - 465s 62ms/step - loss: 0.6307 - accuracy: 0.8325 - val_loss: 0.4887 - val_accuracy: 0.8686\n",
            "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Epoch 1/40\n",
            "7548/7548 [==============================] - 477s 62ms/step - loss: 1.5933 - accuracy: 0.6034 - val_loss: 0.9418 - val_accuracy: 0.7567\n",
            "Epoch 2/40\n",
            "7548/7548 [==============================] - 467s 62ms/step - loss: 1.1046 - accuracy: 0.7154 - val_loss: 0.7687 - val_accuracy: 0.7994\n",
            "Epoch 3/40\n",
            "7548/7548 [==============================] - 466s 62ms/step - loss: 0.9596 - accuracy: 0.7509 - val_loss: 0.6898 - val_accuracy: 0.8195\n",
            "Epoch 4/40\n",
            "7548/7548 [==============================] - 464s 61ms/step - loss: 0.8829 - accuracy: 0.7697 - val_loss: 0.6507 - val_accuracy: 0.8302\n",
            "Epoch 5/40\n",
            "7548/7548 [==============================] - 459s 61ms/step - loss: 0.8369 - accuracy: 0.7816 - val_loss: 0.6216 - val_accuracy: 0.8368\n",
            "Epoch 6/40\n",
            "7548/7548 [==============================] - 468s 62ms/step - loss: 0.8060 - accuracy: 0.7892 - val_loss: 0.6045 - val_accuracy: 0.8415\n",
            "Epoch 7/40\n",
            "7548/7548 [==============================] - 462s 61ms/step - loss: 0.7806 - accuracy: 0.7958 - val_loss: 0.5893 - val_accuracy: 0.8457\n",
            "Epoch 8/40\n",
            "7548/7548 [==============================] - 465s 62ms/step - loss: 0.7623 - accuracy: 0.7999 - val_loss: 0.5765 - val_accuracy: 0.8479\n",
            "Epoch 9/40\n",
            "7548/7548 [==============================] - 464s 61ms/step - loss: 0.7473 - accuracy: 0.8038 - val_loss: 0.5684 - val_accuracy: 0.8508\n",
            "Epoch 10/40\n",
            "7548/7548 [==============================] - 466s 62ms/step - loss: 0.7361 - accuracy: 0.8066 - val_loss: 0.5592 - val_accuracy: 0.8526\n",
            "Epoch 11/40\n",
            "7548/7548 [==============================] - 461s 61ms/step - loss: 0.7258 - accuracy: 0.8092 - val_loss: 0.5519 - val_accuracy: 0.8545\n",
            "Epoch 12/40\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7548/7548 [==============================] - 463s 61ms/step - loss: 0.7162 - accuracy: 0.8116 - val_loss: 0.5467 - val_accuracy: 0.8556\n",
            "Epoch 13/40\n",
            "7548/7548 [==============================] - 472s 63ms/step - loss: 0.7099 - accuracy: 0.8135 - val_loss: 0.5421 - val_accuracy: 0.8577\n",
            "Epoch 14/40\n",
            "7548/7548 [==============================] - 471s 62ms/step - loss: 0.7026 - accuracy: 0.8146 - val_loss: 0.5377 - val_accuracy: 0.8591\n",
            "Epoch 15/40\n",
            "7548/7548 [==============================] - 468s 62ms/step - loss: 0.6969 - accuracy: 0.8165 - val_loss: 0.5345 - val_accuracy: 0.8594\n",
            "Epoch 16/40\n",
            "7548/7548 [==============================] - 480s 64ms/step - loss: 0.6916 - accuracy: 0.8177 - val_loss: 0.5326 - val_accuracy: 0.8606\n",
            "Epoch 17/40\n",
            "7548/7548 [==============================] - 479s 63ms/step - loss: 0.6854 - accuracy: 0.8194 - val_loss: 0.5279 - val_accuracy: 0.8613\n",
            "Epoch 18/40\n",
            "7548/7548 [==============================] - 478s 63ms/step - loss: 0.6819 - accuracy: 0.8201 - val_loss: 0.5239 - val_accuracy: 0.8622\n",
            "Epoch 19/40\n",
            "7548/7548 [==============================] - 475s 63ms/step - loss: 0.6775 - accuracy: 0.8215 - val_loss: 0.5224 - val_accuracy: 0.8625\n",
            "Epoch 20/40\n",
            "7548/7548 [==============================] - 480s 64ms/step - loss: 0.6723 - accuracy: 0.8227 - val_loss: 0.5206 - val_accuracy: 0.8629\n",
            "Epoch 21/40\n",
            "7548/7548 [==============================] - 476s 63ms/step - loss: 0.6689 - accuracy: 0.8231 - val_loss: 0.5154 - val_accuracy: 0.8641\n",
            "Epoch 22/40\n",
            "7548/7548 [==============================] - 480s 64ms/step - loss: 0.6674 - accuracy: 0.8238 - val_loss: 0.5146 - val_accuracy: 0.8637\n",
            "Epoch 23/40\n",
            "7548/7548 [==============================] - 480s 64ms/step - loss: 0.6646 - accuracy: 0.8244 - val_loss: 0.5125 - val_accuracy: 0.8646\n",
            "Epoch 24/40\n",
            "7548/7548 [==============================] - 478s 63ms/step - loss: 0.6610 - accuracy: 0.8258 - val_loss: 0.5098 - val_accuracy: 0.8654\n",
            "Epoch 25/40\n",
            "7548/7548 [==============================] - 477s 63ms/step - loss: 0.6573 - accuracy: 0.8264 - val_loss: 0.5091 - val_accuracy: 0.8661\n",
            "Epoch 26/40\n",
            "7548/7548 [==============================] - 480s 64ms/step - loss: 0.6555 - accuracy: 0.8266 - val_loss: 0.5065 - val_accuracy: 0.8664\n",
            "Epoch 27/40\n",
            "7548/7548 [==============================] - 478s 63ms/step - loss: 0.6531 - accuracy: 0.8275 - val_loss: 0.5063 - val_accuracy: 0.8669\n",
            "Epoch 28/40\n",
            "7548/7548 [==============================] - 477s 63ms/step - loss: 0.6505 - accuracy: 0.8280 - val_loss: 0.5020 - val_accuracy: 0.8669\n",
            "Epoch 29/40\n",
            "7548/7548 [==============================] - 478s 63ms/step - loss: 0.6480 - accuracy: 0.8286 - val_loss: 0.5018 - val_accuracy: 0.8679\n",
            "Epoch 30/40\n",
            "7548/7548 [==============================] - 484s 64ms/step - loss: 0.6471 - accuracy: 0.8286 - val_loss: 0.5013 - val_accuracy: 0.8670\n",
            "Epoch 31/40\n",
            "7548/7548 [==============================] - 480s 64ms/step - loss: 0.6438 - accuracy: 0.8296 - val_loss: 0.4985 - val_accuracy: 0.8677\n",
            "Epoch 32/40\n",
            "7548/7548 [==============================] - 478s 63ms/step - loss: 0.6417 - accuracy: 0.8300 - val_loss: 0.4980 - val_accuracy: 0.8682\n",
            "Epoch 33/40\n",
            "7548/7548 [==============================] - 472s 62ms/step - loss: 0.6403 - accuracy: 0.8304 - val_loss: 0.4978 - val_accuracy: 0.8685\n",
            "Epoch 34/40\n",
            "7548/7548 [==============================] - 477s 63ms/step - loss: 0.6381 - accuracy: 0.8308 - val_loss: 0.4977 - val_accuracy: 0.8682\n",
            "Epoch 35/40\n",
            "7548/7548 [==============================] - 472s 63ms/step - loss: 0.6372 - accuracy: 0.8315 - val_loss: 0.4960 - val_accuracy: 0.8693\n",
            "Epoch 36/40\n",
            "7548/7548 [==============================] - 478s 63ms/step - loss: 0.6352 - accuracy: 0.8318 - val_loss: 0.4942 - val_accuracy: 0.8691\n",
            "Epoch 37/40\n",
            "7548/7548 [==============================] - 477s 63ms/step - loss: 0.6328 - accuracy: 0.8325 - val_loss: 0.4929 - val_accuracy: 0.8697\n",
            "Epoch 38/40\n",
            "7548/7548 [==============================] - 473s 63ms/step - loss: 0.6326 - accuracy: 0.8327 - val_loss: 0.4922 - val_accuracy: 0.8700\n",
            "Epoch 39/40\n",
            "7548/7548 [==============================] - 477s 63ms/step - loss: 0.6302 - accuracy: 0.8331 - val_loss: 0.4921 - val_accuracy: 0.8700\n",
            "Epoch 40/40\n",
            "7548/7548 [==============================] - 475s 63ms/step - loss: 0.6289 - accuracy: 0.8334 - val_loss: 0.4899 - val_accuracy: 0.8696\n",
            "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Epoch 1/40\n",
            "7548/7548 [==============================] - 478s 62ms/step - loss: 1.5765 - accuracy: 0.6096 - val_loss: 0.8979 - val_accuracy: 0.7648\n",
            "Epoch 2/40\n",
            "7548/7548 [==============================] - 473s 63ms/step - loss: 1.0780 - accuracy: 0.7213 - val_loss: 0.7504 - val_accuracy: 0.8005\n",
            "Epoch 3/40\n",
            "7548/7548 [==============================] - 474s 63ms/step - loss: 0.9427 - accuracy: 0.7547 - val_loss: 0.6814 - val_accuracy: 0.8197\n",
            "Epoch 4/40\n",
            "7548/7548 [==============================] - 475s 63ms/step - loss: 0.8740 - accuracy: 0.7718 - val_loss: 0.6442 - val_accuracy: 0.8288\n",
            "Epoch 5/40\n",
            "7548/7548 [==============================] - 470s 62ms/step - loss: 0.8321 - accuracy: 0.7825 - val_loss: 0.6219 - val_accuracy: 0.8360\n",
            "Epoch 6/40\n",
            "7548/7548 [==============================] - 471s 62ms/step - loss: 0.8020 - accuracy: 0.7898 - val_loss: 0.6014 - val_accuracy: 0.8404\n",
            "Epoch 7/40\n",
            "7548/7548 [==============================] - 475s 63ms/step - loss: 0.7801 - accuracy: 0.7954 - val_loss: 0.5899 - val_accuracy: 0.8437\n",
            "Epoch 8/40\n",
            "7548/7548 [==============================] - 470s 62ms/step - loss: 0.7631 - accuracy: 0.7998 - val_loss: 0.5759 - val_accuracy: 0.8469\n",
            "Epoch 9/40\n",
            "7548/7548 [==============================] - 472s 62ms/step - loss: 0.7488 - accuracy: 0.8032 - val_loss: 0.5707 - val_accuracy: 0.8496\n",
            "Epoch 10/40\n",
            "7548/7548 [==============================] - 469s 62ms/step - loss: 0.7365 - accuracy: 0.8068 - val_loss: 0.5604 - val_accuracy: 0.8515\n",
            "Epoch 11/40\n",
            "7548/7548 [==============================] - 469s 62ms/step - loss: 0.7285 - accuracy: 0.8088 - val_loss: 0.5526 - val_accuracy: 0.8539\n",
            "Epoch 12/40\n",
            "7548/7548 [==============================] - 467s 62ms/step - loss: 0.7184 - accuracy: 0.8108 - val_loss: 0.5490 - val_accuracy: 0.8552\n",
            "Epoch 13/40\n",
            "7548/7548 [==============================] - 469s 62ms/step - loss: 0.7108 - accuracy: 0.8129 - val_loss: 0.5416 - val_accuracy: 0.8565\n",
            "Epoch 14/40\n",
            "7548/7548 [==============================] - 472s 63ms/step - loss: 0.7047 - accuracy: 0.8148 - val_loss: 0.5401 - val_accuracy: 0.8568\n",
            "Epoch 15/40\n",
            "7548/7548 [==============================] - 466s 62ms/step - loss: 0.6971 - accuracy: 0.8165 - val_loss: 0.5347 - val_accuracy: 0.8585\n",
            "Epoch 16/40\n",
            "7548/7548 [==============================] - 473s 63ms/step - loss: 0.6935 - accuracy: 0.8178 - val_loss: 0.5316 - val_accuracy: 0.8595\n",
            "Epoch 17/40\n",
            "7548/7548 [==============================] - 469s 62ms/step - loss: 0.6870 - accuracy: 0.8187 - val_loss: 0.5274 - val_accuracy: 0.8606\n",
            "Epoch 18/40\n",
            "7548/7548 [==============================] - 473s 63ms/step - loss: 0.6828 - accuracy: 0.8204 - val_loss: 0.5241 - val_accuracy: 0.8611\n",
            "Epoch 19/40\n",
            "7548/7548 [==============================] - 493s 65ms/step - loss: 0.6793 - accuracy: 0.8209 - val_loss: 0.5206 - val_accuracy: 0.8616\n",
            "Epoch 20/40\n",
            "7548/7548 [==============================] - 486s 64ms/step - loss: 0.6754 - accuracy: 0.8215 - val_loss: 0.5201 - val_accuracy: 0.8619\n",
            "Epoch 21/40\n",
            "7548/7548 [==============================] - 478s 63ms/step - loss: 0.6713 - accuracy: 0.8230 - val_loss: 0.5156 - val_accuracy: 0.8630\n",
            "Epoch 22/40\n",
            "7548/7548 [==============================] - 489s 65ms/step - loss: 0.6679 - accuracy: 0.8238 - val_loss: 0.5163 - val_accuracy: 0.8630\n",
            "Epoch 23/40\n",
            "7548/7548 [==============================] - 503s 67ms/step - loss: 0.6662 - accuracy: 0.8242 - val_loss: 0.5126 - val_accuracy: 0.8638\n",
            "Epoch 24/40\n",
            "7548/7548 [==============================] - 864s 114ms/step - loss: 0.6626 - accuracy: 0.8250 - val_loss: 0.5092 - val_accuracy: 0.8645\n",
            "Epoch 25/40\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7548/7548 [==============================] - 478s 63ms/step - loss: 0.6601 - accuracy: 0.8257 - val_loss: 0.5084 - val_accuracy: 0.8649\n",
            "Epoch 26/40\n",
            "7548/7548 [==============================] - 471s 62ms/step - loss: 0.6574 - accuracy: 0.8264 - val_loss: 0.5068 - val_accuracy: 0.8648\n",
            "Epoch 27/40\n",
            "7548/7548 [==============================] - 474s 63ms/step - loss: 0.6553 - accuracy: 0.8266 - val_loss: 0.5054 - val_accuracy: 0.8653\n",
            "Epoch 28/40\n",
            "7548/7548 [==============================] - 513s 68ms/step - loss: 0.6526 - accuracy: 0.8273 - val_loss: 0.5062 - val_accuracy: 0.8658\n",
            "Epoch 29/40\n",
            "7548/7548 [==============================] - 475s 63ms/step - loss: 0.6508 - accuracy: 0.8285 - val_loss: 0.5025 - val_accuracy: 0.8663\n",
            "Epoch 30/40\n",
            "7548/7548 [==============================] - 481s 64ms/step - loss: 0.6494 - accuracy: 0.8283 - val_loss: 0.5024 - val_accuracy: 0.8667\n",
            "Epoch 31/40\n",
            "7548/7548 [==============================] - 487s 65ms/step - loss: 0.6470 - accuracy: 0.8286 - val_loss: 0.5014 - val_accuracy: 0.8663\n",
            "Epoch 32/40\n",
            "7548/7548 [==============================] - 478s 63ms/step - loss: 0.6459 - accuracy: 0.8296 - val_loss: 0.5002 - val_accuracy: 0.8673\n",
            "Epoch 33/40\n",
            "7548/7548 [==============================] - 475s 63ms/step - loss: 0.6430 - accuracy: 0.8299 - val_loss: 0.5019 - val_accuracy: 0.8665\n",
            "Epoch 34/40\n",
            "7548/7548 [==============================] - 475s 63ms/step - loss: 0.6422 - accuracy: 0.8300 - val_loss: 0.4976 - val_accuracy: 0.8674\n",
            "Epoch 35/40\n",
            "7548/7548 [==============================] - 473s 63ms/step - loss: 0.6396 - accuracy: 0.8305 - val_loss: 0.4972 - val_accuracy: 0.8673\n",
            "Epoch 36/40\n",
            "7548/7548 [==============================] - 473s 63ms/step - loss: 0.6380 - accuracy: 0.8313 - val_loss: 0.4941 - val_accuracy: 0.8684\n",
            "Epoch 37/40\n",
            "7548/7548 [==============================] - 478s 63ms/step - loss: 0.6374 - accuracy: 0.8314 - val_loss: 0.4954 - val_accuracy: 0.8678\n",
            "Epoch 38/40\n",
            "7548/7548 [==============================] - 473s 63ms/step - loss: 0.6350 - accuracy: 0.8318 - val_loss: 0.4936 - val_accuracy: 0.8681\n",
            "Epoch 39/40\n",
            "7548/7548 [==============================] - 477s 63ms/step - loss: 0.6343 - accuracy: 0.8318 - val_loss: 0.4933 - val_accuracy: 0.8688\n",
            "Epoch 40/40\n",
            "7548/7548 [==============================] - 479s 64ms/step - loss: 0.6338 - accuracy: 0.8324 - val_loss: 0.4922 - val_accuracy: 0.8692\n",
            "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Epoch 1/40\n",
            "7548/7548 [==============================] - 487s 63ms/step - loss: 1.6075 - accuracy: 0.5977 - val_loss: 0.9181 - val_accuracy: 0.7619\n",
            "Epoch 2/40\n",
            "7548/7548 [==============================] - 478s 63ms/step - loss: 1.0902 - accuracy: 0.7174 - val_loss: 0.7583 - val_accuracy: 0.7991\n",
            "Epoch 3/40\n",
            "7548/7548 [==============================] - 483s 64ms/step - loss: 0.9504 - accuracy: 0.7524 - val_loss: 0.6840 - val_accuracy: 0.8188\n",
            "Epoch 4/40\n",
            "7548/7548 [==============================] - 482s 64ms/step - loss: 0.8765 - accuracy: 0.7702 - val_loss: 0.6450 - val_accuracy: 0.8287\n",
            "Epoch 5/40\n",
            "7548/7548 [==============================] - 482s 64ms/step - loss: 0.8303 - accuracy: 0.7824 - val_loss: 0.6209 - val_accuracy: 0.8358\n",
            "Epoch 6/40\n",
            "7548/7548 [==============================] - 479s 63ms/step - loss: 0.8007 - accuracy: 0.7902 - val_loss: 0.6019 - val_accuracy: 0.8408\n",
            "Epoch 7/40\n",
            "7548/7548 [==============================] - 477s 63ms/step - loss: 0.7773 - accuracy: 0.7959 - val_loss: 0.5846 - val_accuracy: 0.8457\n",
            "Epoch 8/40\n",
            "7548/7548 [==============================] - 475s 63ms/step - loss: 0.7580 - accuracy: 0.8005 - val_loss: 0.5750 - val_accuracy: 0.8485\n",
            "Epoch 9/40\n",
            "7548/7548 [==============================] - 473s 63ms/step - loss: 0.7448 - accuracy: 0.8037 - val_loss: 0.5647 - val_accuracy: 0.8516\n",
            "Epoch 10/40\n",
            "7548/7548 [==============================] - 481s 64ms/step - loss: 0.7338 - accuracy: 0.8069 - val_loss: 0.5608 - val_accuracy: 0.8518\n",
            "Epoch 11/40\n",
            "7548/7548 [==============================] - 478s 63ms/step - loss: 0.7222 - accuracy: 0.8101 - val_loss: 0.5526 - val_accuracy: 0.8537\n",
            "Epoch 12/40\n",
            "7548/7548 [==============================] - 473s 63ms/step - loss: 0.7156 - accuracy: 0.8111 - val_loss: 0.5472 - val_accuracy: 0.8558\n",
            "Epoch 13/40\n",
            "7548/7548 [==============================] - 478s 63ms/step - loss: 0.7057 - accuracy: 0.8135 - val_loss: 0.5419 - val_accuracy: 0.8562\n",
            "Epoch 14/40\n",
            "7548/7548 [==============================] - 479s 63ms/step - loss: 0.7017 - accuracy: 0.8152 - val_loss: 0.5381 - val_accuracy: 0.8577\n",
            "Epoch 15/40\n",
            "7548/7548 [==============================] - 476s 63ms/step - loss: 0.6935 - accuracy: 0.8176 - val_loss: 0.5345 - val_accuracy: 0.8591\n",
            "Epoch 16/40\n",
            "7548/7548 [==============================] - 476s 63ms/step - loss: 0.6883 - accuracy: 0.8187 - val_loss: 0.5320 - val_accuracy: 0.8599\n",
            "Epoch 17/40\n",
            "7548/7548 [==============================] - 476s 63ms/step - loss: 0.6841 - accuracy: 0.8196 - val_loss: 0.5263 - val_accuracy: 0.8603\n",
            "Epoch 18/40\n",
            "7548/7548 [==============================] - 475s 63ms/step - loss: 0.6795 - accuracy: 0.8208 - val_loss: 0.5236 - val_accuracy: 0.8614\n",
            "Epoch 19/40\n",
            "7548/7548 [==============================] - 480s 64ms/step - loss: 0.6766 - accuracy: 0.8216 - val_loss: 0.5211 - val_accuracy: 0.8622\n",
            "Epoch 20/40\n",
            "7548/7548 [==============================] - 494s 65ms/step - loss: 0.6705 - accuracy: 0.8229 - val_loss: 0.5196 - val_accuracy: 0.8621\n",
            "Epoch 21/40\n",
            "7548/7548 [==============================] - 491s 65ms/step - loss: 0.6693 - accuracy: 0.8230 - val_loss: 0.5171 - val_accuracy: 0.8629\n",
            "Epoch 22/40\n",
            "7548/7548 [==============================] - 481s 64ms/step - loss: 0.6641 - accuracy: 0.8242 - val_loss: 0.5171 - val_accuracy: 0.8629\n",
            "Epoch 23/40\n",
            "7548/7548 [==============================] - 479s 64ms/step - loss: 0.6631 - accuracy: 0.8250 - val_loss: 0.5145 - val_accuracy: 0.8641\n",
            "Epoch 24/40\n",
            "7548/7548 [==============================] - 478s 63ms/step - loss: 0.6595 - accuracy: 0.8257 - val_loss: 0.5115 - val_accuracy: 0.8636\n",
            "Epoch 25/40\n",
            "7548/7548 [==============================] - 477s 63ms/step - loss: 0.6568 - accuracy: 0.8264 - val_loss: 0.5100 - val_accuracy: 0.8650\n",
            "Epoch 26/40\n",
            "7548/7548 [==============================] - 480s 64ms/step - loss: 0.6533 - accuracy: 0.8272 - val_loss: 0.5075 - val_accuracy: 0.8648\n",
            "Epoch 27/40\n",
            "7548/7548 [==============================] - 478s 63ms/step - loss: 0.6513 - accuracy: 0.8274 - val_loss: 0.5070 - val_accuracy: 0.8656\n",
            "Epoch 28/40\n",
            "7548/7548 [==============================] - 485s 64ms/step - loss: 0.6510 - accuracy: 0.8278 - val_loss: 0.5045 - val_accuracy: 0.8656\n",
            "Epoch 29/40\n",
            "7548/7548 [==============================] - 481s 64ms/step - loss: 0.6458 - accuracy: 0.8293 - val_loss: 0.5069 - val_accuracy: 0.8659\n",
            "Epoch 30/40\n",
            "7548/7548 [==============================] - 481s 64ms/step - loss: 0.6457 - accuracy: 0.8295 - val_loss: 0.5028 - val_accuracy: 0.8667\n",
            "Epoch 31/40\n",
            "7548/7548 [==============================] - 483s 64ms/step - loss: 0.6435 - accuracy: 0.8292 - val_loss: 0.5003 - val_accuracy: 0.8672\n",
            "Epoch 32/40\n",
            "7548/7548 [==============================] - 486s 64ms/step - loss: 0.6414 - accuracy: 0.8302 - val_loss: 0.5001 - val_accuracy: 0.8674\n",
            "Epoch 33/40\n",
            "7548/7548 [==============================] - 479s 63ms/step - loss: 0.6391 - accuracy: 0.8305 - val_loss: 0.4998 - val_accuracy: 0.8674\n",
            "Epoch 34/40\n",
            "7548/7548 [==============================] - 492s 65ms/step - loss: 0.6382 - accuracy: 0.8306 - val_loss: 0.4977 - val_accuracy: 0.8676\n",
            "Epoch 35/40\n",
            "7548/7548 [==============================] - 497s 66ms/step - loss: 0.6369 - accuracy: 0.8313 - val_loss: 0.4961 - val_accuracy: 0.8678\n",
            "Epoch 36/40\n",
            "7548/7548 [==============================] - 499s 66ms/step - loss: 0.6352 - accuracy: 0.8322 - val_loss: 0.4969 - val_accuracy: 0.8683\n",
            "Epoch 37/40\n",
            "7548/7548 [==============================] - 501s 66ms/step - loss: 0.6331 - accuracy: 0.8324 - val_loss: 0.4935 - val_accuracy: 0.8685\n",
            "Epoch 38/40\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7548/7548 [==============================] - 498s 66ms/step - loss: 0.6314 - accuracy: 0.8326 - val_loss: 0.4954 - val_accuracy: 0.8683\n",
            "Epoch 39/40\n",
            "7548/7548 [==============================] - 501s 66ms/step - loss: 0.6302 - accuracy: 0.8332 - val_loss: 0.4946 - val_accuracy: 0.8682\n",
            "Epoch 40/40\n",
            "7548/7548 [==============================] - 501s 66ms/step - loss: 0.6288 - accuracy: 0.8333 - val_loss: 0.4914 - val_accuracy: 0.8688\n",
            "WARNING:tensorflow:Layer lstm_10 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_11 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Epoch 1/40\n",
            "7548/7548 [==============================] - 503s 66ms/step - loss: 1.5876 - accuracy: 0.6057 - val_loss: 0.9151 - val_accuracy: 0.7604\n",
            "Epoch 2/40\n",
            "7548/7548 [==============================] - 483s 64ms/step - loss: 1.0852 - accuracy: 0.7188 - val_loss: 0.7545 - val_accuracy: 0.8016\n",
            "Epoch 3/40\n",
            "7548/7548 [==============================] - 483s 64ms/step - loss: 0.9473 - accuracy: 0.7538 - val_loss: 0.6857 - val_accuracy: 0.8191\n",
            "Epoch 4/40\n",
            "7548/7548 [==============================] - 482s 64ms/step - loss: 0.8755 - accuracy: 0.7716 - val_loss: 0.6435 - val_accuracy: 0.8297\n",
            "Epoch 5/40\n",
            "7548/7548 [==============================] - 484s 64ms/step - loss: 0.8326 - accuracy: 0.7824 - val_loss: 0.6184 - val_accuracy: 0.8374\n",
            "Epoch 6/40\n",
            "7548/7548 [==============================] - 489s 65ms/step - loss: 0.8002 - accuracy: 0.7908 - val_loss: 0.5990 - val_accuracy: 0.8425\n",
            "Epoch 7/40\n",
            "7548/7548 [==============================] - 484s 64ms/step - loss: 0.7786 - accuracy: 0.7963 - val_loss: 0.5859 - val_accuracy: 0.8458\n",
            "Epoch 8/40\n",
            "7548/7548 [==============================] - 482s 64ms/step - loss: 0.7618 - accuracy: 0.8002 - val_loss: 0.5756 - val_accuracy: 0.8481\n",
            "Epoch 9/40\n",
            "7548/7548 [==============================] - 485s 64ms/step - loss: 0.7467 - accuracy: 0.8040 - val_loss: 0.5634 - val_accuracy: 0.8520\n",
            "Epoch 10/40\n",
            "7548/7548 [==============================] - 485s 64ms/step - loss: 0.7346 - accuracy: 0.8070 - val_loss: 0.5597 - val_accuracy: 0.8535\n",
            "Epoch 11/40\n",
            "7548/7548 [==============================] - 485s 64ms/step - loss: 0.7252 - accuracy: 0.8091 - val_loss: 0.5539 - val_accuracy: 0.8539\n",
            "Epoch 12/40\n",
            "7548/7548 [==============================] - 485s 64ms/step - loss: 0.7183 - accuracy: 0.8116 - val_loss: 0.5467 - val_accuracy: 0.8567\n",
            "Epoch 13/40\n",
            "7548/7548 [==============================] - 486s 64ms/step - loss: 0.7094 - accuracy: 0.8136 - val_loss: 0.5418 - val_accuracy: 0.8578\n",
            "Epoch 14/40\n",
            "7548/7548 [==============================] - 483s 64ms/step - loss: 0.7031 - accuracy: 0.8151 - val_loss: 0.5358 - val_accuracy: 0.8590\n",
            "Epoch 15/40\n",
            "7548/7548 [==============================] - 484s 64ms/step - loss: 0.6969 - accuracy: 0.8168 - val_loss: 0.5313 - val_accuracy: 0.8596\n",
            "Epoch 16/40\n",
            "7548/7548 [==============================] - 483s 64ms/step - loss: 0.6918 - accuracy: 0.8181 - val_loss: 0.5278 - val_accuracy: 0.8608\n",
            "Epoch 17/40\n",
            "7548/7548 [==============================] - 485s 64ms/step - loss: 0.6869 - accuracy: 0.8193 - val_loss: 0.5242 - val_accuracy: 0.8618\n",
            "Epoch 18/40\n",
            "7548/7548 [==============================] - 490s 65ms/step - loss: 0.6829 - accuracy: 0.8205 - val_loss: 0.5219 - val_accuracy: 0.8624\n",
            "Epoch 19/40\n",
            "7548/7548 [==============================] - 488s 65ms/step - loss: 0.6793 - accuracy: 0.8213 - val_loss: 0.5208 - val_accuracy: 0.8627\n",
            "Epoch 20/40\n",
            "7548/7548 [==============================] - 487s 64ms/step - loss: 0.6747 - accuracy: 0.8225 - val_loss: 0.5174 - val_accuracy: 0.8639\n",
            "Epoch 21/40\n",
            "7548/7548 [==============================] - 487s 65ms/step - loss: 0.6707 - accuracy: 0.8232 - val_loss: 0.5150 - val_accuracy: 0.8641\n",
            "Epoch 22/40\n",
            "7548/7548 [==============================] - 479s 63ms/step - loss: 0.6665 - accuracy: 0.8246 - val_loss: 0.5146 - val_accuracy: 0.8641\n",
            "Epoch 23/40\n",
            "7548/7548 [==============================] - 485s 64ms/step - loss: 0.6639 - accuracy: 0.8246 - val_loss: 0.5119 - val_accuracy: 0.8647\n",
            "Epoch 24/40\n",
            "7548/7548 [==============================] - 483s 64ms/step - loss: 0.6623 - accuracy: 0.8251 - val_loss: 0.5101 - val_accuracy: 0.8652\n",
            "Epoch 25/40\n",
            "7548/7548 [==============================] - 484s 64ms/step - loss: 0.6594 - accuracy: 0.8261 - val_loss: 0.5086 - val_accuracy: 0.8657\n",
            "Epoch 26/40\n",
            "7548/7548 [==============================] - 481s 64ms/step - loss: 0.6565 - accuracy: 0.8265 - val_loss: 0.5068 - val_accuracy: 0.8660\n",
            "Epoch 27/40\n",
            "7548/7548 [==============================] - 481s 64ms/step - loss: 0.6546 - accuracy: 0.8275 - val_loss: 0.5041 - val_accuracy: 0.8664\n",
            "Epoch 28/40\n",
            "7548/7548 [==============================] - 481s 64ms/step - loss: 0.6525 - accuracy: 0.8276 - val_loss: 0.5051 - val_accuracy: 0.8672\n",
            "Epoch 29/40\n",
            "7548/7548 [==============================] - 478s 63ms/step - loss: 0.6494 - accuracy: 0.8284 - val_loss: 0.5016 - val_accuracy: 0.8671\n",
            "Epoch 30/40\n",
            "7548/7548 [==============================] - 483s 64ms/step - loss: 0.6483 - accuracy: 0.8288 - val_loss: 0.4975 - val_accuracy: 0.8678\n",
            "Epoch 31/40\n",
            "7548/7548 [==============================] - 479s 63ms/step - loss: 0.6458 - accuracy: 0.8291 - val_loss: 0.4991 - val_accuracy: 0.8678\n",
            "Epoch 32/40\n",
            "7548/7548 [==============================] - 481s 64ms/step - loss: 0.6441 - accuracy: 0.8298 - val_loss: 0.4961 - val_accuracy: 0.8692\n",
            "Epoch 33/40\n",
            "7548/7548 [==============================] - 482s 64ms/step - loss: 0.6426 - accuracy: 0.8305 - val_loss: 0.4951 - val_accuracy: 0.8683\n",
            "Epoch 34/40\n",
            "7548/7548 [==============================] - 486s 64ms/step - loss: 0.6402 - accuracy: 0.8309 - val_loss: 0.4977 - val_accuracy: 0.8683\n",
            "Epoch 35/40\n",
            "7548/7548 [==============================] - 483s 64ms/step - loss: 0.6388 - accuracy: 0.8312 - val_loss: 0.4940 - val_accuracy: 0.8698\n",
            "Epoch 36/40\n",
            "7548/7548 [==============================] - 483s 64ms/step - loss: 0.6371 - accuracy: 0.8314 - val_loss: 0.4931 - val_accuracy: 0.8697\n",
            "Epoch 37/40\n",
            "7548/7548 [==============================] - 480s 64ms/step - loss: 0.6360 - accuracy: 0.8318 - val_loss: 0.4919 - val_accuracy: 0.8699\n",
            "Epoch 38/40\n",
            "7548/7548 [==============================] - 482s 64ms/step - loss: 0.6345 - accuracy: 0.8316 - val_loss: 0.4920 - val_accuracy: 0.8697\n",
            "Epoch 39/40\n",
            "7548/7548 [==============================] - 481s 64ms/step - loss: 0.6319 - accuracy: 0.8328 - val_loss: 0.4912 - val_accuracy: 0.8702\n",
            "Epoch 40/40\n",
            "7548/7548 [==============================] - 482s 64ms/step - loss: 0.6314 - accuracy: 0.8328 - val_loss: 0.4908 - val_accuracy: 0.8701\n"
          ]
        }
      ],
      "source": [
        "scores = []\n",
        "models = []\n",
        "\n",
        "for tri, vai in cv.split(X_train):\n",
        "    model = build_cnn_lstm2()\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "    callbacks = [EarlyStopping(monitor='val_loss', patience=5)]\n",
        "    history = model.fit(X_train[tri], y_train[tri],\n",
        "                        validation_data=(X_train[vai], y_train[vai]),\n",
        "                        epochs=40,callbacks=callbacks,\n",
        "                        batch_size = 106, verbose=1) \n",
        "    models.append(model)\n",
        "    scores.append(history.history[\"accuracy\"])\n",
        "    if is_holdout:\n",
        "        break    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iGUDLNXjSbXc"
      },
      "outputs": [],
      "source": [
        "from keras.models import load_model\n",
        "model.save('/content/drive/MyDrive/통계청_AI경진대회/final/data/mode_k_fold.h5')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QXejllFxBdXX",
        "outputId": "848e63eb-3a6c-47e3-c2db-d89fd557049b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_10 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_11 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
          ]
        }
      ],
      "source": [
        "model = load_model('/content/drive/MyDrive/통계청_AI경진대회/final/data/mode_k_fold.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B1OTv-ipxmNF",
        "outputId": "61bddde3-a811-40e4-bcef-31be19091f67"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.5748075246810913, 0.7162912487983704, 0.7518012523651123, 0.7704062461853027, 0.782057523727417, 0.7899324893951416, 0.7953137755393982, 0.800163745880127, 0.8033524751663208, 0.8068000078201294, 0.8091149926185608, 0.8121437430381775, 0.8135137557983398, 0.8148425221443176, 0.8168274760246277, 0.8182799816131592, 0.819186270236969, 0.8209025263786316, 0.821524977684021, 0.822380006313324, 0.8232662677764893, 0.8241337537765503, 0.8249874711036682, 0.8254975080490112, 0.826259970664978, 0.8266987204551697, 0.8273587226867676, 0.8278312683105469, 0.8282062411308289, 0.828983724117279, 0.8294699788093567, 0.8301874995231628, 0.8306487202644348, 0.8304637670516968, 0.831250011920929, 0.8314974904060364, 0.8317912220954895, 0.8325275182723999, 0.8328225016593933, 0.8325087428092957], [0.6033812761306763, 0.7153674960136414, 0.7509474754333496, 0.7697362303733826, 0.7816449999809265, 0.7892312407493591, 0.7958325147628784, 0.7998862266540527, 0.8037599921226501, 0.8065549731254578, 0.8092125058174133, 0.8116400241851807, 0.813548743724823, 0.8146200180053711, 0.8164862394332886, 0.8176637291908264, 0.8194112777709961, 0.82014000415802, 0.8215224742889404, 0.8227224946022034, 0.8230812549591064, 0.8237900137901306, 0.8243774771690369, 0.8257837295532227, 0.826411247253418, 0.8266187310218811, 0.8274725079536438, 0.8280487656593323, 0.8285650014877319, 0.8285675048828125, 0.8296225070953369, 0.8299612402915955, 0.830442488193512, 0.8308437466621399, 0.8315187692642212, 0.8318225145339966, 0.8324512243270874, 0.8326837420463562, 0.8331137299537659, 0.8333550095558167], [0.6096087694168091, 0.721262514591217, 0.7547374963760376, 0.7717762589454651, 0.7825462222099304, 0.7898275256156921, 0.7954275012016296, 0.7997962236404419, 0.8031799793243408, 0.8067899942398071, 0.8087599873542786, 0.8108149766921997, 0.8128862380981445, 0.8147575259208679, 0.8164912462234497, 0.8178112506866455, 0.8187100291252136, 0.82037752866745, 0.8208712339401245, 0.8214824795722961, 0.8229862451553345, 0.8237937688827515, 0.8241962790489197, 0.8249750137329102, 0.8257499933242798, 0.8263800144195557, 0.8266425132751465, 0.8273400068283081, 0.828461229801178, 0.8282837271690369, 0.8286012411117554, 0.829604983329773, 0.8299487233161926, 0.8300062417984009, 0.8304774761199951, 0.8312637209892273, 0.8313949704170227, 0.8317924737930298, 0.8318349719047546, 0.8324074745178223], [0.5976787209510803, 0.7173600196838379, 0.7523624897003174, 0.7701687216758728, 0.7824262380599976, 0.7901912331581116, 0.7958987355232239, 0.8004775047302246, 0.8036500215530396, 0.8068774938583374, 0.8101037740707397, 0.8111025094985962, 0.8134549856185913, 0.8151512742042542, 0.8175612688064575, 0.8186525106430054, 0.8195675015449524, 0.8207637667655945, 0.8216187357902527, 0.8229012489318848, 0.822967529296875, 0.824236273765564, 0.8250287771224976, 0.8257175087928772, 0.826411247253418, 0.8271937370300293, 0.8274162411689758, 0.8277712464332581, 0.8292700052261353, 0.8295199871063232, 0.8292112350463867, 0.8301912546157837, 0.8304687738418579, 0.8305937647819519, 0.8313199877738953, 0.8321574926376343, 0.8323712348937988, 0.8325987458229065, 0.8331787586212158, 0.833261251449585], [0.6057375073432922, 0.7188287377357483, 0.7537887692451477, 0.7715774774551392, 0.7824112772941589, 0.7908375263214111, 0.7962912321090698, 0.8001912236213684, 0.8040187358856201, 0.8069775104522705, 0.809133768081665, 0.811641275882721, 0.8136374950408936, 0.8151475191116333, 0.8167974948883057, 0.8180599808692932, 0.8193487524986267, 0.8204812407493591, 0.8212724924087524, 0.8224537372589111, 0.8231800198554993, 0.8246175050735474, 0.8246187567710876, 0.8250762224197388, 0.8260637521743774, 0.8264700174331665, 0.827507495880127, 0.8275612592697144, 0.8283525109291077, 0.8288074731826782, 0.829143762588501, 0.8298412561416626, 0.830481231212616, 0.8309312462806702, 0.8312249779701233, 0.8313800096511841, 0.8317775130271912, 0.8316400051116943, 0.8327537775039673, 0.8327637314796448]]\n",
            "0.8090180546045304\n"
          ]
        }
      ],
      "source": [
        "print(scores)\n",
        "print(np.mean(scores))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "txrAu1UIBdXX",
        "outputId": "0f0012c0-3a06-472c-b75e-238ddaaf23cc"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.title('Loss')\n",
        "plt.plot(history.history['loss'], label='train')\n",
        "plt.plot(history.history['val_loss'], label='test')\n",
        "plt.legend()\n",
        "plt.show();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s4UW3ItwBdXY",
        "outputId": "51aaf4a9-4612-45f7-bea9-698ba8d7be3c"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.title('Accuracy')\n",
        "plt.plot(history.history['accuracy'], label='train')\n",
        "plt.plot(history.history['val_accuracy'], label='test')\n",
        "plt.legend()\n",
        "plt.show();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xT6rjuLBdXY"
      },
      "source": [
        "# test padding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MM6L7bt8BdXZ"
      },
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(test)\n",
        "X_encoded = tokenizer.texts_to_sequences(test)\n",
        "#print('정수 인코딩 결과 :',X_encoded.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZBWWxnnQBdXZ"
      },
      "outputs": [],
      "source": [
        "X_test = pad_sequences(X_encoded, maxlen=max_len, padding='post')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AuZ7eWw4xhra"
      },
      "outputs": [],
      "source": [
        "pred_list =[]\n",
        "for i,(tri, vai) in enumerate(cv.split(X_train,y_train) ):\n",
        "    pred = models[i].predict(X_test)\n",
        "    pred_list.append(pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QRLaw3NR96eX",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "y_pred = np.mean(pred_list,axis=0)\n",
        "predicted = y_pred.argmax(axis=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "karvKIepBdXZ",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "digit_1_index = [1.0, 5.0, 10.0, 35.0, 36.0, 41.0, 45.0, 49.0, 55.0, 58.0, 64.0, 68.0, 70.0, 74.0, 84.0, 85.0, 86.0, 90.0, 94.0, 97.0, 99.0]\n",
        "digit_1_value = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M','N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U']\n",
        "\n",
        "dsa = [ i for i in range(100)]\n",
        "def search_digit_1(i):\n",
        "    ans = 0\n",
        "    if i <digit_1_index[1]:\n",
        "        ans = digit_1_value[0]\n",
        "    elif i <digit_1_index[2]:\n",
        "        ans=digit_1_value[1]\n",
        "    elif i <digit_1_index[3]:\n",
        "        ans=digit_1_value[2]\n",
        "\n",
        "    elif i <digit_1_index[4]:\n",
        "        ans=digit_1_value[3]\n",
        "    elif i <digit_1_index[5]:\n",
        "        ans=digit_1_value[4]\n",
        "\n",
        "    elif i <digit_1_index[6]:\n",
        "        ans=digit_1_value[5]\n",
        "    elif i <digit_1_index[7]:\n",
        "        ans=digit_1_value[6]\n",
        "\n",
        "    elif i <digit_1_index[8]:\n",
        "        ans=digit_1_value[7]\n",
        "    elif i <digit_1_index[9]:\n",
        "        ans=digit_1_value[8]\n",
        "    elif i <digit_1_index[10]:\n",
        "        ans=digit_1_value[9]\n",
        "    elif i <digit_1_index[11]:\n",
        "        ans=digit_1_value[10]\n",
        "    elif i <digit_1_index[12]:\n",
        "        ans=digit_1_value[11]\n",
        "\n",
        "    elif i <digit_1_index[13]:\n",
        "        ans=digit_1_value[12]\n",
        "    elif i <digit_1_index[14]:\n",
        "        ans=digit_1_value[13]\n",
        "\n",
        "    elif i <digit_1_index[15]:\n",
        "        ans=digit_1_value[14]\n",
        "    elif i <digit_1_index[16]:\n",
        "        ans=digit_1_value[15]\n",
        "\n",
        "    elif i <digit_1_index[17]:\n",
        "        ans=digit_1_value[16]\n",
        "    elif i <digit_1_index[18]:S\n",
        "        ans=digit_1_value[17]\n",
        "\n",
        "    elif i <digit_1_index[19]:\n",
        "        ans=digit_1_value[18]\n",
        "    elif i <digit_1_index[20]:\n",
        "        ans=digit_1_value[19]\n",
        "\n",
        "    else:\n",
        "        ans=digit_1_value[20]\n",
        "    return ans"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s4Ble0YSBdXa",
        "outputId": "face58cf-3a9d-4f77-e437-2ce4df8fce3b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-63-ab4b631f4e13>:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  submission['digit_3'][i] = int(labels[predicted[i]])\n",
            "<ipython-input-63-ab4b631f4e13>:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  submission['digit_2'][i] = int(labels[predicted[i]])//10\n",
            "<ipython-input-63-ab4b631f4e13>:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  submission['digit_1'][i] = search_digit_1(int(labels[predicted[i]])//10)\n",
            "C:\\Users\\SEO\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:670: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  iloc._setitem_with_indexer(indexer, value)\n",
            "<ipython-input-63-ab4b631f4e13>:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  submission['digit_3'][i] = int(labels[predicted[i]])\n",
            "<ipython-input-63-ab4b631f4e13>:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  submission['digit_2'][i] = int(labels[predicted[i]][0])\n",
            "<ipython-input-63-ab4b631f4e13>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  submission['digit_1'][i] = search_digit_1(int(labels[predicted[i]])//10)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>AI_id</th>\n",
              "      <th>digit_1</th>\n",
              "      <th>digit_2</th>\n",
              "      <th>digit_3</th>\n",
              "      <th>text_obj</th>\n",
              "      <th>text_mthd</th>\n",
              "      <th>text_deal</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>id_000001</td>\n",
              "      <td>S</td>\n",
              "      <td>96.0</td>\n",
              "      <td>961.0</td>\n",
              "      <td>치킨전문점에서</td>\n",
              "      <td>고객의주문에의해</td>\n",
              "      <td>치킨판매</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>id_000002</td>\n",
              "      <td>L</td>\n",
              "      <td>68.0</td>\n",
              "      <td>682.0</td>\n",
              "      <td>산업공구</td>\n",
              "      <td>다른 소매업자에게</td>\n",
              "      <td>철물 수공구</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>id_000003</td>\n",
              "      <td>S</td>\n",
              "      <td>96.0</td>\n",
              "      <td>969.0</td>\n",
              "      <td>절에서</td>\n",
              "      <td>신도을 대상으로</td>\n",
              "      <td>불교단체운영</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>id_000004</td>\n",
              "      <td>G</td>\n",
              "      <td>46.0</td>\n",
              "      <td>463.0</td>\n",
              "      <td>영업장에서</td>\n",
              "      <td>고객요구로</td>\n",
              "      <td>자동차튜닝</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>id_000005</td>\n",
              "      <td>I</td>\n",
              "      <td>56.0</td>\n",
              "      <td>561.0</td>\n",
              "      <td>실내포장마차에서</td>\n",
              "      <td>접객시설을 갖추고</td>\n",
              "      <td>소주,맥주제공</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99995</th>\n",
              "      <td>id_099996</td>\n",
              "      <td>C</td>\n",
              "      <td>28.0</td>\n",
              "      <td>284.0</td>\n",
              "      <td>사업장에서</td>\n",
              "      <td>일반인대상으로</td>\n",
              "      <td>버섯농장</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99996</th>\n",
              "      <td>id_099997</td>\n",
              "      <td>C</td>\n",
              "      <td>25.0</td>\n",
              "      <td>259.0</td>\n",
              "      <td>한의원에서</td>\n",
              "      <td>외래환자위주고</td>\n",
              "      <td>치료</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99997</th>\n",
              "      <td>id_099998</td>\n",
              "      <td>H</td>\n",
              "      <td>49.0</td>\n",
              "      <td>494.0</td>\n",
              "      <td>일반점포에서</td>\n",
              "      <td>소비자에게</td>\n",
              "      <td>그림판매</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99998</th>\n",
              "      <td>id_099999</td>\n",
              "      <td>I</td>\n",
              "      <td>56.0</td>\n",
              "      <td>561.0</td>\n",
              "      <td>사업장에서</td>\n",
              "      <td>일반인.학생대상으로</td>\n",
              "      <td>학습공간제공</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99999</th>\n",
              "      <td>id_100000</td>\n",
              "      <td>S</td>\n",
              "      <td>96.0</td>\n",
              "      <td>961.0</td>\n",
              "      <td>사업장에서</td>\n",
              "      <td>대리현대아파트를</td>\n",
              "      <td>관리</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100000 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           AI_id digit_1  digit_2  digit_3  text_obj   text_mthd text_deal\n",
              "0      id_000001       S     96.0    961.0   치킨전문점에서    고객의주문에의해      치킨판매\n",
              "1      id_000002       L     68.0    682.0      산업공구   다른 소매업자에게    철물 수공구\n",
              "2      id_000003       S     96.0    969.0       절에서    신도을 대상으로    불교단체운영\n",
              "3      id_000004       G     46.0    463.0     영업장에서       고객요구로     자동차튜닝\n",
              "4      id_000005       I     56.0    561.0  실내포장마차에서   접객시설을 갖추고   소주,맥주제공\n",
              "...          ...     ...      ...      ...       ...         ...       ...\n",
              "99995  id_099996       C     28.0    284.0     사업장에서     일반인대상으로      버섯농장\n",
              "99996  id_099997       C     25.0    259.0     한의원에서     외래환자위주고        치료\n",
              "99997  id_099998       H     49.0    494.0    일반점포에서       소비자에게      그림판매\n",
              "99998  id_099999       I     56.0    561.0     사업장에서  일반인.학생대상으로    학습공간제공\n",
              "99999  id_100000       S     96.0    961.0     사업장에서    대리현대아파트를        관리\n",
              "\n",
              "[100000 rows x 7 columns]"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "for i in range(len(predicted)):\n",
        "    if len(labels[predicted[i]]) == 2:\n",
        "        submission['digit_3'][i] = int(labels[predicted[i]])\n",
        "        submission['digit_2'][i] = int(labels[predicted[i]][0])\n",
        "        submission['digit_1'][i] = search_digit_1(int(labels[predicted[i]])//10)\n",
        "    submission['digit_3'][i] = int(labels[predicted[i]])\n",
        "    submission['digit_2'][i] = int(labels[predicted[i]])//10\n",
        "    submission['digit_1'][i] = search_digit_1(int(labels[predicted[i]])//10)\n",
        "submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Y-iGncEBdXb"
      },
      "outputs": [],
      "source": [
        "submission[['digit_2','digit_3']] = submission[['digit_2','digit_3']].astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-BIiuV3i-If4"
      },
      "outputs": [],
      "source": [
        "submission.to_csv('/content/drive/MyDrive/통계청_AI경진대회/final/data/sub1_optuna.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y_hQ9oNPBdXb",
        "outputId": "c5b5833c-b4b5-45d0-f757-6ece41e77c65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.utils import plot_model\n",
        "plot_model(model)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "[Final] modeling.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
