{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rootofdata/kostat_AI_contest/blob/main/pca_K_flod_version_(%ED%95%98%EC%9D%B4%ED%8D%BC%ED%8C%8C%EB%9D%BC%EB%AF%B8%ED%84%B0).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwZgHJgDBdWd"
      },
      "source": [
        "# 256->512 ver. CNN-LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_UetIdNBdWq",
        "outputId": "1c18c913-1790-47ea-ec45-e3aa0e5c168d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (3.6.0)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.15.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.4.1)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (5.2.1)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.21.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "BMYM8ptUBdWx",
        "outputId": "c4fbe8a5-466f-4f5a-dd52-2b98f792cd23"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.8.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "tf.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQnhqHjzBdW0",
        "outputId": "4b9d9e7f-1f6a-4e1e-c2ad-43e949db592a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From <ipython-input-3-db1e1abccb74>:3: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.config.list_physical_devices('GPU')` instead.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "device_lib.list_local_devices()\n",
        "tf.test.is_gpu_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JGNdUrmhBdW2",
        "outputId": "db738abe-9a10-45d3-a47a-8f42bbf0d0b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[name: \"/device:CPU:0\"\n",
            "device_type: \"CPU\"\n",
            "memory_limit: 268435456\n",
            "locality {\n",
            "}\n",
            "incarnation: 9002873150842966851\n",
            "xla_global_id: -1\n",
            ", name: \"/device:GPU:0\"\n",
            "device_type: \"GPU\"\n",
            "memory_limit: 11320098816\n",
            "locality {\n",
            "  bus_id: 1\n",
            "  links {\n",
            "  }\n",
            "}\n",
            "incarnation: 9608810868748248595\n",
            "physical_device_desc: \"device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7\"\n",
            "xla_global_id: 416903419\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "\n",
        "print(device_lib.list_local_devices())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yDTA2wLCkx1P"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IEEjEQugjjUt"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from gensim.models import word2vec\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rttwJXTfEFO3"
      },
      "source": [
        "# 함수 및 데이터 로드"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yw9wEXBymBYw"
      },
      "outputs": [],
      "source": [
        "def compute_pca(X: np.ndarray, n_components: int=2) -> np.ndarray:\n",
        "\n",
        "    X_demeaned = X - X.mean(axis=0)\n",
        "\n",
        "    # calculate the covariance matrix\n",
        "    covariance_matrix = np.cov(X_demeaned, rowvar=False)\n",
        "\n",
        "    # calculate eigenvectors & eigenvalues of the covariance matrix\n",
        "    eigen_vals, eigen_vecs = np.linalg.eigh(covariance_matrix)\n",
        "\n",
        "    # sort eigenvalue in increasing order (get the indices from the sort)\n",
        "    idx_sorted = np.argsort(eigen_vals)\n",
        "\n",
        "    # reverse the order so that it's from highest to lowest.\n",
        "    idx_sorted_decreasing = list(reversed(idx_sorted))\n",
        "\n",
        "    # sort the eigen values by idx_sorted_decreasing\n",
        "    eigen_vals_sorted = eigen_vals[idx_sorted_decreasing]\n",
        "\n",
        "    # sort eigenvectors using the idx_sorted_decreasing indices\n",
        "    eigen_vecs_sorted = eigen_vecs[:, idx_sorted_decreasing]\n",
        "\n",
        "    # select the first n eigenvectors (n is desired dimension\n",
        "    # of rescaled data array, or dims_rescaled_data)\n",
        "    # once again, make sure to get all the rows and only slice the columns\n",
        "    eigen_vecs_subset = eigen_vecs_sorted[:, :n_components]\n",
        "\n",
        "    # transform the data by multiplying the transpose of the eigenvectors \n",
        "    # with the transpose of the de-meaned data\n",
        "    # Then take the transpose of that product.\n",
        "    X_reduced = np.dot(eigen_vecs_subset.T, X_demeaned.T).T\n",
        "    return X_reduced"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Iky1oa5lx-Z"
      },
      "outputs": [],
      "source": [
        "def get_vector(word):\n",
        "    if word in word2vec_model:\n",
        "        return word2vec_model[word]\n",
        "    else:\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lctC7Hu3Bqgm",
        "outputId": "badd0ebd-3c7e-4d3e-c8dc-72c54c031396"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yJKQjm2ajufW"
      },
      "outputs": [],
      "source": [
        "word2vec_model = word2vec.Word2Vec.load('/content/drive/MyDrive/통계청_AI경진대회/final/data/train_final.model2')\n",
        "word2vec_model = word2vec_model.wv\n",
        "submission = pd.read_csv('/content/drive/MyDrive/통계청_AI경진대회/모델 개발용 자료/모델 개발용 자료.csv',header = 1)\n",
        "data = pd.read_csv('/content/drive/MyDrive/통계청_AI경진대회/실습용 자료/실습용 자료.csv',header = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F3EtSp-xkPwv"
      },
      "outputs": [],
      "source": [
        "train = []\n",
        "with open('/content/drive/MyDrive/통계청_AI경진대회/final/data/train_final2','rb') as f:\n",
        "    train = pickle.load(f)\n",
        "max_len = max(len(l) for l in train)\n",
        "\n",
        "test = []\n",
        "with open('/content/drive/MyDrive/통계청_AI경진대회/final/data/submission_final2','rb') as f:\n",
        "    test = pickle.load(f)\n",
        "max_len2 = max(len(l) for l in test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QxPgSvrtsX6g",
        "outputId": "26845bba-0b06-44cb-8041-8e487533efc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1000495\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DO8hH_K9kpfG",
        "outputId": "0a549131-d1cb-4c52-95b7-e9f001602b43"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(53, 49)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "max_len, max_len2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4DYK3aq71Jf3"
      },
      "source": [
        "# embedding Matrix-> pca"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tcPlspsg1ML2",
        "outputId": "7655f9eb-88ad-4168-dd1d-7b1f7ebfab74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어 집합 : 37117\n"
          ]
        }
      ],
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(train[:-495])\n",
        "vocab_size = len(tokenizer.word_index) + 1 # 패딩을 고려하여 +1\n",
        "print('단어 집합 :',vocab_size)\n",
        "\n",
        "X_encoded = tokenizer.texts_to_sequences(train[:-495])\n",
        "#print('정수 인코딩 결과 :',X_encoded.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(X_encoded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tqDD0ZlfuZXB",
        "outputId": "a206bdc4-00e4-40a3-a7e1-30ad17fa80b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1000000"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fsi7FYE08iYM"
      },
      "outputs": [],
      "source": [
        "# 학습으로는 필요없고 워드투벡으로만 필요하다고 가정\n",
        "# import pickle\n",
        "# with open('/content/drive/MyDrive/통계청_AI경진대회/영석/a_495','rb') as f:\n",
        "#     a_495 = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del(train)"
      ],
      "metadata": {
        "id": "HbCNLc4K2RXo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "sDvS3mD8BdXO",
        "outputId": "4ddd245e-9577-48f3-8f1d-97b9209745b9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        digit_3\n",
              "0           952\n",
              "1           472\n",
              "2           467\n",
              "3           475\n",
              "4           872\n",
              "...         ...\n",
              "999995      134\n",
              "999996      424\n",
              "999997      474\n",
              "999998      856\n",
              "999999      561\n",
              "\n",
              "[1000000 rows x 1 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-de3c0b50-c9d8-4a80-a843-5f32dc2497d1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>digit_3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>952</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>472</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>467</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>475</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>872</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999995</th>\n",
              "      <td>134</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999996</th>\n",
              "      <td>424</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999997</th>\n",
              "      <td>474</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999998</th>\n",
              "      <td>856</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999999</th>\n",
              "      <td>561</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000000 rows × 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-de3c0b50-c9d8-4a80-a843-5f32dc2497d1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-de3c0b50-c9d8-4a80-a843-5f32dc2497d1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-de3c0b50-c9d8-4a80-a843-5f32dc2497d1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "a1=pd.DataFrame(data['digit_3'])\n",
        "y = a1\n",
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17oaLYan1VQ2",
        "outputId": "90524bb2-30c6-4de6-9782-fe55aa0440ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['101' '102' '103' '104' '105' '106' '107' '108' '11' '111' '112' '12'\n",
            " '120' '131' '132' '133' '134' '139' '14' '141' '142' '143' '144' '151'\n",
            " '152' '161' '162' '163' '171' '172' '179' '181' '182' '191' '192' '20'\n",
            " '201' '202' '203' '204' '205' '211' '212' '213' '221' '222' '231' '232'\n",
            " '233' '239' '241' '242' '243' '251' '252' '259' '261' '262' '263' '264'\n",
            " '265' '266' '271' '272' '273' '274' '281' '282' '283' '284' '285' '289'\n",
            " '291' '292' '301' '302' '303' '304' '31' '311' '312' '313' '319' '32'\n",
            " '320' '331' '332' '333' '334' '339' '340' '351' '352' '353' '360' '370'\n",
            " '381' '382' '383' '390' '411' '412' '421' '422' '423' '424' '425' '426'\n",
            " '451' '452' '453' '461' '462' '463' '464' '465' '466' '467' '468' '471'\n",
            " '472' '473' '474' '475' '476' '477' '478' '479' '491' '492' '493' '494'\n",
            " '495' '501' '502' '51' '511' '512' '521' '529' '551' '559' '561' '562'\n",
            " '581' '582' '591' '592' '601' '602' '61' '611' '612' '62' '620' '631'\n",
            " '639' '641' '642' '649' '651' '652' '653' '661' '662' '681' '682' '701'\n",
            " '702' '71' '711' '712' '713' '714' '715' '716' '72' '721' '729' '731'\n",
            " '732' '733' '739' '741' '742' '743' '751' '752' '753' '759' '761' '762'\n",
            " '763' '764' '80' '841' '842' '843' '844' '845' '851' '852' '853' '854'\n",
            " '855' '856' '857' '861' '862' '863' '869' '871' '872' '901' '902' '911'\n",
            " '912' '941' '942' '949' '951' '952' '953' '961' '969']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "import tensorflow as tf\n",
        "\n",
        "y_train = y.astype(str)\n",
        "\n",
        "le = LabelEncoder()\n",
        "le.fit(y_train)\n",
        "print(le.classes_)\n",
        "labels = le.classes_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vOx8adfTBdXP",
        "outputId": "3c1ce4f0-63d2-4ca3-d2dc-896e65be5315"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['101' '102' '103' '104' '105' '106' '107' '108' '11' '111' '112' '12'\n",
            " '120' '131' '132' '133' '134' '139' '14' '141' '142' '143' '144' '151'\n",
            " '152' '161' '162' '163' '171' '172' '179' '181' '182' '191' '192' '20'\n",
            " '201' '202' '203' '204' '205' '211' '212' '213' '221' '222' '231' '232'\n",
            " '233' '239' '241' '242' '243' '251' '252' '259' '261' '262' '263' '264'\n",
            " '265' '266' '271' '272' '273' '274' '281' '282' '283' '284' '285' '289'\n",
            " '291' '292' '301' '302' '303' '304' '31' '311' '312' '313' '319' '32'\n",
            " '320' '331' '332' '333' '334' '339' '340' '351' '352' '353' '360' '370'\n",
            " '381' '382' '383' '390' '411' '412' '421' '422' '423' '424' '425' '426'\n",
            " '451' '452' '453' '461' '462' '463' '464' '465' '466' '467' '468' '471'\n",
            " '472' '473' '474' '475' '476' '477' '478' '479' '491' '492' '493' '494'\n",
            " '495' '501' '502' '51' '511' '512' '521' '529' '551' '559' '561' '562'\n",
            " '581' '582' '591' '592' '601' '602' '61' '611' '612' '62' '620' '631'\n",
            " '639' '641' '642' '649' '651' '652' '653' '661' '662' '681' '682' '701'\n",
            " '702' '71' '711' '712' '713' '714' '715' '716' '72' '721' '729' '731'\n",
            " '732' '733' '739' '741' '742' '743' '751' '752' '753' '759' '761' '762'\n",
            " '763' '764' '80' '841' '842' '843' '844' '845' '851' '852' '853' '854'\n",
            " '855' '856' '857' '861' '862' '863' '869' '871' '872' '901' '902' '911'\n",
            " '912' '941' '942' '949' '951' '952' '953' '961' '969']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1000000, 225)\n"
          ]
        }
      ],
      "source": [
        "print(labels)\n",
        "y_train = le.transform(y_train)\n",
        "y_train = tf.keras.utils.to_categorical(y_train)\n",
        "print(y_train.shape) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aRI2oQDI1acs",
        "outputId": "1586edd1-55fc-41ed-ac36-3209fb29f075"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "패딩 결과 :\n",
            "[[  92   18   87 ...    0    0    0]\n",
            " [1141  183  147 ...    0    0    0]\n",
            " [  38  462  331 ...    0    0    0]\n",
            " ...\n",
            " [  42   14    0 ...    0    0    0]\n",
            " [ 562    0    0 ...    0    0    0]\n",
            " [  30 1177    0 ...    0    0    0]]\n",
            "y_train numclass (1000000, 225)\n"
          ]
        }
      ],
      "source": [
        "X_train = pad_sequences(X_encoded, maxlen=max_len, padding='post')\n",
        "print('패딩 결과 :')\n",
        "print(X_train)\n",
        "print('y_train numclass',y_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "utvDwoI-1e9c",
        "outputId": "645b853d-c1a4-444a-bad4-89c5a1b97a00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "임베딩 행렬의 크기(shape) : (37117, 100)\n"
          ]
        }
      ],
      "source": [
        "# numclass = data['digit_3'].nunique()\n",
        "\n",
        "embedding_matrix = np.zeros((vocab_size, 100))\n",
        "print('임베딩 행렬의 크기(shape) :',np.shape(embedding_matrix))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uXixGTMY1lSf"
      },
      "outputs": [],
      "source": [
        "for word, index in tokenizer.word_index.items():\n",
        "    # 단어와 맵핑되는 사전 훈련된 임베딩 벡터값\n",
        "    vector_value = get_vector(word)\n",
        "    if vector_value is not None:\n",
        "        embedding_matrix[index] = vector_value"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del(X_encoded)\n",
        "del(y)\n",
        "del(a1)"
      ],
      "metadata": {
        "id": "BZMJmzp22gNG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zzq1n6r2BdXS"
      },
      "source": [
        "## PCA 100 -> 50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UOJExvCV1pdM"
      },
      "outputs": [],
      "source": [
        "X = embedding_matrix\n",
        "X_reduced = compute_pca(X, n_components=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ymJy12crBdXT"
      },
      "outputs": [],
      "source": [
        "y_train = y_train.astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICUNuko7BdXT",
        "outputId": "aee47e42-e0d3-44c1-e630-ce3039ed36c7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(37117, 50)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "X_reduced.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del(X)"
      ],
      "metadata": {
        "id": "CcSHf1vN2uuU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3teURNLKBdXU"
      },
      "source": [
        "# fine tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-rhG1VLTBdXU",
        "outputId": "1ced3a91-7ba8-4ab0-994a-b99774bda3e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-2.10.0-py3-none-any.whl (308 kB)\n",
            "\u001b[?25l\r\u001b[K     |█                               | 10 kB 17.6 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 20 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 30 kB 9.0 MB/s eta 0:00:01\r\u001b[K     |████▎                           | 40 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 51 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 61 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 71 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 81 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 92 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 102 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 112 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 122 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 133 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 143 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 153 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 163 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 174 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 184 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 194 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 204 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 215 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 225 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 235 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 245 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 256 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 266 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 276 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 286 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 296 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 307 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 308 kB 5.2 MB/s \n",
            "\u001b[?25hCollecting colorlog\n",
            "  Downloading colorlog-6.6.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: scipy!=1.4.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from optuna) (1.21.5)\n",
            "Collecting cliff\n",
            "  Downloading cliff-3.10.1-py3-none-any.whl (81 kB)\n",
            "\u001b[K     |████████████████████████████████| 81 kB 9.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from optuna) (3.13)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (21.3)\n",
            "Collecting cmaes>=0.8.2\n",
            "  Downloading cmaes-0.8.2-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.32)\n",
            "Collecting alembic\n",
            "  Downloading alembic-1.7.7-py3-none-any.whl (210 kB)\n",
            "\u001b[K     |████████████████████████████████| 210 kB 45.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from optuna) (4.63.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->optuna) (3.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (1.1.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (4.11.3)\n",
            "Collecting Mako\n",
            "  Downloading Mako-1.2.0-py3-none-any.whl (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 6.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from alembic->optuna) (5.4.0)\n",
            "Collecting autopage>=0.4.0\n",
            "  Downloading autopage-0.5.0-py3-none-any.whl (29 kB)\n",
            "Collecting pbr!=2.1.0,>=2.0.0\n",
            "  Downloading pbr-5.8.1-py2.py3-none-any.whl (113 kB)\n",
            "\u001b[K     |████████████████████████████████| 113 kB 42.4 MB/s \n",
            "\u001b[?25hCollecting cmd2>=1.0.0\n",
            "  Downloading cmd2-2.4.0-py3-none-any.whl (150 kB)\n",
            "\u001b[K     |████████████████████████████████| 150 kB 45.1 MB/s \n",
            "\u001b[?25hCollecting stevedore>=2.0.1\n",
            "  Downloading stevedore-3.5.0-py3-none-any.whl (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 5.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (3.2.0)\n",
            "Collecting pyperclip>=1.6\n",
            "  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (21.4.0)\n",
            "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (3.10.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->sqlalchemy>=1.1.0->optuna) (3.7.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic->optuna) (2.0.1)\n",
            "Building wheels for collected packages: pyperclip\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11137 sha256=ec8141464b69aa3f162f186af632843f69bf8f53c5654e76eedac0b2b07987f5\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/18/84/8f69f8b08169c7bae2dde6bd7daf0c19fca8c8e500ee620a28\n",
            "Successfully built pyperclip\n",
            "Installing collected packages: pyperclip, pbr, stevedore, Mako, cmd2, autopage, colorlog, cmaes, cliff, alembic, optuna\n",
            "Successfully installed Mako-1.2.0 alembic-1.7.7 autopage-0.5.0 cliff-3.10.1 cmaes-0.8.2 cmd2-2.4.0 colorlog-6.6.0 optuna-2.10.0 pbr-5.8.1 pyperclip-1.8.2 stevedore-3.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dAJ_I_fs1uFU"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Input, Activation, Dropout, LSTM, Dense,Conv1D,MaxPooling1D,Embedding,Flatten\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import utils\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "def build_cnn_lstm2(recurrent_dropout = 0.5,dropout=0.5,):\n",
        "    with tf.device('/gpu:0'):\n",
        "        model = Sequential()\n",
        "\n",
        "        model.add(Input(shape=(max_len,)))\n",
        "        e = Embedding(vocab_size,output_dim =50,  weights=[X_reduced], input_length=max_len, trainable=False)\n",
        "        model.add(e)\n",
        "\n",
        "        model.add(Conv1D(filters=64, kernel_size=3, padding='same', activation='relu'))\n",
        "        model.add(MaxPooling1D(pool_size=2))\n",
        "        model.add(Dropout(dropout))\n",
        "\n",
        "        model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
        "        model.add(MaxPooling1D(pool_size=2))\n",
        "\n",
        "        model.add(LSTM(256, recurrent_dropout=recurrent_dropout,activation='tanh',kernel_initializer=\"he_normal\",unroll=True,return_sequences=True))\n",
        "        model.add(Dropout(dropout))\n",
        "\n",
        "        model.add(LSTM(512, recurrent_dropout=recurrent_dropout,activation='tanh',kernel_initializer=\"he_normal\",unroll=True))\n",
        "        model.add(Dropout(dropout))\n",
        "\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(y_train.shape[1], activation='softmax'))\n",
        "        # adam = tf.keras.optimizers.Adam(learning_rate = 1e-5)\n",
        "        \n",
        "\n",
        "        return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zEBQVkF6BdXV",
        "outputId": "7583a667-b833-4d78-814b-4d6f7f8b9ae1"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-04-10 15:24:23,621]\u001b[0m A new study created in memory with name: no-name-698317ee-26cd-45ba-80d3-c75f77b7afc4\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Epoch 1/40\n",
            "6041/6041 [==============================] - 470s 72ms/step - loss: 1.5325 - accuracy: 0.6328 - val_loss: 0.8945 - val_accuracy: 0.7724\n",
            "Epoch 2/40\n",
            "6041/6041 [==============================] - 429s 71ms/step - loss: 0.9242 - accuracy: 0.7601 - val_loss: 0.7474 - val_accuracy: 0.8059\n",
            "Epoch 3/40\n",
            "6041/6041 [==============================] - 427s 71ms/step - loss: 0.7979 - accuracy: 0.7906 - val_loss: 0.6767 - val_accuracy: 0.8229\n",
            "Epoch 4/40\n",
            "6041/6041 [==============================] - 428s 71ms/step - loss: 0.7282 - accuracy: 0.8081 - val_loss: 0.6341 - val_accuracy: 0.8333\n",
            "Epoch 5/40\n",
            "6041/6041 [==============================] - 428s 71ms/step - loss: 0.6824 - accuracy: 0.8195 - val_loss: 0.6044 - val_accuracy: 0.8393\n",
            "Epoch 6/40\n",
            "6041/6041 [==============================] - 427s 71ms/step - loss: 0.6519 - accuracy: 0.8269 - val_loss: 0.5821 - val_accuracy: 0.8449\n",
            "Epoch 7/40\n",
            "6041/6041 [==============================] - 427s 71ms/step - loss: 0.6261 - accuracy: 0.8334 - val_loss: 0.5668 - val_accuracy: 0.8490\n",
            "Epoch 8/40\n",
            "6041/6041 [==============================] - 427s 71ms/step - loss: 0.6082 - accuracy: 0.8378 - val_loss: 0.5533 - val_accuracy: 0.8530\n",
            "Epoch 9/40\n",
            "6041/6041 [==============================] - 427s 71ms/step - loss: 0.5919 - accuracy: 0.8417 - val_loss: 0.5410 - val_accuracy: 0.8557\n",
            "Epoch 10/40\n",
            "6041/6041 [==============================] - 427s 71ms/step - loss: 0.5796 - accuracy: 0.8448 - val_loss: 0.5344 - val_accuracy: 0.8570\n",
            "Epoch 11/40\n",
            "6041/6041 [==============================] - 427s 71ms/step - loss: 0.5680 - accuracy: 0.8473 - val_loss: 0.5259 - val_accuracy: 0.8599\n",
            "Epoch 12/40\n",
            "6041/6041 [==============================] - 428s 71ms/step - loss: 0.5582 - accuracy: 0.8503 - val_loss: 0.5211 - val_accuracy: 0.8608\n",
            "Epoch 13/40\n",
            "6041/6041 [==============================] - 427s 71ms/step - loss: 0.5504 - accuracy: 0.8518 - val_loss: 0.5140 - val_accuracy: 0.8621\n",
            "Epoch 14/40\n",
            "6041/6041 [==============================] - 428s 71ms/step - loss: 0.5432 - accuracy: 0.8538 - val_loss: 0.5095 - val_accuracy: 0.8633\n",
            "Epoch 15/40\n",
            "6041/6041 [==============================] - 426s 71ms/step - loss: 0.5365 - accuracy: 0.8551 - val_loss: 0.5051 - val_accuracy: 0.8643\n",
            "Epoch 16/40\n",
            "6041/6041 [==============================] - 428s 71ms/step - loss: 0.5307 - accuracy: 0.8568 - val_loss: 0.5006 - val_accuracy: 0.8664\n",
            "Epoch 17/40\n",
            "6041/6041 [==============================] - 428s 71ms/step - loss: 0.5254 - accuracy: 0.8582 - val_loss: 0.4972 - val_accuracy: 0.8664\n",
            "Epoch 18/40\n",
            "6041/6041 [==============================] - 428s 71ms/step - loss: 0.5211 - accuracy: 0.8590 - val_loss: 0.4943 - val_accuracy: 0.8675\n",
            "Epoch 19/40\n",
            "6041/6041 [==============================] - 432s 72ms/step - loss: 0.5164 - accuracy: 0.8603 - val_loss: 0.4909 - val_accuracy: 0.8683\n",
            "Epoch 20/40\n",
            "6041/6041 [==============================] - 434s 72ms/step - loss: 0.5116 - accuracy: 0.8613 - val_loss: 0.4878 - val_accuracy: 0.8686\n",
            "Epoch 21/40\n",
            "6041/6041 [==============================] - 434s 72ms/step - loss: 0.5067 - accuracy: 0.8624 - val_loss: 0.4861 - val_accuracy: 0.8695\n",
            "Epoch 22/40\n",
            "6041/6041 [==============================] - 434s 72ms/step - loss: 0.5037 - accuracy: 0.8631 - val_loss: 0.4845 - val_accuracy: 0.8692\n",
            "Epoch 23/40\n",
            "6041/6041 [==============================] - 434s 72ms/step - loss: 0.5000 - accuracy: 0.8642 - val_loss: 0.4824 - val_accuracy: 0.8701\n",
            "Epoch 24/40\n",
            "6041/6041 [==============================] - 435s 72ms/step - loss: 0.4970 - accuracy: 0.8648 - val_loss: 0.4825 - val_accuracy: 0.8699\n",
            "Epoch 25/40\n",
            "6041/6041 [==============================] - 433s 72ms/step - loss: 0.4942 - accuracy: 0.8652 - val_loss: 0.4795 - val_accuracy: 0.8710\n",
            "Epoch 26/40\n",
            "6041/6041 [==============================] - 434s 72ms/step - loss: 0.4906 - accuracy: 0.8660 - val_loss: 0.4785 - val_accuracy: 0.8707\n",
            "Epoch 27/40\n",
            "6041/6041 [==============================] - 434s 72ms/step - loss: 0.4884 - accuracy: 0.8666 - val_loss: 0.4759 - val_accuracy: 0.8720\n",
            "Epoch 28/40\n",
            "6041/6041 [==============================] - 435s 72ms/step - loss: 0.4859 - accuracy: 0.8672 - val_loss: 0.4746 - val_accuracy: 0.8723\n",
            "Epoch 29/40\n",
            "6041/6041 [==============================] - 434s 72ms/step - loss: 0.4826 - accuracy: 0.8677 - val_loss: 0.4746 - val_accuracy: 0.8724\n",
            "Epoch 30/40\n",
            "6041/6041 [==============================] - 434s 72ms/step - loss: 0.4801 - accuracy: 0.8688 - val_loss: 0.4730 - val_accuracy: 0.8724\n",
            "Epoch 31/40\n",
            "6041/6041 [==============================] - 433s 72ms/step - loss: 0.4790 - accuracy: 0.8685 - val_loss: 0.4708 - val_accuracy: 0.8735\n",
            "Epoch 32/40\n",
            "4445/6041 [=====================>........] - ETA: 1:46 - loss: 0.4760 - accuracy: 0.8698"
          ]
        }
      ],
      "source": [
        "import optuna\n",
        "from optuna.trial import TrialState\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "def objective(trial):\n",
        "    x_tri, X_val, y_tri, y_val = train_test_split(X_train,y_train, test_size=0.2, shuffle=False)\n",
        "    params = {\n",
        "    # 'optimizer_name' : trial.suggest_categorical(\"optimizer\", [\"Adam\",\"RMSprop\"]),\n",
        "    # 'epochs' : trial.suggest_int(\"epochs\", 30, 60,step=10),\n",
        "    # 'batchsize' : trial.suggest_int(\"batchsize\", max_len, 8*max_len,step=max_len),\n",
        "    'learning_rate' : trial.suggest_uniform('learning_rate',0.00001,0.0001),\n",
        "    'recurrent_dropout' : trial.suggest_float('recurrent_dropout',0.1,0.7,step=0.1),\n",
        "    'task_type' : 'GPU',\n",
        "    'dropout' : trial.suggest_float('dropout',0.1,0.7,step=0.1)\n",
        "    }\n",
        "    model = build_cnn_lstm2(params['recurrent_dropout'],params['dropout'])\n",
        "    \n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate = params['learning_rate'])\n",
        "\n",
        "    \n",
        "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "    callbacks = [EarlyStopping(monitor='val_loss', patience=10)]\n",
        "    history = model.fit(x_tri,y_tri,\n",
        "                epochs=40,callbacks=callbacks,\n",
        "              batch_size = 106, validation_split = 0.2,verbose=1)\n",
        "    \n",
        "    val_acc = model.evaluate(X_val,y_val)[1]\n",
        "    weights = model.get_weights()\n",
        "    # Handle pruning based on the intermediate value.\n",
        "    if trial.should_prune():\n",
        "        raise optuna.exceptions.TrialPruned()\n",
        "\n",
        "    trial.set_user_attr(key=\"best_model_weights\", value=weights)\n",
        "    return val_acc\n",
        "\n",
        "def callback(study, trial):\n",
        "    if study.best_trial.number == trial.number:\n",
        "        study.set_user_attr(key=\"best_model_weights\", \n",
        "                            value=trial.user_attrs[\"best_model_weights\"])\n",
        "\n",
        "study = optuna.create_study(direction=\"maximize\",sampler=optuna.samplers.TPESampler())\n",
        "study.optimize(objective, n_trials=20, timeout=None, callbacks=[callback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GFDm3pmsBdXW"
      },
      "outputs": [],
      "source": [
        "best_params = study.best_trial.params\n",
        "print(f\"Best trial :{study.best_trial.value}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9vigO9OrBdXW"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import StratifiedKFold , KFold\n",
        "is_holdout = False\n",
        "n_splits = 5\n",
        "cv = KFold(n_splits=n_splits, shuffle=True)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate = 8.382620250945622e-05)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del(model)\n",
        "del(scores)\n",
        "del(models)"
      ],
      "metadata": {
        "id": "7km1eVqi1sXF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores = []\n",
        "models = []\n",
        "\n",
        "for tri, vai in cv.split(X_train):\n",
        "    model = build_cnn_lstm2()\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "    callbacks = [EarlyStopping(monitor='val_loss', patience=5)]\n",
        "    history = model.fit(X_train[tri], y_train[tri],\n",
        "                        validation_data=(X_train[vai], y_train[vai]),\n",
        "                        epochs=40,callbacks=callbacks,\n",
        "                        batch_size = 106, verbose=1)\n",
        "    models.append(model)\n",
        "    scores.append(history.history[\"accuracy\"])\n",
        "    if is_holdout:\n",
        "        break    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "atDtX6uWvdBF",
        "outputId": "963ce96e-7452-44a2-c15e-285446581592"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Epoch 1/40\n",
            "7548/7548 [==============================] - 571s 73ms/step - loss: 1.7786 - accuracy: 0.5701 - val_loss: 0.9330 - val_accuracy: 0.7566\n",
            "Epoch 2/40\n",
            "7548/7548 [==============================] - 546s 72ms/step - loss: 1.1060 - accuracy: 0.7136 - val_loss: 0.7571 - val_accuracy: 0.7997\n",
            "Epoch 3/40\n",
            "7548/7548 [==============================] - 547s 72ms/step - loss: 0.9523 - accuracy: 0.7514 - val_loss: 0.6824 - val_accuracy: 0.8190\n",
            "Epoch 4/40\n",
            "7548/7548 [==============================] - 547s 72ms/step - loss: 0.8774 - accuracy: 0.7704 - val_loss: 0.6425 - val_accuracy: 0.8295\n",
            "Epoch 5/40\n",
            "7548/7548 [==============================] - 545s 72ms/step - loss: 0.8326 - accuracy: 0.7814 - val_loss: 0.6137 - val_accuracy: 0.8373\n",
            "Epoch 6/40\n",
            "7548/7548 [==============================] - 543s 72ms/step - loss: 0.8007 - accuracy: 0.7897 - val_loss: 0.6011 - val_accuracy: 0.8417\n",
            "Epoch 7/40\n",
            "7548/7548 [==============================] - 547s 72ms/step - loss: 0.7790 - accuracy: 0.7955 - val_loss: 0.5824 - val_accuracy: 0.8458\n",
            "Epoch 8/40\n",
            "7548/7548 [==============================] - 546s 72ms/step - loss: 0.7612 - accuracy: 0.8004 - val_loss: 0.5751 - val_accuracy: 0.8481\n",
            "Epoch 9/40\n",
            "7548/7548 [==============================] - 546s 72ms/step - loss: 0.7466 - accuracy: 0.8041 - val_loss: 0.5679 - val_accuracy: 0.8506\n",
            "Epoch 10/40\n",
            "7548/7548 [==============================] - 547s 72ms/step - loss: 0.7341 - accuracy: 0.8069 - val_loss: 0.5600 - val_accuracy: 0.8523\n",
            "Epoch 11/40\n",
            "7548/7548 [==============================] - 548s 73ms/step - loss: 0.7243 - accuracy: 0.8097 - val_loss: 0.5515 - val_accuracy: 0.8554\n",
            "Epoch 12/40\n",
            "7548/7548 [==============================] - 548s 73ms/step - loss: 0.7159 - accuracy: 0.8117 - val_loss: 0.5446 - val_accuracy: 0.8565\n",
            "Epoch 13/40\n",
            "2972/7548 [==========>...................] - ETA: 5:08 - loss: 0.7089 - accuracy: 0.8125"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QXejllFxBdXX"
      },
      "outputs": [],
      "source": [
        "# model = build_cnn_lstm2()\n",
        "\n",
        "\n",
        "# callbacks = [EarlyStopping(monitor='val_loss', patience=10)]\n",
        "# history = model.fit(X_train,y_train, epochs=best_params['epochs'],callbacks=callbacks,batch_size = best_params['batchsize'],recurrent_dropout=best_params['recurrent_dropout'], validation_split = 0.2,verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(scores)\n",
        "print(np.mean(scores))"
      ],
      "metadata": {
        "id": "B1OTv-ipxmNF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "txrAu1UIBdXX"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.title('Loss')\n",
        "plt.plot(history.history['loss'], label='train')\n",
        "plt.plot(history.history['val_loss'], label='test')\n",
        "plt.legend()\n",
        "plt.show();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s4UW3ItwBdXY"
      },
      "outputs": [],
      "source": [
        "plt.title('Accuracy')\n",
        "plt.plot(history.history['accuracy'], label='train')\n",
        "plt.plot(history.history['val_accuracy'], label='test')\n",
        "plt.legend()\n",
        "plt.show();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xT6rjuLBdXY"
      },
      "source": [
        "# test padding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MM6L7bt8BdXZ"
      },
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(test)\n",
        "X_encoded = tokenizer.texts_to_sequences(test)\n",
        "#print('정수 인코딩 결과 :',X_encoded.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZBWWxnnQBdXZ"
      },
      "outputs": [],
      "source": [
        "X_test = pad_sequences(X_encoded, maxlen=max_len, padding='post')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_list =[]\n",
        "for i,(tri, vai) in enumerate(cv.split(x_train,y_train) ):\n",
        "    pred = models[i].predict_proba(x_test)[:, 1]\n",
        "    pred_list.append(pred)"
      ],
      "metadata": {
        "id": "AuZ7eWw4xhra"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QRLaw3NR96eX",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "y_pred = np.mean(pred_list)\n",
        "predicted = y_pred.argmax(axis=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "karvKIepBdXZ"
      },
      "outputs": [],
      "source": [
        "digit_1_index = [1.0, 5.0, 10.0, 35.0, 36.0, 41.0, 45.0, 49.0, 55.0, 58.0, 64.0, 68.0, 70.0, 74.0, 84.0, 85.0, 86.0, 90.0, 94.0, 97.0, 99.0]\n",
        "digit_1_value = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M','N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U']\n",
        "\n",
        "dsa = [ i for i in range(100)]\n",
        "def search_digit_1(i):\n",
        "    ans = 0\n",
        "    if i <=digit_1_index[0]:\n",
        "        ans = digit_1_value[0]\n",
        "    elif i <=digit_1_index[1]:\n",
        "        ans=digit_1_value[1]\n",
        "    elif i <=digit_1_index[2]:\n",
        "        ans=digit_1_value[2]\n",
        "\n",
        "    elif i <=digit_1_index[3]:\n",
        "        ans=digit_1_value[3]\n",
        "    elif i <=digit_1_index[4]:\n",
        "        ans=digit_1_value[4]\n",
        "\n",
        "    elif i <=digit_1_index[5]:\n",
        "        ans=digit_1_value[5]\n",
        "    elif i <=digit_1_index[6]:\n",
        "        ans=digit_1_value[6]\n",
        "\n",
        "    elif i <=digit_1_index[7]:\n",
        "        ans=digit_1_value[7]\n",
        "    elif i <=digit_1_index[8]:\n",
        "        ans=digit_1_value[8]\n",
        "    elif i <=digit_1_index[9]:\n",
        "        ans=digit_1_value[9]\n",
        "    elif i <=digit_1_index[10]:\n",
        "        ans=digit_1_value[10]\n",
        "    elif i <=digit_1_index[11]:\n",
        "        ans=digit_1_value[11]\n",
        "\n",
        "    elif i <=digit_1_index[12]:\n",
        "        ans=digit_1_value[12]\n",
        "    elif i <=digit_1_index[13]:\n",
        "        ans=digit_1_value[13]\n",
        "\n",
        "    elif i <=digit_1_index[14]:\n",
        "        ans=digit_1_value[14]\n",
        "    elif i <=digit_1_index[15]:\n",
        "        ans=digit_1_value[15]\n",
        "\n",
        "    elif i <=digit_1_index[16]:\n",
        "        ans=digit_1_value[16]\n",
        "    elif i <=digit_1_index[17]:\n",
        "        ans=digit_1_value[17]\n",
        "\n",
        "    elif i <=digit_1_index[18]:\n",
        "        ans=digit_1_value[18]\n",
        "    elif i <=digit_1_index[19]:\n",
        "        ans=digit_1_value[19]\n",
        "\n",
        "    elif i <=digit_1_index[20]:\n",
        "        ans=digit_1_value[20]\n",
        "    return ans"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s4Ble0YSBdXa"
      },
      "outputs": [],
      "source": [
        "for i in range(len(predicted)):\n",
        "    if len(i) == 2:\n",
        "        submission['digit_3'][i] = int(labels[predicted[i]])*10\n",
        "        submission['digit_2'][i] = int(labels[predicted[i]][0])\n",
        "        submission['digit_1'][i] = search_digit_1(int(labels[predicted[i]])//10)\n",
        "    submission['digit_3'][i] = int(labels[predicted[i]])\n",
        "    submission['digit_2'][i] = int(labels[predicted[i]])//10\n",
        "    submission['digit_1'][i] = search_digit_1(int(labels[predicted[i]])//10)\n",
        "submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Y-iGncEBdXb"
      },
      "outputs": [],
      "source": [
        "submission[['digit_2','digit_3']] = submission[['digit_2','digit_3']].astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-BIiuV3i-If4"
      },
      "outputs": [],
      "source": [
        "submission.to_csv('C:/Users/SEO/OneDrive - 숭실대학교 - Soongsil University/바탕 화면/통계청 ai 경진대회/final/data/sub1_optuna.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y_hQ9oNPBdXb",
        "outputId": "c5b5833c-b4b5-45d0-f757-6ece41e77c65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.utils import plot_model\n",
        "plot_model(model)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "pca-K_flod_version (하이퍼파라미터).ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
