{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data= pd.read_csv('C:/Users/dudtj/OneDrive - 숭실대학교 - Soongsil University/Desktop/CL/python/kostat_AI_contest/실습용 자료/1. 실습용자료.txt', sep ='|',encoding='CP949', header=0)\n",
    "\n",
    "submission= pd.read_csv('C:/Users/dudtj/OneDrive - 숭실대학교 - Soongsil University/Desktop/CL/python/kostat_AI_contest/모델 개발용 자료/2. 모델개발용자료.txt', sep ='|',encoding='CP949', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AI_id</th>\n",
       "      <th>digit_1</th>\n",
       "      <th>digit_2</th>\n",
       "      <th>digit_3</th>\n",
       "      <th>text_obj</th>\n",
       "      <th>text_mthd</th>\n",
       "      <th>text_deal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_0000001</td>\n",
       "      <td>S</td>\n",
       "      <td>95</td>\n",
       "      <td>952</td>\n",
       "      <td>카센터에서</td>\n",
       "      <td>자동차부분정비</td>\n",
       "      <td>타이어오일교환</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_0000002</td>\n",
       "      <td>G</td>\n",
       "      <td>47</td>\n",
       "      <td>472</td>\n",
       "      <td>상점내에서</td>\n",
       "      <td>일반인을 대상으로</td>\n",
       "      <td>채소.과일판매</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_0000003</td>\n",
       "      <td>G</td>\n",
       "      <td>46</td>\n",
       "      <td>467</td>\n",
       "      <td>절단하여사업체에도매</td>\n",
       "      <td>공업용고무를가지고</td>\n",
       "      <td>합성고무도매</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_0000004</td>\n",
       "      <td>G</td>\n",
       "      <td>47</td>\n",
       "      <td>475</td>\n",
       "      <td>영업점에서</td>\n",
       "      <td>일반소비자에게</td>\n",
       "      <td>열쇠잠금장치</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_0000005</td>\n",
       "      <td>Q</td>\n",
       "      <td>87</td>\n",
       "      <td>872</td>\n",
       "      <td>어린이집</td>\n",
       "      <td>보호자의 위탁을 받아</td>\n",
       "      <td>취학전아동보육</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        AI_id digit_1  digit_2  digit_3    text_obj    text_mthd text_deal\n",
       "0  id_0000001       S       95      952       카센터에서      자동차부분정비   타이어오일교환\n",
       "1  id_0000002       G       47      472       상점내에서    일반인을 대상으로   채소.과일판매\n",
       "2  id_0000003       G       46      467  절단하여사업체에도매    공업용고무를가지고    합성고무도매\n",
       "3  id_0000004       G       47      475       영업점에서      일반소비자에게    열쇠잠금장치\n",
       "4  id_0000005       Q       87      872        어린이집  보호자의 위탁을 받아   취학전아동보육"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AI_id</th>\n",
       "      <th>digit_1</th>\n",
       "      <th>digit_2</th>\n",
       "      <th>digit_3</th>\n",
       "      <th>text_obj</th>\n",
       "      <th>text_mthd</th>\n",
       "      <th>text_deal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_000001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>치킨전문점에서</td>\n",
       "      <td>고객의주문에의해</td>\n",
       "      <td>치킨판매</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_000002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>산업공구</td>\n",
       "      <td>다른 소매업자에게</td>\n",
       "      <td>철물 수공구</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_000003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>절에서</td>\n",
       "      <td>신도을 대상으로</td>\n",
       "      <td>불교단체운영</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_000004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>영업장에서</td>\n",
       "      <td>고객요구로</td>\n",
       "      <td>자동차튜닝</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_000005</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>실내포장마차에서</td>\n",
       "      <td>접객시설을 갖추고</td>\n",
       "      <td>소주,맥주제공</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       AI_id  digit_1  digit_2  digit_3  text_obj  text_mthd text_deal\n",
       "0  id_000001      NaN      NaN      NaN   치킨전문점에서   고객의주문에의해      치킨판매\n",
       "1  id_000002      NaN      NaN      NaN      산업공구  다른 소매업자에게    철물 수공구\n",
       "2  id_000003      NaN      NaN      NaN       절에서   신도을 대상으로    불교단체운영\n",
       "3  id_000004      NaN      NaN      NaN     영업장에서      고객요구로     자동차튜닝\n",
       "4  id_000005      NaN      NaN      NaN  실내포장마차에서  접객시설을 갖추고   소주,맥주제공"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           카센터에서 자동차부분정비 타이어오일교환\n",
       "1         상점내에서 일반인을 대상으로 채소.과일판매\n",
       "2     절단하여사업체에도매 공업용고무를가지고 합성고무도매\n",
       "3            영업점에서 일반소비자에게 열쇠잠금장치\n",
       "4        어린이집 보호자의 위탁을 받아 취학전아동보육\n",
       "                 ...             \n",
       "95               미용실 두발미용 서비스 컷.펌\n",
       "96             상가에서 소매업자에게 도매 티셔츠\n",
       "97               안경점 일반소비자에게 안경소매\n",
       "98           사업장에서 아파트를 위해 아파트 관리\n",
       "99          목재,페인트로 간판의뢰를받아 목간판제조\n",
       "Length: 100, dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col = ['text_obj','text_mthd','text_deal']\n",
    "NLP = data[col].apply(lambda row: ' '.join(row.values.astype(str)), axis=1)\n",
    "NLP.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data[['AI_id','digit_3']].copy()\n",
    "df['NLP'] = NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트 정제 함수 : 한글 이외의 문자는 전부 제거합니다.\n",
    "import re\n",
    "def text_cleaning(text):\n",
    "    hangul = re.compile('[^ ㄱ-ㅣ가-힣]+') # 한글의 정규표현식을 나타냅니다.\n",
    "    result = hangul.sub('', text)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import *\n",
    "\n",
    "hannanum = Hannanum()\n",
    "kkma = Kkma()\n",
    "komoran = Komoran()\n",
    "okt = Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Adjective': '형용사',\n",
       " 'Adverb': '부사',\n",
       " 'Alpha': '알파벳',\n",
       " 'Conjunction': '접속사',\n",
       " 'Determiner': '관형사',\n",
       " 'Eomi': '어미',\n",
       " 'Exclamation': '감탄사',\n",
       " 'Foreign': '외국어, 한자 및 기타기호',\n",
       " 'Hashtag': '트위터 해쉬태그',\n",
       " 'Josa': '조사',\n",
       " 'KoreanParticle': '(ex: ㅋㅋ)',\n",
       " 'Noun': '명사',\n",
       " 'Number': '숫자',\n",
       " 'PreEomi': '선어말어미',\n",
       " 'Punctuation': '구두점',\n",
       " 'ScreenName': '트위터 아이디',\n",
       " 'Suffix': '접미사',\n",
       " 'Unknown': '미등록어',\n",
       " 'Verb': '동사'}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "okt.tagset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OKT-기호</th>\n",
       "      <th>OKT-품사</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adjective</td>\n",
       "      <td>형용사</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adverb</td>\n",
       "      <td>부사</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alpha</td>\n",
       "      <td>알파벳</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Conjunction</td>\n",
       "      <td>접속사</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Determiner</td>\n",
       "      <td>관형사</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Eomi</td>\n",
       "      <td>어미</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Exclamation</td>\n",
       "      <td>감탄사</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Foreign</td>\n",
       "      <td>외국어, 한자 및 기타기호</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Hashtag</td>\n",
       "      <td>트위터 해쉬태그</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Josa</td>\n",
       "      <td>조사</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>KoreanParticle</td>\n",
       "      <td>(ex: ㅋㅋ)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Noun</td>\n",
       "      <td>명사</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Number</td>\n",
       "      <td>숫자</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>PreEomi</td>\n",
       "      <td>선어말어미</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Punctuation</td>\n",
       "      <td>구두점</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ScreenName</td>\n",
       "      <td>트위터 아이디</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Suffix</td>\n",
       "      <td>접미사</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>미등록어</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Verb</td>\n",
       "      <td>동사</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            OKT-기호          OKT-품사\n",
       "0        Adjective             형용사\n",
       "1           Adverb              부사\n",
       "2            Alpha             알파벳\n",
       "3      Conjunction             접속사\n",
       "4       Determiner             관형사\n",
       "5             Eomi              어미\n",
       "6      Exclamation             감탄사\n",
       "7          Foreign  외국어, 한자 및 기타기호\n",
       "8          Hashtag        트위터 해쉬태그\n",
       "9             Josa              조사\n",
       "10  KoreanParticle        (ex: ㅋㅋ)\n",
       "11            Noun              명사\n",
       "12          Number              숫자\n",
       "13         PreEomi           선어말어미\n",
       "14     Punctuation             구두점\n",
       "15      ScreenName         트위터 아이디\n",
       "16          Suffix             접미사\n",
       "17         Unknown            미등록어\n",
       "18            Verb              동사"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagsets = pd.DataFrame()\n",
    "N = 18\n",
    "tagsets[\"OKT-기호\"] = list(okt.tagset.keys()) + list(\"*\" * (N - len(okt.tagset)))\n",
    "tagsets[\"OKT-품사\"] = list(okt.tagset.values()) + list(\"*\" * (N - len(okt.tagset)))\n",
    "tagsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in NLP:\n",
    "  text_cleaning(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0               카센터에서 자동차부분정비 타이어오일교환\n",
       "1             상점내에서 일반인을 대상으로 채소.과일판매\n",
       "2         절단하여사업체에도매 공업용고무를가지고 합성고무도매\n",
       "3                영업점에서 일반소비자에게 열쇠잠금장치\n",
       "4            어린이집 보호자의 위탁을 받아 취학전아동보육\n",
       "                     ...             \n",
       "999995                  제품입고 워싱 청바지워싱\n",
       "999996           현장에서 고객의요청에의해 실내인테리어\n",
       "999997          영업점에서 일반소비자에게 여성의류 판매\n",
       "999998           사업장에서 일반고객을대상으로 필라테스\n",
       "999999      사업장에서 접객시설을 갖추고 한식(미역구)판매\n",
       "Length: 1000000, dtype: object"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'상점내에서 일반인을 대상으로 채소.과일판매'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import Text\n",
    "# for i in range(10):\n",
    "#   a.append(okt.nouns(NLP[i]))\n",
    "kolaw = Text(NLP, name=\"kolaw\")\n",
    "kolaw[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-7b9937304d11>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtokenized_contents1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNLP\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m   \u001b[0mtokenized_contents1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mokt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNLP\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\konlpy\\tag\\_okt.py\u001b[0m in \u001b[0;36mpos\u001b[1;34m(self, phrase, norm, stem, join)\u001b[0m\n\u001b[0;32m     72\u001b[0m                     \u001b[0mphrase\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m                     \u001b[0mjpype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjava\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlang\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBoolean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m                     jpype.java.lang.Boolean(stem)).toArray()\n\u001b[0m\u001b[0;32m     75\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mjoin\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtokens\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tokenized_contents1 = []\n",
    "for i in range(len(NLP)):\n",
    "  tokenized_contents1.append(okt.pos(NLP[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hannanum 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Hannanum\n",
    "hannanum=Hannanum()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hannanum-기호</th>\n",
       "      <th>hannanum-품사</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E</td>\n",
       "      <td>어미</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EC</td>\n",
       "      <td>연결 어미</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EF</td>\n",
       "      <td>종결 어미</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EP</td>\n",
       "      <td>선어말어미</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ET</td>\n",
       "      <td>전성 어미</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>F</td>\n",
       "      <td>외국어</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I</td>\n",
       "      <td>독립언</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>II</td>\n",
       "      <td>감탄사</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>J</td>\n",
       "      <td>관계언</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>JC</td>\n",
       "      <td>격조사</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>JP</td>\n",
       "      <td>서술격 조사</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>JX</td>\n",
       "      <td>보조사</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>M</td>\n",
       "      <td>수식언</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>MA</td>\n",
       "      <td>부사</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>MM</td>\n",
       "      <td>관형사</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>N</td>\n",
       "      <td>체언</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NB</td>\n",
       "      <td>의존명사</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NC</td>\n",
       "      <td>보통명사</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>NN</td>\n",
       "      <td>수사</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>NP</td>\n",
       "      <td>대명사</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NQ</td>\n",
       "      <td>고유명사</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>P</td>\n",
       "      <td>용언</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>PA</td>\n",
       "      <td>형용사</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>PV</td>\n",
       "      <td>동사</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>PX</td>\n",
       "      <td>보조 용언</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>S</td>\n",
       "      <td>기호</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>X</td>\n",
       "      <td>접사</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>XP</td>\n",
       "      <td>접두사</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>XS</td>\n",
       "      <td>접미사</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hannanum-기호 hannanum-품사\n",
       "0            E          어미\n",
       "1           EC       연결 어미\n",
       "2           EF       종결 어미\n",
       "3           EP       선어말어미\n",
       "4           ET       전성 어미\n",
       "5            F         외국어\n",
       "6            I         독립언\n",
       "7           II         감탄사\n",
       "8            J         관계언\n",
       "9           JC         격조사\n",
       "10          JP      서술격 조사\n",
       "11          JX         보조사\n",
       "12           M         수식언\n",
       "13          MA          부사\n",
       "14          MM         관형사\n",
       "15           N          체언\n",
       "16          NB        의존명사\n",
       "17          NC        보통명사\n",
       "18          NN          수사\n",
       "19          NP         대명사\n",
       "20          NQ        고유명사\n",
       "21           P          용언\n",
       "22          PA         형용사\n",
       "23          PV          동사\n",
       "24          PX       보조 용언\n",
       "25           S          기호\n",
       "26           X          접사\n",
       "27          XP         접두사\n",
       "28          XS         접미사"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagsets = pd.DataFrame()\n",
    "N = 18\n",
    "tagsets[\"hannanum-기호\"] = list(hannanum.tagset.keys()) + list(\"*\" * (N - len(hannanum.tagset)))\n",
    "tagsets[\"hannanum-품사\"] = list(hannanum.tagset.values()) + list(\"*\" * (N - len(hannanum.tagset)))\n",
    "tagsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-c940cd737b3e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtokenized_contents\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNLP\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m   \u001b[0mtokenized_contents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhannanum\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNLP\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\konlpy\\tag\\_hannanum.py\u001b[0m in \u001b[0;36mpos\u001b[1;34m(self, phrase, ntags, flatten, join)\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mntags\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m9\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjhi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimplePos09\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mphrase\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    100\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mntags\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m22\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjhi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimplePos22\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mphrase\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tokenized_contents2 = []\n",
    "for i in range(len(NLP)):\n",
    "  tokenized_contents2.append(hannanum.pos(NLP[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/lovit/soynlp 참고"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from soynlp.noun import LRNounExtractor\n",
    "noun_extractor = LRNounExtractor()\n",
    "nouns = noun_extractor.train_extract( ) # list of str like\n",
    "\n",
    "from soynlp.noun import NewsNounExtractor\n",
    "noun_extractor = NewsNounExtractor()\n",
    "nouns = noun_extractor.train_extract( ) # list of str like"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from soynlp.utils import DoublespaceLineCorpus\n",
    "from soynlp.noun import LRNounExtractor_v2\n",
    "\n",
    "corpus_path = '2016-10-20-news'\n",
    "sents = DoublespaceLineCorpus(NLP, iter_sent=True)\n",
    "\n",
    "noun_extractor = LRNounExtractor_v2(verbose=True)\n",
    "nouns = noun_extractor.train_extract(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training ... (700000 in 1000000 sents) use memory 1.582 Gb"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-534287232729>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mmin_right_branching_entropy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m )\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mword_extractor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNLP\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# list of str or like\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mword_extractor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextract\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\soynlp\\word\\_word.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, sents, num_for_pruning, cumulate)\u001b[0m\n\u001b[0;32m     97\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_aL\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'%s %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright_word\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_left_length\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword_len\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_aR\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'%s %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mleft_word\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnum_for_pruning\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m \u001b[0mnum_sent\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mnum_for_pruning\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from soynlp.word import WordExtractor\n",
    "\n",
    "word_extractor = WordExtractor(min_frequency=100,\n",
    "    min_cohesion_forward=0.05, \n",
    "    min_right_branching_entropy=0.0\n",
    ")\n",
    "word_extractor.train(NLP) # list of str or like\n",
    "words = word_extractor.extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pos_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-a8c12590a2c2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msoynlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpostagger\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mUnknowLRPostprocessor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mdictionary\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDictionary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpos_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mgenerator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLRTemplateMatcher\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mevaluator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLREvaluator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pos_dict' is not defined"
     ]
    }
   ],
   "source": [
    "from soynlp.postagger import Dictionary\n",
    "from soynlp.postagger import LRTemplateMatcher\n",
    "from soynlp.postagger import LREvaluator\n",
    "from soynlp.postagger import SimpleTagger\n",
    "from soynlp.postagger import UnknowLRPostprocessor\n",
    "\n",
    "dictionary = Dictionary(tokenized_contents1)\n",
    "generator = LRTemplateMatcher(dictionary)    \n",
    "evaluator = LREvaluator()\n",
    "postprocessor = UnknowLRPostprocessor()\n",
    "tagger = SimpleTagger(generator, evaluator, postprocessor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from soynlp.postagger import Dictionary\n",
    "from soynlp.postagger import LRTemplateMatcher\n",
    "from soynlp.postagger import LREvaluator\n",
    "from soynlp.postagger import SimpleTagger\n",
    "from soynlp.postagger import UnknowLRPostprocessor\n",
    "\n",
    "dictionary = Dictionary(tokenized_contents2)\n",
    "generator = LRTemplateMatcher(dictionary)    \n",
    "evaluator = LREvaluator()\n",
    "postprocessor = UnknowLRPostprocessor()\n",
    "tagger = SimpleTagger(generator, evaluator, postprocessor)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e017a947ed1cbd98d6fb4aec7d9beab0ece45773d45accafee45474853a8cce5"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
