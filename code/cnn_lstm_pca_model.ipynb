{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rootofdata/kostat_AI_contest/blob/main/pca_model_(%EC%98%81%EC%84%9D_%ED%95%98%EC%9D%B4%ED%8D%BC%ED%8C%8C%EB%9D%BC%EB%AF%B8%ED%84%B0).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86xHHfRk6qBT"
      },
      "source": [
        "# 256->512 ver. CNN-LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VFWgPylT6qBV",
        "outputId": "9b347c32-308d-4df5-a215-b256cf053452"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gensim in c:\\users\\seo\\anaconda3\\lib\\site-packages (4.1.2)\n",
            "Requirement already satisfied: Cython==0.29.23 in c:\\users\\seo\\anaconda3\\lib\\site-packages (from gensim) (0.29.23)\n",
            "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\seo\\anaconda3\\lib\\site-packages (from gensim) (1.5.2)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\seo\\anaconda3\\lib\\site-packages (from gensim) (5.2.1)\n",
            "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\seo\\anaconda3\\lib\\site-packages (from gensim) (1.22.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fK_z9ki46qBX",
        "outputId": "447f48ea-4c40-4dfd-849c-f38bdf17b359"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'2.8.0'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "tf.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tEKQI9-Y6qBX",
        "outputId": "ff1bfd0d-63ee-435f-87bb-30a06c99a2be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-3-db1e1abccb74>:3: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.config.list_physical_devices('GPU')` instead.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "device_lib.list_local_devices()\n",
        "tf.test.is_gpu_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kDpHMbrt6qBY",
        "outputId": "b08634df-fdc2-4436-9a29-d2074793805a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[name: \"/device:CPU:0\"\n",
            "device_type: \"CPU\"\n",
            "memory_limit: 268435456\n",
            "locality {\n",
            "}\n",
            "incarnation: 11041875311111005340\n",
            "xla_global_id: -1\n",
            ", name: \"/device:GPU:0\"\n",
            "device_type: \"GPU\"\n",
            "memory_limit: 5769199616\n",
            "locality {\n",
            "  bus_id: 1\n",
            "  links {\n",
            "  }\n",
            "}\n",
            "incarnation: 11163976052974721689\n",
            "physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 3060 Ti, pci bus id: 0000:01:00.0, compute capability: 8.6\"\n",
            "xla_global_id: 416903419\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "\n",
        "print(device_lib.list_local_devices())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yDTA2wLCkx1P"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IEEjEQugjjUt"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from gensim.models import word2vec\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rttwJXTfEFO3"
      },
      "source": [
        "# 함수 및 데이터 로드"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yw9wEXBymBYw"
      },
      "outputs": [],
      "source": [
        "def compute_pca(X: np.ndarray, n_components: int=2) -> np.ndarray:\n",
        "    \"\"\"Calculate the principal components for X\n",
        "\n",
        "    Args:\n",
        "       X: of dimension (m,n) where each row corresponds to a word vector\n",
        "       n_components: Number of components you want to keep.\n",
        "\n",
        "    Return:\n",
        "       X_reduced: data transformed in 2 dims/columns + regenerated original data\n",
        "    \"\"\"\n",
        "    # you need to set axis to 0 or it will calculate the mean of the entire matrix instead of one per row\n",
        "    X_demeaned = X - X.mean(axis=0)\n",
        "\n",
        "    # calculate the covariance matrix\n",
        "    # the default np.cov assumes the rows are variables, not columns so set rowvar to False\n",
        "    covariance_matrix = np.cov(X_demeaned, rowvar=False)\n",
        "\n",
        "    # calculate eigenvectors & eigenvalues of the covariance matrix\n",
        "    eigen_vals, eigen_vecs = np.linalg.eigh(covariance_matrix)\n",
        "\n",
        "    # sort eigenvalue in increasing order (get the indices from the sort)\n",
        "    idx_sorted = np.argsort(eigen_vals)\n",
        "\n",
        "    # reverse the order so that it's from highest to lowest.\n",
        "    idx_sorted_decreasing = list(reversed(idx_sorted))\n",
        "\n",
        "    # sort the eigen values by idx_sorted_decreasing\n",
        "    eigen_vals_sorted = eigen_vals[idx_sorted_decreasing]\n",
        "\n",
        "    # sort eigenvectors using the idx_sorted_decreasing indices\n",
        "    # We're only sorting the columns so remember to get all the rows in the slice\n",
        "    eigen_vecs_sorted = eigen_vecs[:, idx_sorted_decreasing]\n",
        "\n",
        "    # select the first n eigenvectors (n is desired dimension\n",
        "    # of rescaled data array, or dims_rescaled_data)\n",
        "    # once again, make sure to get all the rows and only slice the columns\n",
        "    eigen_vecs_subset = eigen_vecs_sorted[:, :n_components]\n",
        "\n",
        "    # transform the data by multiplying the transpose of the eigenvectors \n",
        "    # with the transpose of the de-meaned data\n",
        "    # Then take the transpose of that product.\n",
        "    X_reduced = np.dot(eigen_vecs_subset.T, X_demeaned.T).T\n",
        "    return X_reduced"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Iky1oa5lx-Z"
      },
      "outputs": [],
      "source": [
        "def get_vector(word):\n",
        "    if word in word2vec_model:\n",
        "        return word2vec_model[word]\n",
        "    else:\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yJKQjm2ajufW"
      },
      "outputs": [],
      "source": [
        "# train = pd.read_csv('/content/drive/MyDrive/통계청_AI경진대회/final/data/bigword_split_okt2_remove_stopword_8_4')\n",
        "# test = pd.read_csv('/content/drive/MyDrive/통계청_AI경진대회/final/data/tok_sm8_2_with_remove_stopword')\n",
        "word2vec_model = word2vec.Word2Vec.load('C:/Users/SEO/OneDrive - 숭실대학교 - Soongsil University/바탕 화면/통계청 ai 경진대회/final/data/train_final.model2')\n",
        "word2vec_model = word2vec_model.wv\n",
        "submission = pd.read_csv('C:/Users/SEO/OneDrive - 숭실대학교 - Soongsil University/바탕 화면/통계청 ai 경진대회/모델 개발용 자료/모델 개발용 자료.csv',header = 1)\n",
        "data = pd.read_csv('C:/Users/SEO/OneDrive - 숭실대학교 - Soongsil University/바탕 화면/통계청 ai 경진대회/실습용 자료/실습용 자료.csv',header = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F3EtSp-xkPwv"
      },
      "outputs": [],
      "source": [
        "train = []\n",
        "with open('C:/Users/SEO/OneDrive - 숭실대학교 - Soongsil University/바탕 화면/통계청 ai 경진대회/final/data/train_final2','rb') as f:\n",
        "    train = pickle.load(f)\n",
        "max_len = max(len(l) for l in train)\n",
        "\n",
        "test = []\n",
        "with open('C:/Users/SEO/OneDrive - 숭실대학교 - Soongsil University/바탕 화면/통계청 ai 경진대회/final/data/submission_final2','rb') as f:\n",
        "    test = pickle.load(f)\n",
        "max_len2 = max(len(l) for l in test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DO8hH_K9kpfG",
        "outputId": "9e6dd648-062c-4c2e-c932-f577000ca257"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(53, 49)"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "max_len, max_len2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4DYK3aq71Jf3"
      },
      "source": [
        "# embedding Matrix-> pca"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tcPlspsg1ML2",
        "outputId": "c71961db-b31e-431b-aeb5-69fcd369a3e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "단어 집합 : 37121\n"
          ]
        }
      ],
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(train)\n",
        "vocab_size = len(tokenizer.word_index) + 1 # 패딩을 고려하여 +1\n",
        "print('단어 집합 :',vocab_size)\n",
        "\n",
        "X_encoded = tokenizer.texts_to_sequences(train)\n",
        "#print('정수 인코딩 결과 :',X_encoded.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fsi7FYE08iYM"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open('C:/Users/SEO/OneDrive - 숭실대학교 - Soongsil University/바탕 화면/통계청 ai 경진대회/a_495','rb') as f:\n",
        "    a_495 = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s7WUh4pQ6qBb",
        "outputId": "d8c0f71c-08b0-4db0-f22e-12e0317c9efe"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>digit_3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>952</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>472</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>467</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>475</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>872</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>490</th>\n",
              "      <td>969</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>491</th>\n",
              "      <td>970</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>492</th>\n",
              "      <td>981</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>493</th>\n",
              "      <td>982</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>494</th>\n",
              "      <td>990</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000495 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     digit_3\n",
              "0        952\n",
              "1        472\n",
              "2        467\n",
              "3        475\n",
              "4        872\n",
              "..       ...\n",
              "490      969\n",
              "491      970\n",
              "492      981\n",
              "493      982\n",
              "494      990\n",
              "\n",
              "[1000495 rows x 1 columns]"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a1=pd.DataFrame(data['digit_3'])\n",
        "a2=pd.DataFrame(a_495)\n",
        "y = pd.concat([a1 ,a2] )\n",
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17oaLYan1VQ2",
        "outputId": "a728889a-326f-4114-9740-5719e1aaa87c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['101' '102' '103' '104' '105' '106' '107' '108' '11' '111' '112' '12'\n",
            " '120' '13' '131' '132' '133' '134' '139' '14' '141' '142' '143' '144'\n",
            " '15' '151' '152' '161' '162' '163' '171' '172' '179' '181' '182' '191'\n",
            " '192' '20' '201' '202' '203' '204' '205' '211' '212' '213' '221' '222'\n",
            " '231' '232' '233' '239' '241' '242' '243' '251' '252' '259' '261' '262'\n",
            " '263' '264' '265' '266' '271' '272' '273' '274' '281' '282' '283' '284'\n",
            " '285' '289' '291' '292' '301' '302' '303' '304' '31' '311' '312' '313'\n",
            " '319' '32' '320' '331' '332' '333' '334' '339' '340' '351' '352' '353'\n",
            " '360' '370' '381' '382' '383' '390' '411' '412' '421' '422' '423' '424'\n",
            " '425' '426' '451' '452' '453' '461' '462' '463' '464' '465' '466' '467'\n",
            " '468' '471' '472' '473' '474' '475' '476' '477' '478' '479' '491' '492'\n",
            " '493' '494' '495' '501' '502' '51' '511' '512' '52' '521' '529' '551'\n",
            " '559' '561' '562' '581' '582' '591' '592' '601' '602' '61' '611' '612'\n",
            " '62' '620' '631' '639' '641' '642' '649' '651' '652' '653' '661' '662'\n",
            " '681' '682' '701' '702' '71' '711' '712' '713' '714' '715' '716' '72'\n",
            " '721' '729' '731' '732' '733' '739' '741' '742' '743' '751' '752' '753'\n",
            " '759' '761' '762' '763' '764' '80' '841' '842' '843' '844' '845' '851'\n",
            " '852' '853' '854' '855' '856' '857' '861' '862' '863' '869' '871' '872'\n",
            " '901' '902' '911' '912' '941' '942' '949' '951' '952' '953' '961' '969'\n",
            " '970' '981' '982' '990']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\SEO\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  return f(**kwargs)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "import tensorflow as tf\n",
        "\n",
        "y_train = y.astype(str)\n",
        "\n",
        "le = LabelEncoder()\n",
        "le.fit(y_train)\n",
        "print(le.classes_)\n",
        "labels = le.classes_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uYwBJltX6qBb",
        "outputId": "79c0080f-3fba-4f05-c111-93aae8b84f0f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['101' '102' '103' '104' '105' '106' '107' '108' '11' '111' '112' '12'\n",
            " '120' '13' '131' '132' '133' '134' '139' '14' '141' '142' '143' '144'\n",
            " '15' '151' '152' '161' '162' '163' '171' '172' '179' '181' '182' '191'\n",
            " '192' '20' '201' '202' '203' '204' '205' '211' '212' '213' '221' '222'\n",
            " '231' '232' '233' '239' '241' '242' '243' '251' '252' '259' '261' '262'\n",
            " '263' '264' '265' '266' '271' '272' '273' '274' '281' '282' '283' '284'\n",
            " '285' '289' '291' '292' '301' '302' '303' '304' '31' '311' '312' '313'\n",
            " '319' '32' '320' '331' '332' '333' '334' '339' '340' '351' '352' '353'\n",
            " '360' '370' '381' '382' '383' '390' '411' '412' '421' '422' '423' '424'\n",
            " '425' '426' '451' '452' '453' '461' '462' '463' '464' '465' '466' '467'\n",
            " '468' '471' '472' '473' '474' '475' '476' '477' '478' '479' '491' '492'\n",
            " '493' '494' '495' '501' '502' '51' '511' '512' '52' '521' '529' '551'\n",
            " '559' '561' '562' '581' '582' '591' '592' '601' '602' '61' '611' '612'\n",
            " '62' '620' '631' '639' '641' '642' '649' '651' '652' '653' '661' '662'\n",
            " '681' '682' '701' '702' '71' '711' '712' '713' '714' '715' '716' '72'\n",
            " '721' '729' '731' '732' '733' '739' '741' '742' '743' '751' '752' '753'\n",
            " '759' '761' '762' '763' '764' '80' '841' '842' '843' '844' '845' '851'\n",
            " '852' '853' '854' '855' '856' '857' '861' '862' '863' '869' '871' '872'\n",
            " '901' '902' '911' '912' '941' '942' '949' '951' '952' '953' '961' '969'\n",
            " '970' '981' '982' '990']\n",
            "(1000495, 232)\n"
          ]
        }
      ],
      "source": [
        "print(labels)\n",
        "y_train = le.transform(y_train)\n",
        "y_train = tf.keras.utils.to_categorical(y_train)\n",
        "print(y_train.shape) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aRI2oQDI1acs",
        "outputId": "0afdb47c-18bd-419f-9c36-0366c4cc960c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "패딩 결과 :\n",
            "[[  92   18   87 ...    0    0    0]\n",
            " [1141  183  147 ...    0    0    0]\n",
            " [  38  462  331 ...    0    0    0]\n",
            " ...\n",
            " [3810  952 2807 ...    0    0    0]\n",
            " [3810  952 2807 ...    0    0    0]\n",
            " [1172 1220  368 ...    0    0    0]]\n",
            "y_train numclass (1000495, 232)\n"
          ]
        }
      ],
      "source": [
        "X_train = pad_sequences(X_encoded, maxlen=max_len, padding='post')\n",
        "print('패딩 결과 :')\n",
        "print(X_train)\n",
        "print('y_train numclass',y_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "utvDwoI-1e9c",
        "outputId": "0635b74c-1e47-4adf-fd81-1dd1c976ab4e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "임베딩 행렬의 크기(shape) : (37121, 100)\n"
          ]
        }
      ],
      "source": [
        "numclass = data['digit_3'].nunique()\n",
        "\n",
        "embedding_matrix = np.zeros((vocab_size, 100))\n",
        "print('임베딩 행렬의 크기(shape) :',np.shape(embedding_matrix))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uXixGTMY1lSf"
      },
      "outputs": [],
      "source": [
        "for word, index in tokenizer.word_index.items():\n",
        "    # 단어와 맵핑되는 사전 훈련된 임베딩 벡터값\n",
        "    vector_value = get_vector(word)\n",
        "    if vector_value is not None:\n",
        "        embedding_matrix[index] = vector_value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qUJJ5aX6qBc"
      },
      "source": [
        "## PCA 100 -> 50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UOJExvCV1pdM"
      },
      "outputs": [],
      "source": [
        "X = embedding_matrix\n",
        "X_reduced = compute_pca(X, n_components=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Or9X0zqu6qBc"
      },
      "outputs": [],
      "source": [
        "y_train = y_train.astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XQGUVV6w6qBc",
        "outputId": "3c3301e9-cb23-4298-c77a-d6b5fd7225d5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(37121, 50)"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_reduced.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Y44VcuU6qBc"
      },
      "source": [
        "# fine tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "TS1sCUeZ6qBc",
        "outputId": "d59a2854-b423-487f-b8ad-71084638aa79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: optuna in c:\\users\\seo\\anaconda3\\lib\\site-packages (2.10.0)\n",
            "Requirement already satisfied: alembic in c:\\users\\seo\\anaconda3\\lib\\site-packages (from optuna) (1.7.7)\n",
            "Requirement already satisfied: colorlog in c:\\users\\seo\\anaconda3\\lib\\site-packages (from optuna) (6.6.0)\n",
            "Requirement already satisfied: tqdm in c:\\users\\seo\\anaconda3\\lib\\site-packages (from optuna) (4.50.2)\n",
            "Requirement already satisfied: PyYAML in c:\\users\\seo\\anaconda3\\lib\\site-packages (from optuna) (5.3.1)\n",
            "Requirement already satisfied: cmaes>=0.8.2 in c:\\users\\seo\\anaconda3\\lib\\site-packages (from optuna) (0.8.2)\n",
            "Requirement already satisfied: scipy!=1.4.0 in c:\\users\\seo\\anaconda3\\lib\\site-packages (from optuna) (1.5.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.1.0 in c:\\users\\seo\\anaconda3\\lib\\site-packages (from optuna) (1.3.20)\n",
            "Requirement already satisfied: numpy in c:\\users\\seo\\anaconda3\\lib\\site-packages (from optuna) (1.22.3)\n",
            "Requirement already satisfied: cliff in c:\\users\\seo\\anaconda3\\lib\\site-packages (from optuna) (3.10.1)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\seo\\anaconda3\\lib\\site-packages (from optuna) (20.4)\n",
            "Requirement already satisfied: Mako in c:\\users\\seo\\anaconda3\\lib\\site-packages (from alembic->optuna) (1.2.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.9\" in c:\\users\\seo\\anaconda3\\lib\\site-packages (from alembic->optuna) (4.11.3)\n",
            "Requirement already satisfied: importlib-resources; python_version < \"3.9\" in c:\\users\\seo\\anaconda3\\lib\\site-packages (from alembic->optuna) (5.6.0)\n",
            "Requirement already satisfied: colorama; sys_platform == \"win32\" in c:\\users\\seo\\anaconda3\\lib\\site-packages (from colorlog->optuna) (0.4.4)\n",
            "Requirement already satisfied: autopage>=0.4.0 in c:\\users\\seo\\anaconda3\\lib\\site-packages (from cliff->optuna) (0.5.0)\n",
            "Requirement already satisfied: PrettyTable>=0.7.2 in c:\\users\\seo\\anaconda3\\lib\\site-packages (from cliff->optuna) (3.2.0)\n",
            "Requirement already satisfied: pyparsing>=2.1.0 in c:\\users\\seo\\anaconda3\\lib\\site-packages (from cliff->optuna) (2.4.7)\n",
            "Requirement already satisfied: stevedore>=2.0.1 in c:\\users\\seo\\anaconda3\\lib\\site-packages (from cliff->optuna) (3.5.0)\n",
            "Requirement already satisfied: pbr!=2.1.0,>=2.0.0 in c:\\users\\seo\\anaconda3\\lib\\site-packages (from cliff->optuna) (5.8.1)\n",
            "Requirement already satisfied: cmd2>=1.0.0 in c:\\users\\seo\\anaconda3\\lib\\site-packages (from cliff->optuna) (2.4.0)\n",
            "Requirement already satisfied: six in c:\\users\\seo\\anaconda3\\lib\\site-packages (from packaging>=20.0->optuna) (1.15.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in c:\\users\\seo\\anaconda3\\lib\\site-packages (from Mako->alembic->optuna) (1.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in c:\\users\\seo\\anaconda3\\lib\\site-packages (from importlib-metadata; python_version < \"3.9\"->alembic->optuna) (3.4.0)\n",
            "Requirement already satisfied: wcwidth in c:\\users\\seo\\anaconda3\\lib\\site-packages (from PrettyTable>=0.7.2->cliff->optuna) (0.2.5)\n",
            "Requirement already satisfied: pyreadline3; sys_platform == \"win32\" in c:\\users\\seo\\anaconda3\\lib\\site-packages (from cmd2>=1.0.0->cliff->optuna) (3.4.1)\n",
            "Requirement already satisfied: attrs>=16.3.0 in c:\\users\\seo\\anaconda3\\lib\\site-packages (from cmd2>=1.0.0->cliff->optuna) (20.3.0)\n",
            "Requirement already satisfied: pyperclip>=1.6 in c:\\users\\seo\\anaconda3\\lib\\site-packages (from cmd2>=1.0.0->cliff->optuna) (1.8.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dAJ_I_fs1uFU"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Input, Activation, Dropout, LSTM, Dense,Conv1D,MaxPooling1D,Embedding,Flatten\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import utils\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "def build_cnn_lstm2():\n",
        "    with tf.device('/gpu:0'):\n",
        "        model = Sequential()\n",
        "\n",
        "        model.add(Input(shape=(max_len,)))\n",
        "        e = Embedding(vocab_size,output_dim =50,  weights=[X_reduced], input_length=max_len, trainable=False)\n",
        "        model.add(e)\n",
        "\n",
        "        model.add(Conv1D(filters=64, kernel_size=3, padding='same', activation='relu'))\n",
        "        model.add(MaxPooling1D(pool_size=2))\n",
        "\n",
        "        model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
        "        model.add(MaxPooling1D(pool_size=2))\n",
        "\n",
        "        model.add(LSTM(256, recurrent_dropout=0.5,kernel_initializer=\"he_normal\",unroll=True,return_sequences=True))\n",
        "        model.add(Dropout(0.5))\n",
        "\n",
        "        model.add(LSTM(512, recurrent_dropout=0.5,kernel_initializer=\"he_normal\",unroll=True))\n",
        "        model.add(Dropout(0.5))\n",
        "\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(y_train.shape[1], activation='softmax'))\n",
        "        # adam = tf.keras.optimizers.Adam(learning_rate = 1e-5)\n",
        "        \n",
        "\n",
        "        return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "ZXIzhn9Y6qBd",
        "outputId": "6cc3afe6-ecc4-4521-92cf-cc34efb65e01"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-04-10 03:21:07,856]\u001b[0m A new study created in memory with name: no-name-bf049315-f9b9-4042-89e3-85bd6a6e5000\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Epoch 1/40\n",
            "3021/3021 [==============================] - 202s 63ms/step - loss: 1.6984 - accuracy: 0.6033 - val_loss: 0.9591 - val_accuracy: 0.7599\n",
            "Epoch 2/40\n",
            "3021/3021 [==============================] - 188s 62ms/step - loss: 0.9289 - accuracy: 0.7650 - val_loss: 0.7775 - val_accuracy: 0.8030\n",
            "Epoch 3/40\n",
            "3021/3021 [==============================] - 188s 62ms/step - loss: 0.7792 - accuracy: 0.8005 - val_loss: 0.6984 - val_accuracy: 0.8215\n",
            "Epoch 4/40\n",
            "3021/3021 [==============================] - 187s 62ms/step - loss: 0.7037 - accuracy: 0.8184 - val_loss: 0.6532 - val_accuracy: 0.8314\n",
            "Epoch 5/40\n",
            "3021/3021 [==============================] - 189s 63ms/step - loss: 0.6586 - accuracy: 0.8289 - val_loss: 0.6199 - val_accuracy: 0.8388\n",
            "Epoch 6/40\n",
            "3021/3021 [==============================] - 191s 63ms/step - loss: 0.6253 - accuracy: 0.8369 - val_loss: 0.5961 - val_accuracy: 0.8438\n",
            "Epoch 7/40\n",
            "3021/3021 [==============================] - 193s 64ms/step - loss: 0.6007 - accuracy: 0.8427 - val_loss: 0.5806 - val_accuracy: 0.8480\n",
            "Epoch 8/40\n",
            "3021/3021 [==============================] - 191s 63ms/step - loss: 0.5818 - accuracy: 0.8478 - val_loss: 0.5687 - val_accuracy: 0.8505\n",
            "Epoch 9/40\n",
            "3021/3021 [==============================] - 196s 65ms/step - loss: 0.5661 - accuracy: 0.8514 - val_loss: 0.5577 - val_accuracy: 0.8529\n",
            "Epoch 10/40\n",
            "3021/3021 [==============================] - 196s 65ms/step - loss: 0.5531 - accuracy: 0.8542 - val_loss: 0.5520 - val_accuracy: 0.8549\n",
            "Epoch 11/40\n",
            "3021/3021 [==============================] - 191s 63ms/step - loss: 0.5419 - accuracy: 0.8570 - val_loss: 0.5405 - val_accuracy: 0.8567\n",
            "Epoch 12/40\n",
            "3021/3021 [==============================] - 192s 64ms/step - loss: 0.5322 - accuracy: 0.8594 - val_loss: 0.5346 - val_accuracy: 0.8586\n",
            "Epoch 13/40\n",
            "3021/3021 [==============================] - 195s 65ms/step - loss: 0.5232 - accuracy: 0.8613 - val_loss: 0.5320 - val_accuracy: 0.8596\n",
            "Epoch 14/40\n",
            "3021/3021 [==============================] - 200s 66ms/step - loss: 0.5168 - accuracy: 0.8631 - val_loss: 0.5241 - val_accuracy: 0.8613\n",
            "Epoch 15/40\n",
            "3021/3021 [==============================] - 200s 66ms/step - loss: 0.5107 - accuracy: 0.8645 - val_loss: 0.5200 - val_accuracy: 0.8629\n",
            "Epoch 16/40\n",
            "3021/3021 [==============================] - 201s 67ms/step - loss: 0.5044 - accuracy: 0.8657 - val_loss: 0.5163 - val_accuracy: 0.8638\n",
            "Epoch 17/40\n",
            "3021/3021 [==============================] - 192s 63ms/step - loss: 0.4989 - accuracy: 0.8670 - val_loss: 0.5137 - val_accuracy: 0.8647\n",
            "Epoch 18/40\n",
            "3021/3021 [==============================] - 186s 62ms/step - loss: 0.4936 - accuracy: 0.8687 - val_loss: 0.5084 - val_accuracy: 0.8655\n",
            "Epoch 19/40\n",
            "3021/3021 [==============================] - 187s 62ms/step - loss: 0.4886 - accuracy: 0.8694 - val_loss: 0.5061 - val_accuracy: 0.8663\n",
            "Epoch 20/40\n",
            "3021/3021 [==============================] - 188s 62ms/step - loss: 0.4843 - accuracy: 0.8707 - val_loss: 0.5032 - val_accuracy: 0.8676\n",
            "Epoch 21/40\n",
            "3021/3021 [==============================] - 187s 62ms/step - loss: 0.4810 - accuracy: 0.8711 - val_loss: 0.5025 - val_accuracy: 0.8678\n",
            "Epoch 22/40\n",
            "3021/3021 [==============================] - 187s 62ms/step - loss: 0.4769 - accuracy: 0.8722 - val_loss: 0.4998 - val_accuracy: 0.8673\n",
            "Epoch 23/40\n",
            "3021/3021 [==============================] - 191s 63ms/step - loss: 0.4731 - accuracy: 0.8729 - val_loss: 0.4972 - val_accuracy: 0.8687\n",
            "Epoch 24/40\n",
            "3021/3021 [==============================] - 202s 67ms/step - loss: 0.4700 - accuracy: 0.8738 - val_loss: 0.4951 - val_accuracy: 0.8691\n",
            "Epoch 25/40\n",
            "3021/3021 [==============================] - 190s 63ms/step - loss: 0.4674 - accuracy: 0.8747 - val_loss: 0.4940 - val_accuracy: 0.8696\n",
            "Epoch 26/40\n",
            "3021/3021 [==============================] - 188s 62ms/step - loss: 0.4638 - accuracy: 0.8754 - val_loss: 0.4901 - val_accuracy: 0.8706\n",
            "Epoch 27/40\n",
            "3021/3021 [==============================] - 199s 66ms/step - loss: 0.4603 - accuracy: 0.8761 - val_loss: 0.4895 - val_accuracy: 0.8708\n",
            "Epoch 28/40\n",
            "3021/3021 [==============================] - 201s 66ms/step - loss: 0.4583 - accuracy: 0.8767 - val_loss: 0.4894 - val_accuracy: 0.8709\n",
            "Epoch 29/40\n",
            "3021/3021 [==============================] - 199s 66ms/step - loss: 0.4566 - accuracy: 0.8768 - val_loss: 0.4885 - val_accuracy: 0.8717\n",
            "Epoch 30/40\n",
            "3021/3021 [==============================] - 199s 66ms/step - loss: 0.4531 - accuracy: 0.8775 - val_loss: 0.4867 - val_accuracy: 0.8719\n",
            "Epoch 31/40\n",
            "3021/3021 [==============================] - 200s 66ms/step - loss: 0.4520 - accuracy: 0.8780 - val_loss: 0.4863 - val_accuracy: 0.8719\n",
            "Epoch 32/40\n",
            "3021/3021 [==============================] - 200s 66ms/step - loss: 0.4486 - accuracy: 0.8789 - val_loss: 0.4857 - val_accuracy: 0.8726\n",
            "Epoch 33/40\n",
            "3021/3021 [==============================] - 199s 66ms/step - loss: 0.4466 - accuracy: 0.8793 - val_loss: 0.4833 - val_accuracy: 0.8728\n",
            "Epoch 34/40\n",
            "3021/3021 [==============================] - 199s 66ms/step - loss: 0.4449 - accuracy: 0.8798 - val_loss: 0.4827 - val_accuracy: 0.8728\n",
            "Epoch 35/40\n",
            "3021/3021 [==============================] - 199s 66ms/step - loss: 0.4425 - accuracy: 0.8803 - val_loss: 0.4808 - val_accuracy: 0.8733\n",
            "Epoch 36/40\n",
            "3021/3021 [==============================] - 198s 66ms/step - loss: 0.4403 - accuracy: 0.8806 - val_loss: 0.4821 - val_accuracy: 0.8736\n",
            "Epoch 37/40\n",
            "3021/3021 [==============================] - 198s 66ms/step - loss: 0.4386 - accuracy: 0.8812 - val_loss: 0.4818 - val_accuracy: 0.8735\n",
            "Epoch 38/40\n",
            "3021/3021 [==============================] - 199s 66ms/step - loss: 0.4373 - accuracy: 0.8814 - val_loss: 0.4790 - val_accuracy: 0.8745\n",
            "Epoch 39/40\n",
            "3021/3021 [==============================] - 199s 66ms/step - loss: 0.4349 - accuracy: 0.8818 - val_loss: 0.4791 - val_accuracy: 0.8740\n",
            "Epoch 40/40\n",
            "3021/3021 [==============================] - 198s 66ms/step - loss: 0.4331 - accuracy: 0.8827 - val_loss: 0.4772 - val_accuracy: 0.8742\n",
            "6254/6254 [==============================] - 166s 27ms/step - loss: 0.4825 - accuracy: 0.8737\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-04-10 05:33:41,078]\u001b[0m Trial 0 finished with value: 0.8736725449562073 and parameters: {'optimizer': 'Adam', 'epochs': 40, 'batchsize': 212, 'learning_rate': 7.78698432607108e-05}. Best is trial 0 with value: 0.8736725449562073.\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Epoch 1/40\n",
            "2417/2417 [==============================] - 172s 68ms/step - loss: 2.2488 - accuracy: 0.4967 - val_loss: 1.2906 - val_accuracy: 0.6931\n",
            "Epoch 2/40\n",
            "2417/2417 [==============================] - 167s 69ms/step - loss: 1.2436 - accuracy: 0.6983 - val_loss: 1.0088 - val_accuracy: 0.7569\n",
            "Epoch 3/40\n",
            "2417/2417 [==============================] - 166s 69ms/step - loss: 1.0302 - accuracy: 0.7487 - val_loss: 0.8959 - val_accuracy: 0.7833\n",
            "Epoch 4/40\n",
            "2417/2417 [==============================] - 166s 69ms/step - loss: 0.9225 - accuracy: 0.7740 - val_loss: 0.8308 - val_accuracy: 0.7988\n",
            "Epoch 5/40\n",
            "2417/2417 [==============================] - 165s 68ms/step - loss: 0.8534 - accuracy: 0.7901 - val_loss: 0.7811 - val_accuracy: 0.8090\n",
            "Epoch 6/40\n",
            "2417/2417 [==============================] - 165s 68ms/step - loss: 0.8043 - accuracy: 0.8021 - val_loss: 0.7475 - val_accuracy: 0.8173\n",
            "Epoch 7/40\n",
            "2417/2417 [==============================] - 165s 68ms/step - loss: 0.7690 - accuracy: 0.8105 - val_loss: 0.7237 - val_accuracy: 0.8223\n",
            "Epoch 8/40\n",
            "2417/2417 [==============================] - 166s 69ms/step - loss: 0.7391 - accuracy: 0.8179 - val_loss: 0.7024 - val_accuracy: 0.8282\n",
            "Epoch 9/40\n",
            "2417/2417 [==============================] - 166s 69ms/step - loss: 0.7163 - accuracy: 0.8232 - val_loss: 0.6862 - val_accuracy: 0.8313\n",
            "Epoch 10/40\n",
            "2417/2417 [==============================] - 166s 69ms/step - loss: 0.6966 - accuracy: 0.8280 - val_loss: 0.6738 - val_accuracy: 0.8349\n",
            "Epoch 11/40\n",
            "2417/2417 [==============================] - 166s 69ms/step - loss: 0.6806 - accuracy: 0.8321 - val_loss: 0.6605 - val_accuracy: 0.8369\n",
            "Epoch 12/40\n",
            "2417/2417 [==============================] - 166s 68ms/step - loss: 0.6665 - accuracy: 0.8359 - val_loss: 0.6492 - val_accuracy: 0.8401\n",
            "Epoch 13/40\n",
            "2417/2417 [==============================] - 166s 69ms/step - loss: 0.6549 - accuracy: 0.8384 - val_loss: 0.6408 - val_accuracy: 0.8421\n",
            "Epoch 14/40\n",
            "2417/2417 [==============================] - 166s 69ms/step - loss: 0.6430 - accuracy: 0.8410 - val_loss: 0.6335 - val_accuracy: 0.8439\n",
            "Epoch 15/40\n",
            "2417/2417 [==============================] - 166s 69ms/step - loss: 0.6339 - accuracy: 0.8433 - val_loss: 0.6260 - val_accuracy: 0.8458\n",
            "Epoch 16/40\n",
            "2417/2417 [==============================] - 166s 69ms/step - loss: 0.6246 - accuracy: 0.8455 - val_loss: 0.6199 - val_accuracy: 0.8473\n",
            "Epoch 17/40\n",
            "2417/2417 [==============================] - 167s 69ms/step - loss: 0.6177 - accuracy: 0.8470 - val_loss: 0.6148 - val_accuracy: 0.8487\n",
            "Epoch 18/40\n",
            "2417/2417 [==============================] - 166s 69ms/step - loss: 0.6099 - accuracy: 0.8490 - val_loss: 0.6069 - val_accuracy: 0.8496\n",
            "Epoch 19/40\n",
            "2417/2417 [==============================] - 165s 68ms/step - loss: 0.6051 - accuracy: 0.8502 - val_loss: 0.6050 - val_accuracy: 0.8508\n",
            "Epoch 20/40\n",
            "2417/2417 [==============================] - 166s 69ms/step - loss: 0.5989 - accuracy: 0.8516 - val_loss: 0.5989 - val_accuracy: 0.8521\n",
            "Epoch 21/40\n",
            "2417/2417 [==============================] - 164s 68ms/step - loss: 0.5934 - accuracy: 0.8529 - val_loss: 0.5969 - val_accuracy: 0.8525\n",
            "Epoch 22/40\n",
            "2417/2417 [==============================] - 167s 69ms/step - loss: 0.5889 - accuracy: 0.8541 - val_loss: 0.5946 - val_accuracy: 0.8533\n",
            "Epoch 23/40\n",
            "2417/2417 [==============================] - 167s 69ms/step - loss: 0.5835 - accuracy: 0.8553 - val_loss: 0.5855 - val_accuracy: 0.8542\n",
            "Epoch 24/40\n",
            "2417/2417 [==============================] - 166s 69ms/step - loss: 0.5793 - accuracy: 0.8561 - val_loss: 0.5841 - val_accuracy: 0.8548\n",
            "Epoch 25/40\n",
            "2417/2417 [==============================] - 164s 68ms/step - loss: 0.5747 - accuracy: 0.8573 - val_loss: 0.5827 - val_accuracy: 0.8557\n",
            "Epoch 26/40\n",
            "2417/2417 [==============================] - 166s 69ms/step - loss: 0.5720 - accuracy: 0.8582 - val_loss: 0.5781 - val_accuracy: 0.8572\n",
            "Epoch 27/40\n",
            "2417/2417 [==============================] - 165s 68ms/step - loss: 0.5685 - accuracy: 0.8587 - val_loss: 0.5774 - val_accuracy: 0.8573\n",
            "Epoch 28/40\n",
            "2417/2417 [==============================] - 164s 68ms/step - loss: 0.5650 - accuracy: 0.8598 - val_loss: 0.5767 - val_accuracy: 0.8579\n",
            "Epoch 29/40\n",
            "2417/2417 [==============================] - 164s 68ms/step - loss: 0.5608 - accuracy: 0.8610 - val_loss: 0.5690 - val_accuracy: 0.8584\n",
            "Epoch 30/40\n",
            "2417/2417 [==============================] - 163s 68ms/step - loss: 0.5584 - accuracy: 0.8612 - val_loss: 0.5685 - val_accuracy: 0.8589\n",
            "Epoch 31/40\n",
            "2417/2417 [==============================] - 163s 68ms/step - loss: 0.5554 - accuracy: 0.8619 - val_loss: 0.5659 - val_accuracy: 0.8595\n",
            "Epoch 32/40\n",
            "2417/2417 [==============================] - 164s 68ms/step - loss: 0.5515 - accuracy: 0.8628 - val_loss: 0.5638 - val_accuracy: 0.8602\n",
            "Epoch 33/40\n",
            "2417/2417 [==============================] - 164s 68ms/step - loss: 0.5492 - accuracy: 0.8628 - val_loss: 0.5624 - val_accuracy: 0.8606\n",
            "Epoch 34/40\n",
            "2417/2417 [==============================] - 163s 68ms/step - loss: 0.5472 - accuracy: 0.8635 - val_loss: 0.5600 - val_accuracy: 0.8612\n",
            "Epoch 35/40\n",
            "2417/2417 [==============================] - 163s 67ms/step - loss: 0.5452 - accuracy: 0.8642 - val_loss: 0.5578 - val_accuracy: 0.8618\n",
            "Epoch 36/40\n",
            "2417/2417 [==============================] - 163s 67ms/step - loss: 0.5435 - accuracy: 0.8641 - val_loss: 0.5555 - val_accuracy: 0.8619\n",
            "Epoch 37/40\n",
            "2417/2417 [==============================] - 163s 68ms/step - loss: 0.5407 - accuracy: 0.8651 - val_loss: 0.5561 - val_accuracy: 0.8621\n",
            "Epoch 38/40\n",
            "2417/2417 [==============================] - 163s 67ms/step - loss: 0.5388 - accuracy: 0.8658 - val_loss: 0.5546 - val_accuracy: 0.8625\n",
            "Epoch 39/40\n",
            "2417/2417 [==============================] - 164s 68ms/step - loss: 0.5372 - accuracy: 0.8662 - val_loss: 0.5492 - val_accuracy: 0.8631\n",
            "Epoch 40/40\n",
            "2417/2417 [==============================] - 164s 68ms/step - loss: 0.5350 - accuracy: 0.8670 - val_loss: 0.5492 - val_accuracy: 0.8634\n",
            "6254/6254 [==============================] - 164s 26ms/step - loss: 0.5493 - accuracy: 0.8643\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-04-10 07:26:36,718]\u001b[0m Trial 1 finished with value: 0.8642522096633911 and parameters: {'optimizer': 'RMSprop', 'epochs': 40, 'batchsize': 265, 'learning_rate': 4.479056506795051e-05}. Best is trial 0 with value: 0.8736725449562073.\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Epoch 1/30\n",
            "4028/4028 [==============================] - 276s 67ms/step - loss: 2.1424 - accuracy: 0.5180 - val_loss: 1.2487 - val_accuracy: 0.6994\n",
            "Epoch 2/30\n",
            "4028/4028 [==============================] - 267s 66ms/step - loss: 1.2161 - accuracy: 0.7005 - val_loss: 0.9828 - val_accuracy: 0.7573\n",
            "Epoch 3/30\n",
            "4028/4028 [==============================] - 268s 67ms/step - loss: 1.0012 - accuracy: 0.7495 - val_loss: 0.8638 - val_accuracy: 0.7829\n",
            "Epoch 4/30\n",
            "4028/4028 [==============================] - 268s 67ms/step - loss: 0.8881 - accuracy: 0.7756 - val_loss: 0.7923 - val_accuracy: 0.7995\n",
            "Epoch 5/30\n",
            "4028/4028 [==============================] - 268s 67ms/step - loss: 0.8157 - accuracy: 0.7927 - val_loss: 0.7442 - val_accuracy: 0.8111\n",
            "Epoch 6/30\n",
            "4028/4028 [==============================] - 268s 66ms/step - loss: 0.7657 - accuracy: 0.8043 - val_loss: 0.7101 - val_accuracy: 0.8198\n",
            "Epoch 7/30\n",
            "4028/4028 [==============================] - 269s 67ms/step - loss: 0.7264 - accuracy: 0.8139 - val_loss: 0.6844 - val_accuracy: 0.8250\n",
            "Epoch 8/30\n",
            "4028/4028 [==============================] - 269s 67ms/step - loss: 0.6970 - accuracy: 0.8208 - val_loss: 0.6591 - val_accuracy: 0.8309\n",
            "Epoch 9/30\n",
            "4028/4028 [==============================] - 269s 67ms/step - loss: 0.6718 - accuracy: 0.8266 - val_loss: 0.6447 - val_accuracy: 0.8348\n",
            "Epoch 10/30\n",
            "4028/4028 [==============================] - 267s 66ms/step - loss: 0.6509 - accuracy: 0.8317 - val_loss: 0.6272 - val_accuracy: 0.8387\n",
            "Epoch 11/30\n",
            "4028/4028 [==============================] - 268s 67ms/step - loss: 0.6328 - accuracy: 0.8361 - val_loss: 0.6151 - val_accuracy: 0.8413\n",
            "Epoch 12/30\n",
            "4028/4028 [==============================] - 269s 67ms/step - loss: 0.6198 - accuracy: 0.8390 - val_loss: 0.6048 - val_accuracy: 0.8437\n",
            "Epoch 13/30\n",
            "4028/4028 [==============================] - 269s 67ms/step - loss: 0.6064 - accuracy: 0.8422 - val_loss: 0.5954 - val_accuracy: 0.8462\n",
            "Epoch 14/30\n",
            "4028/4028 [==============================] - 268s 67ms/step - loss: 0.5954 - accuracy: 0.8444 - val_loss: 0.5877 - val_accuracy: 0.8469\n",
            "Epoch 15/30\n",
            "4028/4028 [==============================] - 270s 67ms/step - loss: 0.5849 - accuracy: 0.8471 - val_loss: 0.5788 - val_accuracy: 0.8490\n",
            "Epoch 16/30\n",
            "4028/4028 [==============================] - 271s 67ms/step - loss: 0.5762 - accuracy: 0.8489 - val_loss: 0.5724 - val_accuracy: 0.8511\n",
            "Epoch 17/30\n",
            "4028/4028 [==============================] - 272s 67ms/step - loss: 0.5675 - accuracy: 0.8510 - val_loss: 0.5652 - val_accuracy: 0.8522\n",
            "Epoch 18/30\n",
            "4028/4028 [==============================] - 272s 67ms/step - loss: 0.5607 - accuracy: 0.8527 - val_loss: 0.5610 - val_accuracy: 0.8532\n",
            "Epoch 19/30\n",
            "4028/4028 [==============================] - 271s 67ms/step - loss: 0.5543 - accuracy: 0.8543 - val_loss: 0.5565 - val_accuracy: 0.8541\n",
            "Epoch 20/30\n",
            "4028/4028 [==============================] - 272s 68ms/step - loss: 0.5474 - accuracy: 0.8562 - val_loss: 0.5535 - val_accuracy: 0.8549\n",
            "Epoch 21/30\n",
            "4028/4028 [==============================] - 271s 67ms/step - loss: 0.5420 - accuracy: 0.8573 - val_loss: 0.5496 - val_accuracy: 0.8561\n",
            "Epoch 22/30\n",
            "4028/4028 [==============================] - 270s 67ms/step - loss: 0.5362 - accuracy: 0.8588 - val_loss: 0.5442 - val_accuracy: 0.8571\n",
            "Epoch 23/30\n",
            "4028/4028 [==============================] - 269s 67ms/step - loss: 0.5319 - accuracy: 0.8596 - val_loss: 0.5399 - val_accuracy: 0.8577\n",
            "Epoch 24/30\n",
            "4028/4028 [==============================] - 270s 67ms/step - loss: 0.5268 - accuracy: 0.8608 - val_loss: 0.5369 - val_accuracy: 0.8590\n",
            "Epoch 25/30\n",
            "4028/4028 [==============================] - 268s 67ms/step - loss: 0.5229 - accuracy: 0.8617 - val_loss: 0.5342 - val_accuracy: 0.8597\n",
            "Epoch 26/30\n",
            "4028/4028 [==============================] - 267s 66ms/step - loss: 0.5187 - accuracy: 0.8626 - val_loss: 0.5319 - val_accuracy: 0.8605\n",
            "Epoch 27/30\n",
            "4028/4028 [==============================] - 271s 67ms/step - loss: 0.5152 - accuracy: 0.8636 - val_loss: 0.5278 - val_accuracy: 0.8602\n",
            "Epoch 28/30\n",
            "4028/4028 [==============================] - 269s 67ms/step - loss: 0.5124 - accuracy: 0.8641 - val_loss: 0.5273 - val_accuracy: 0.8614\n",
            "Epoch 29/30\n",
            "4028/4028 [==============================] - 267s 66ms/step - loss: 0.5084 - accuracy: 0.8651 - val_loss: 0.5241 - val_accuracy: 0.8616\n",
            "Epoch 30/30\n",
            "4028/4028 [==============================] - 268s 67ms/step - loss: 0.5046 - accuracy: 0.8662 - val_loss: 0.5208 - val_accuracy: 0.8622\n",
            "6254/6254 [==============================] - 165s 26ms/step - loss: 0.5206 - accuracy: 0.8631\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-04-10 09:44:08,516]\u001b[0m Trial 2 finished with value: 0.8631227612495422 and parameters: {'optimizer': 'Adam', 'epochs': 30, 'batchsize': 159, 'learning_rate': 3.2453255738491435e-05}. Best is trial 0 with value: 0.8736725449562073.\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Epoch 1/50\n",
            "4028/4028 [==============================] - 283s 68ms/step - loss: 2.2808 - accuracy: 0.4872 - val_loss: 1.3802 - val_accuracy: 0.6813\n",
            "Epoch 2/50\n",
            "4028/4028 [==============================] - 277s 69ms/step - loss: 1.3178 - accuracy: 0.6863 - val_loss: 1.0667 - val_accuracy: 0.7508\n",
            "Epoch 3/50\n",
            "4028/4028 [==============================] - 280s 69ms/step - loss: 1.0850 - accuracy: 0.7411 - val_loss: 0.9391 - val_accuracy: 0.7789\n",
            "Epoch 4/50\n",
            "4028/4028 [==============================] - 278s 69ms/step - loss: 0.9710 - accuracy: 0.7675 - val_loss: 0.8662 - val_accuracy: 0.7919\n",
            "Epoch 5/50\n",
            "4028/4028 [==============================] - 280s 69ms/step - loss: 0.8977 - accuracy: 0.7847 - val_loss: 0.8217 - val_accuracy: 0.8040\n",
            "Epoch 6/50\n",
            "4028/4028 [==============================] - 278s 69ms/step - loss: 0.8476 - accuracy: 0.7962 - val_loss: 0.7837 - val_accuracy: 0.8119\n",
            "Epoch 7/50\n",
            "4028/4028 [==============================] - 279s 69ms/step - loss: 0.8100 - accuracy: 0.8050 - val_loss: 0.7548 - val_accuracy: 0.8180\n",
            "Epoch 8/50\n",
            "4028/4028 [==============================] - 280s 70ms/step - loss: 0.7776 - accuracy: 0.8124 - val_loss: 0.7318 - val_accuracy: 0.8232\n",
            "Epoch 9/50\n",
            "4028/4028 [==============================] - 266s 66ms/step - loss: 0.7537 - accuracy: 0.8186 - val_loss: 0.7162 - val_accuracy: 0.8272\n",
            "Epoch 10/50\n",
            "4028/4028 [==============================] - 261s 65ms/step - loss: 0.7353 - accuracy: 0.8230 - val_loss: 0.6990 - val_accuracy: 0.8308\n",
            "Epoch 11/50\n",
            "4028/4028 [==============================] - 258s 64ms/step - loss: 0.7171 - accuracy: 0.8267 - val_loss: 0.6893 - val_accuracy: 0.8326\n",
            "Epoch 12/50\n",
            "4028/4028 [==============================] - 261s 65ms/step - loss: 0.7029 - accuracy: 0.8303 - val_loss: 0.6771 - val_accuracy: 0.8356\n",
            "Epoch 13/50\n",
            "4028/4028 [==============================] - 258s 64ms/step - loss: 0.6901 - accuracy: 0.8333 - val_loss: 0.6698 - val_accuracy: 0.8374\n",
            "Epoch 14/50\n",
            "4028/4028 [==============================] - 256s 64ms/step - loss: 0.6787 - accuracy: 0.8357 - val_loss: 0.6606 - val_accuracy: 0.8397\n",
            "Epoch 15/50\n",
            "3049/4028 [=====================>........] - ETA: 57s - loss: 0.6709 - accuracy: 0.8378"
          ]
        }
      ],
      "source": [
        "import optuna\n",
        "from optuna.trial import TrialState\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "def objective(trial):\n",
        "    x_tri, X_val, y_tri, y_val = train_test_split(X_train,y_train, test_size=0.2, shuffle=False)\n",
        "    params = {\n",
        "    'optimizer_name' : trial.suggest_categorical(\"optimizer\", [\"Adam\",\"RMSprop\"]),\n",
        "    'epochs' : trial.suggest_int(\"epochs\", 30, 60,step=10),\n",
        "    'batchsize' : trial.suggest_int(\"batchsize\", max_len, 8*max_len,step=max_len),\n",
        "    'learning_rate' : trial.suggest_uniform('learning_rate',0.00001,0.0001),\n",
        "    #'recurrent_dropout' : trial.suggest_float('recurrent_dropout',0.1,0.7,step=0.1),\n",
        "    #'dropout' : trial.suggest_float('dropout',0.1,0.7,step=0.1),\n",
        "    }\n",
        "    model = build_cnn_lstm2()\n",
        "    \n",
        "    if params['optimizer_name'] == \"Adam\":\n",
        "        optimizer = tf.keras.optimizers.Adam(learning_rate = params['learning_rate'])\n",
        "    else :\n",
        "        optimizer = tf.keras.optimizers.RMSprop(learning_rate = params['learning_rate'])\n",
        "    \n",
        "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "    callbacks = [EarlyStopping(monitor='val_loss', patience=10)]\n",
        "    history = model.fit(x_tri,y_tri,\n",
        "                epochs=params['epochs'],callbacks=callbacks,\n",
        "              batch_size = params['batchsize'], validation_split = 0.2,verbose=1)\n",
        "    \n",
        "    val_acc = model.evaluate(X_val,y_val)[1]\n",
        "    weights = model.get_weights()\n",
        "    # Handle pruning based on the intermediate value.\n",
        "    if trial.should_prune():\n",
        "        raise optuna.exceptions.TrialPruned()\n",
        "\n",
        "    trial.set_user_attr(key=\"best_model_weights\", value=weights)\n",
        "    return val_acc\n",
        "\n",
        "def callback(study, trial):\n",
        "    if study.best_trial.number == trial.number:\n",
        "        study.set_user_attr(key=\"best_model_weights\", \n",
        "                            value=trial.user_attrs[\"best_model_weights\"])\n",
        "\n",
        "study = optuna.create_study(direction=\"maximize\",sampler=optuna.samplers.TPESampler())\n",
        "study.optimize(objective, n_trials=20, timeout=None, callbacks=[callback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lpQbRLeZ6qBd"
      },
      "outputs": [],
      "source": [
        "best_params = study.best_trial.params\n",
        "print(f\"Best trial :{study.best_trial.value}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9YyjkCqu6qBd"
      },
      "outputs": [],
      "source": [
        "model = build_cnn_lstm2()\n",
        "\n",
        "if best_params['optimizer_name'] == \"Adam\":\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate = best_params['learning_rate'])\n",
        "else :\n",
        "    optimizer = tf.keras.optimizers.RMSprop(learning_rate = best_params['learning_rate'])\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "callbacks = [EarlyStopping(monitor='val_loss', patience=10)]\n",
        "history = model.fit(x_tri,y_tri, epochs=best_params['epochs'],callbacks=callbacks,batch_size = best_params['batchsize'], validation_split = 0.2,verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XgowyGUg6qBd"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.title('Loss')\n",
        "plt.plot(history.history['loss'], label='train')\n",
        "plt.plot(history.history['val_loss'], label='test')\n",
        "plt.legend()\n",
        "plt.show();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bjb2rYDi6qBd"
      },
      "outputs": [],
      "source": [
        "plt.title('Accuracy')\n",
        "plt.plot(history.history['accuracy'], label='train')\n",
        "plt.plot(history.history['val_accuracy'], label='test')\n",
        "plt.legend()\n",
        "plt.show();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwMGOQZS6qBd"
      },
      "source": [
        "# test padding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O2G0vH9R6qBd"
      },
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(test)\n",
        "X_encoded = tokenizer.texts_to_sequences(test)\n",
        "#print('정수 인코딩 결과 :',X_encoded.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bjTOSvnH6qBd"
      },
      "outputs": [],
      "source": [
        "X_test = pad_sequences(X_encoded, maxlen=max_len, padding='post')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QRLaw3NR96eX",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "y_pred = model.predict(X_test)\n",
        "predicted = y_pred.argmax(axis=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "WkpfXEab6qBe"
      },
      "outputs": [],
      "source": [
        "digit_1_index = [1.0, 5.0, 10.0, 35.0, 36.0, 41.0, 45.0, 49.0, 55.0, 58.0, 64.0, 68.0, 70.0, 74.0, 84.0, 85.0, 86.0, 90.0, 94.0, 97.0, 99.0]\n",
        "digit_1_value = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M','N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U']\n",
        "\n",
        "dsa = [ i for i in range(100)]\n",
        "def search_digit_1(i):\n",
        "    ans = 0\n",
        "    if i <=digit_1_index[0]:\n",
        "        ans = digit_1_value[0]\n",
        "    elif i <=digit_1_index[1]:\n",
        "        ans=digit_1_value[1]\n",
        "    elif i <=digit_1_index[2]:\n",
        "        ans=digit_1_value[2]\n",
        "\n",
        "    elif i <=digit_1_index[3]:\n",
        "        ans=digit_1_value[3]\n",
        "    elif i <=digit_1_index[4]:\n",
        "        ans=digit_1_value[4]\n",
        "\n",
        "    elif i <=digit_1_index[5]:\n",
        "        ans=digit_1_value[5]\n",
        "    elif i <=digit_1_index[6]:\n",
        "        ans=digit_1_value[6]\n",
        "\n",
        "    elif i <=digit_1_index[7]:\n",
        "        ans=digit_1_value[7]\n",
        "    elif i <=digit_1_index[8]:\n",
        "        ans=digit_1_value[8]\n",
        "    elif i <=digit_1_index[9]:\n",
        "        ans=digit_1_value[9]\n",
        "    elif i <=digit_1_index[10]:\n",
        "        ans=digit_1_value[10]\n",
        "    elif i <=digit_1_index[11]:\n",
        "        ans=digit_1_value[11]\n",
        "\n",
        "    elif i <=digit_1_index[12]:\n",
        "        ans=digit_1_value[12]\n",
        "    elif i <=digit_1_index[13]:\n",
        "        ans=digit_1_value[13]\n",
        "\n",
        "    elif i <=digit_1_index[14]:\n",
        "        ans=digit_1_value[14]\n",
        "    elif i <=digit_1_index[15]:\n",
        "        ans=digit_1_value[15]\n",
        "\n",
        "    elif i <=digit_1_index[16]:\n",
        "        ans=digit_1_value[16]\n",
        "    elif i <=digit_1_index[17]:\n",
        "        ans=digit_1_value[17]\n",
        "\n",
        "    elif i <=digit_1_index[18]:\n",
        "        ans=digit_1_value[18]\n",
        "    elif i <=digit_1_index[19]:\n",
        "        ans=digit_1_value[19]\n",
        "\n",
        "    elif i <=digit_1_index[20]:\n",
        "        ans=digit_1_value[20]\n",
        "    return ans"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BEb5dabD6qBe"
      },
      "outputs": [],
      "source": [
        "for i in range(len(predicted)):\n",
        "    if len(i) == 2:\n",
        "        submission['digit_3'][i] = int(labels[predicted[i]])\n",
        "        submission['digit_2'][i] = int(labels[predicted[i]][0])\n",
        "        submission['digit_1'][i] = search_digit_1(int(labels[predicted[i]][0]))\n",
        "    submission['digit_3'][i] = int(labels[predicted[i]])\n",
        "    submission['digit_2'][i] = int(labels[predicted[i]][:2])\n",
        "    submission['digit_1'][i] = search_digit_1(int(labels[predicted[i]][0])\n",
        "submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j8_gcV5j6qBe"
      },
      "outputs": [],
      "source": [
        "submission[['digit_2','digit_3']] = submission[['digit_2','digit_3']].astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-BIiuV3i-If4"
      },
      "outputs": [],
      "source": [
        "submission.to_csv('C:/Users/SEO/OneDrive - 숭실대학교 - Soongsil University/바탕 화면/통계청 ai 경진대회/final/data/sub1_optuna.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bVQoJoCh6qBe",
        "outputId": "85d5596c-ddfe-44f1-fdc1-18a74a4cb7ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.utils import plot_model\n",
        "plot_model(model)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "pca-model (영석 하이퍼파라미터).ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
