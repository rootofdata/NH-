{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rootofdata/kostat_AI_contest/blob/main/model1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwZgHJgDBdWd"
      },
      "source": [
        "# 256->512 ver. CNN-LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_UetIdNBdWq",
        "outputId": "a9195e9b-1ca3-4087-a807-10934a05f0ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (3.6.0)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.21.5)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.4.1)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (5.2.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "BMYM8ptUBdWx",
        "outputId": "3cbf2b4d-b1f7-49e9-ed8e-0c586c152ae5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.8.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "tf.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQnhqHjzBdW0",
        "outputId": "eab829d1-deaf-4017-bf26-e5ebef24446a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From <ipython-input-3-db1e1abccb74>:3: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.config.list_physical_devices('GPU')` instead.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "device_lib.list_local_devices()\n",
        "tf.test.is_gpu_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JGNdUrmhBdW2",
        "outputId": "9221b2ca-944c-4af7-99ff-cc345a7ace44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[name: \"/device:CPU:0\"\n",
            "device_type: \"CPU\"\n",
            "memory_limit: 268435456\n",
            "locality {\n",
            "}\n",
            "incarnation: 13232326648598519757\n",
            "xla_global_id: -1\n",
            ", name: \"/device:GPU:0\"\n",
            "device_type: \"GPU\"\n",
            "memory_limit: 11320098816\n",
            "locality {\n",
            "  bus_id: 1\n",
            "  links {\n",
            "  }\n",
            "}\n",
            "incarnation: 9238608986752740057\n",
            "physical_device_desc: \"device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7\"\n",
            "xla_global_id: 416903419\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "\n",
        "print(device_lib.list_local_devices())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yDTA2wLCkx1P"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IEEjEQugjjUt"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from gensim.models import word2vec\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rttwJXTfEFO3"
      },
      "source": [
        "# 함수 및 데이터 로드"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yw9wEXBymBYw"
      },
      "outputs": [],
      "source": [
        "def compute_pca(X: np.ndarray, n_components: int=2) -> np.ndarray:\n",
        "    \"\"\"Calculate the principal components for X\n",
        "\n",
        "    Args:\n",
        "       X: of dimension (m,n) where each row corresponds to a word vector\n",
        "       n_components: Number of components you want to keep.\n",
        "\n",
        "    Return:\n",
        "       X_reduced: data transformed in 2 dims/columns + regenerated original data\n",
        "    \"\"\"\n",
        "    # you need to set axis to 0 or it will calculate the mean of the entire matrix instead of one per row\n",
        "    X_demeaned = X - X.mean(axis=0)\n",
        "\n",
        "    # calculate the covariance matrix\n",
        "    # the default np.cov assumes the rows are variables, not columns so set rowvar to False\n",
        "    covariance_matrix = np.cov(X_demeaned, rowvar=False)\n",
        "\n",
        "    # calculate eigenvectors & eigenvalues of the covariance matrix\n",
        "    eigen_vals, eigen_vecs = np.linalg.eigh(covariance_matrix)\n",
        "\n",
        "    # sort eigenvalue in increasing order (get the indices from the sort)\n",
        "    idx_sorted = np.argsort(eigen_vals)\n",
        "\n",
        "    # reverse the order so that it's from highest to lowest.\n",
        "    idx_sorted_decreasing = list(reversed(idx_sorted))\n",
        "\n",
        "    # sort the eigen values by idx_sorted_decreasing\n",
        "    eigen_vals_sorted = eigen_vals[idx_sorted_decreasing]\n",
        "\n",
        "    # sort eigenvectors using the idx_sorted_decreasing indices\n",
        "    # We're only sorting the columns so remember to get all the rows in the slice\n",
        "    eigen_vecs_sorted = eigen_vecs[:, idx_sorted_decreasing]\n",
        "\n",
        "    # select the first n eigenvectors (n is desired dimension\n",
        "    # of rescaled data array, or dims_rescaled_data)\n",
        "    # once again, make sure to get all the rows and only slice the columns\n",
        "    eigen_vecs_subset = eigen_vecs_sorted[:, :n_components]\n",
        "\n",
        "    # transform the data by multiplying the transpose of the eigenvectors \n",
        "    # with the transpose of the de-meaned data\n",
        "    # Then take the transpose of that product.\n",
        "    X_reduced = np.dot(eigen_vecs_subset.T, X_demeaned.T).T\n",
        "    return X_reduced"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Iky1oa5lx-Z"
      },
      "outputs": [],
      "source": [
        "def get_vector(word):\n",
        "    if word in word2vec_model:\n",
        "        return word2vec_model[word]\n",
        "    else:\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lctC7Hu3Bqgm",
        "outputId": "c9ee70ab-9aa8-4f3f-e1f5-c1063acba301"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yJKQjm2ajufW"
      },
      "outputs": [],
      "source": [
        "# train = pd.read_csv('/content/drive/MyDrive/통계청_AI경진대회/final/data/bigword_split_okt2_remove_stopword_8_4')\n",
        "# test = pd.read_csv('/content/drive/MyDrive/통계청_AI경진대회/final/data/tok_sm8_2_with_remove_stopword')\n",
        "word2vec_model = word2vec.Word2Vec.load('/content/drive/MyDrive/통계청_AI경진대회/final/data/train_final.model2')\n",
        "word2vec_model = word2vec_model.wv\n",
        "submission = pd.read_csv('/content/drive/MyDrive/통계청_AI경진대회/모델 개발용 자료/모델 개발용 자료.csv',header = 1)\n",
        "data = pd.read_csv('/content/drive/MyDrive/통계청_AI경진대회/실습용 자료/실습용 자료.csv',header = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F3EtSp-xkPwv"
      },
      "outputs": [],
      "source": [
        "train = []\n",
        "with open('/content/drive/MyDrive/통계청_AI경진대회/final/data/train_final2','rb') as f:\n",
        "    train = pickle.load(f)\n",
        "max_len = max(len(l) for l in train)\n",
        "\n",
        "test = []\n",
        "with open('/content/drive/MyDrive/통계청_AI경진대회/final/data/submission_final2','rb') as f:\n",
        "    test = pickle.load(f)\n",
        "max_len2 = max(len(l) for l in test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DO8hH_K9kpfG",
        "outputId": "dc48c5ec-8814-43d2-f6a8-29b0eb9f1a70"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(53, 49)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "max_len, max_len2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4DYK3aq71Jf3"
      },
      "source": [
        "# embedding Matrix-> pca"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tcPlspsg1ML2",
        "outputId": "43974b9e-2a0b-4875-998d-45b6c96a3b30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어 집합 : 37121\n"
          ]
        }
      ],
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(train)\n",
        "vocab_size = len(tokenizer.word_index) + 1 # 패딩을 고려하여 +1\n",
        "print('단어 집합 :',vocab_size)\n",
        "\n",
        "X_encoded = tokenizer.texts_to_sequences(train)\n",
        "#print('정수 인코딩 결과 :',X_encoded.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fsi7FYE08iYM"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open('/content/drive/MyDrive/통계청_AI경진대회/영석/a_495','rb') as f:\n",
        "    a_495 = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "sDvS3mD8BdXO",
        "outputId": "fa5ed389-76bb-4f1d-b09d-8b4283723c91"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     digit_3\n",
              "0        952\n",
              "1        472\n",
              "2        467\n",
              "3        475\n",
              "4        872\n",
              "..       ...\n",
              "490      969\n",
              "491      970\n",
              "492      981\n",
              "493      982\n",
              "494      990\n",
              "\n",
              "[1000495 rows x 1 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d80d220b-f8e0-4c36-8445-4aa817fd3427\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>digit_3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>952</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>472</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>467</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>475</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>872</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>490</th>\n",
              "      <td>969</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>491</th>\n",
              "      <td>970</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>492</th>\n",
              "      <td>981</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>493</th>\n",
              "      <td>982</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>494</th>\n",
              "      <td>990</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000495 rows × 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d80d220b-f8e0-4c36-8445-4aa817fd3427')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d80d220b-f8e0-4c36-8445-4aa817fd3427 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d80d220b-f8e0-4c36-8445-4aa817fd3427');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "a1=pd.DataFrame(data['digit_3'])\n",
        "a2=pd.DataFrame(a_495)\n",
        "y = pd.concat([a1 ,a2] )\n",
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17oaLYan1VQ2",
        "outputId": "a7c8c543-c90a-464b-cdab-8aa8e109e985"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['101' '102' '103' '104' '105' '106' '107' '108' '11' '111' '112' '12'\n",
            " '120' '13' '131' '132' '133' '134' '139' '14' '141' '142' '143' '144'\n",
            " '15' '151' '152' '161' '162' '163' '171' '172' '179' '181' '182' '191'\n",
            " '192' '20' '201' '202' '203' '204' '205' '211' '212' '213' '221' '222'\n",
            " '231' '232' '233' '239' '241' '242' '243' '251' '252' '259' '261' '262'\n",
            " '263' '264' '265' '266' '271' '272' '273' '274' '281' '282' '283' '284'\n",
            " '285' '289' '291' '292' '301' '302' '303' '304' '31' '311' '312' '313'\n",
            " '319' '32' '320' '331' '332' '333' '334' '339' '340' '351' '352' '353'\n",
            " '360' '370' '381' '382' '383' '390' '411' '412' '421' '422' '423' '424'\n",
            " '425' '426' '451' '452' '453' '461' '462' '463' '464' '465' '466' '467'\n",
            " '468' '471' '472' '473' '474' '475' '476' '477' '478' '479' '491' '492'\n",
            " '493' '494' '495' '501' '502' '51' '511' '512' '52' '521' '529' '551'\n",
            " '559' '561' '562' '581' '582' '591' '592' '601' '602' '61' '611' '612'\n",
            " '62' '620' '631' '639' '641' '642' '649' '651' '652' '653' '661' '662'\n",
            " '681' '682' '701' '702' '71' '711' '712' '713' '714' '715' '716' '72'\n",
            " '721' '729' '731' '732' '733' '739' '741' '742' '743' '751' '752' '753'\n",
            " '759' '761' '762' '763' '764' '80' '841' '842' '843' '844' '845' '851'\n",
            " '852' '853' '854' '855' '856' '857' '861' '862' '863' '869' '871' '872'\n",
            " '901' '902' '911' '912' '941' '942' '949' '951' '952' '953' '961' '969'\n",
            " '970' '981' '982' '990']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "import tensorflow as tf\n",
        "\n",
        "y_train = y.astype(str)\n",
        "\n",
        "le = LabelEncoder()\n",
        "le.fit(y_train)\n",
        "print(le.classes_)\n",
        "labels = le.classes_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vOx8adfTBdXP",
        "outputId": "c6312f39-1d52-417e-ae8e-26f28fc4165d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['101' '102' '103' '104' '105' '106' '107' '108' '11' '111' '112' '12'\n",
            " '120' '13' '131' '132' '133' '134' '139' '14' '141' '142' '143' '144'\n",
            " '15' '151' '152' '161' '162' '163' '171' '172' '179' '181' '182' '191'\n",
            " '192' '20' '201' '202' '203' '204' '205' '211' '212' '213' '221' '222'\n",
            " '231' '232' '233' '239' '241' '242' '243' '251' '252' '259' '261' '262'\n",
            " '263' '264' '265' '266' '271' '272' '273' '274' '281' '282' '283' '284'\n",
            " '285' '289' '291' '292' '301' '302' '303' '304' '31' '311' '312' '313'\n",
            " '319' '32' '320' '331' '332' '333' '334' '339' '340' '351' '352' '353'\n",
            " '360' '370' '381' '382' '383' '390' '411' '412' '421' '422' '423' '424'\n",
            " '425' '426' '451' '452' '453' '461' '462' '463' '464' '465' '466' '467'\n",
            " '468' '471' '472' '473' '474' '475' '476' '477' '478' '479' '491' '492'\n",
            " '493' '494' '495' '501' '502' '51' '511' '512' '52' '521' '529' '551'\n",
            " '559' '561' '562' '581' '582' '591' '592' '601' '602' '61' '611' '612'\n",
            " '62' '620' '631' '639' '641' '642' '649' '651' '652' '653' '661' '662'\n",
            " '681' '682' '701' '702' '71' '711' '712' '713' '714' '715' '716' '72'\n",
            " '721' '729' '731' '732' '733' '739' '741' '742' '743' '751' '752' '753'\n",
            " '759' '761' '762' '763' '764' '80' '841' '842' '843' '844' '845' '851'\n",
            " '852' '853' '854' '855' '856' '857' '861' '862' '863' '869' '871' '872'\n",
            " '901' '902' '911' '912' '941' '942' '949' '951' '952' '953' '961' '969'\n",
            " '970' '981' '982' '990']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1000495, 232)\n"
          ]
        }
      ],
      "source": [
        "print(labels)\n",
        "y_train = le.transform(y_train)\n",
        "y_train = tf.keras.utils.to_categorical(y_train)\n",
        "print(y_train.shape) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aRI2oQDI1acs",
        "outputId": "f6727b9f-74e4-4b3f-f1f2-c4a83f5f67f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "패딩 결과 :\n",
            "[[  92   18   87 ...    0    0    0]\n",
            " [1141  183  147 ...    0    0    0]\n",
            " [  38  462  331 ...    0    0    0]\n",
            " ...\n",
            " [3810  952 2807 ...    0    0    0]\n",
            " [3810  952 2807 ...    0    0    0]\n",
            " [1172 1220  368 ...    0    0    0]]\n",
            "y_train numclass (1000495, 232)\n"
          ]
        }
      ],
      "source": [
        "X_train = pad_sequences(X_encoded, maxlen=max_len, padding='post')\n",
        "print('패딩 결과 :')\n",
        "print(X_train)\n",
        "print('y_train numclass',y_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "utvDwoI-1e9c",
        "outputId": "08e57649-919d-4270-8b35-720981605d0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "임베딩 행렬의 크기(shape) : (37121, 100)\n"
          ]
        }
      ],
      "source": [
        "numclass = data['digit_3'].nunique()\n",
        "\n",
        "embedding_matrix = np.zeros((vocab_size, 100))\n",
        "print('임베딩 행렬의 크기(shape) :',np.shape(embedding_matrix))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uXixGTMY1lSf"
      },
      "outputs": [],
      "source": [
        "for word, index in tokenizer.word_index.items():\n",
        "    # 단어와 맵핑되는 사전 훈련된 임베딩 벡터값\n",
        "    vector_value = get_vector(word)\n",
        "    if vector_value is not None:\n",
        "        embedding_matrix[index] = vector_value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zzq1n6r2BdXS"
      },
      "source": [
        "## PCA 100 -> 50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UOJExvCV1pdM"
      },
      "outputs": [],
      "source": [
        "X = embedding_matrix\n",
        "X_reduced = compute_pca(X, n_components=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ymJy12crBdXT"
      },
      "outputs": [],
      "source": [
        "y_train = y_train.astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICUNuko7BdXT",
        "outputId": "08d501b4-2b5b-49d6-b7af-0d817dfd0792"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(37121, 50)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "X_reduced.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3teURNLKBdXU"
      },
      "source": [
        "# fine tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-rhG1VLTBdXU",
        "outputId": "cc79883f-73bc-4deb-9370-7dcd88a11d81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-2.10.0-py3-none-any.whl (308 kB)\n",
            "\u001b[K     |████████████████████████████████| 308 kB 4.1 MB/s \n",
            "\u001b[?25hCollecting cliff\n",
            "  Downloading cliff-3.10.1-py3-none-any.whl (81 kB)\n",
            "\u001b[K     |████████████████████████████████| 81 kB 9.8 MB/s \n",
            "\u001b[?25hCollecting cmaes>=0.8.2\n",
            "  Downloading cmaes-0.8.2-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: scipy!=1.4.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from optuna) (4.63.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.32)\n",
            "Collecting alembic\n",
            "  Downloading alembic-1.7.7-py3-none-any.whl (210 kB)\n",
            "\u001b[K     |████████████████████████████████| 210 kB 48.3 MB/s \n",
            "\u001b[?25hCollecting colorlog\n",
            "  Downloading colorlog-6.6.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (21.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from optuna) (1.21.5)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from optuna) (3.13)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->optuna) (3.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (1.1.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (4.11.3)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from alembic->optuna) (5.4.0)\n",
            "Collecting Mako\n",
            "  Downloading Mako-1.2.0-py3-none-any.whl (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 6.5 MB/s \n",
            "\u001b[?25hCollecting cmd2>=1.0.0\n",
            "  Downloading cmd2-2.4.0-py3-none-any.whl (150 kB)\n",
            "\u001b[K     |████████████████████████████████| 150 kB 50.6 MB/s \n",
            "\u001b[?25hCollecting autopage>=0.4.0\n",
            "  Downloading autopage-0.5.0-py3-none-any.whl (29 kB)\n",
            "Collecting stevedore>=2.0.1\n",
            "  Downloading stevedore-3.5.0-py3-none-any.whl (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 5.9 MB/s \n",
            "\u001b[?25hCollecting pbr!=2.1.0,>=2.0.0\n",
            "  Downloading pbr-5.8.1-py2.py3-none-any.whl (113 kB)\n",
            "\u001b[K     |████████████████████████████████| 113 kB 40.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (3.2.0)\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (21.4.0)\n",
            "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n",
            "Collecting pyperclip>=1.6\n",
            "  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (3.10.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->sqlalchemy>=1.1.0->optuna) (3.7.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic->optuna) (2.0.1)\n",
            "Building wheels for collected packages: pyperclip\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11137 sha256=0f9d03fea96b2ea85b259ebc2746efa4eb950b652852ac63d3c79f0ea24d4e95\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/18/84/8f69f8b08169c7bae2dde6bd7daf0c19fca8c8e500ee620a28\n",
            "Successfully built pyperclip\n",
            "Installing collected packages: pyperclip, pbr, stevedore, Mako, cmd2, autopage, colorlog, cmaes, cliff, alembic, optuna\n",
            "Successfully installed Mako-1.2.0 alembic-1.7.7 autopage-0.5.0 cliff-3.10.1 cmaes-0.8.2 cmd2-2.4.0 colorlog-6.6.0 optuna-2.10.0 pbr-5.8.1 pyperclip-1.8.2 stevedore-3.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dAJ_I_fs1uFU"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Input, Activation, Dropout, LSTM, Dense,Conv1D,MaxPooling1D,Embedding,Flatten\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import utils\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "def build_cnn_lstm2(recurrent_dropout = 0.5,dropout=0.5,):\n",
        "    with tf.device('/gpu:0'):\n",
        "        model = Sequential()\n",
        "\n",
        "        model.add(Input(shape=(max_len,)))\n",
        "        e = Embedding(vocab_size,output_dim =50,  weights=[X_reduced], input_length=max_len, trainable=False)\n",
        "        model.add(e)\n",
        "\n",
        "        model.add(Conv1D(filters=64, kernel_size=3, padding='same', activation='relu'))\n",
        "        model.add(MaxPooling1D(pool_size=2))\n",
        "        model.add(Dropout(dropout))\n",
        "\n",
        "        model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
        "        model.add(MaxPooling1D(pool_size=2))\n",
        "\n",
        "        model.add(LSTM(256, recurrent_dropout=recurrent_dropout,activation='tanh',kernel_initializer=\"he_normal\",unroll=True,return_sequences=True))\n",
        "        model.add(Dropout(dropout))\n",
        "\n",
        "        model.add(LSTM(512, recurrent_dropout=recurrent_dropout,activation='tanh',kernel_initializer=\"he_normal\",unroll=True))\n",
        "        model.add(Dropout(dropout))\n",
        "\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(y_train.shape[1], activation='softmax'))\n",
        "        # adam = tf.keras.optimizers.Adam(learning_rate = 1e-5)\n",
        "        \n",
        "\n",
        "        return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zEBQVkF6BdXV",
        "outputId": "3fceb900-27a7-4bff-9b7e-b54a3cf33f68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-04-10 15:15:14,383]\u001b[0m A new study created in memory with name: no-name-76ca2a6e-7436-4712-a1a0-3d2c454db498\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Epoch 1/40\n",
            "3905/6041 [==================>...........] - ETA: 2:25 - loss: 2.7532 - accuracy: 0.3828"
          ]
        }
      ],
      "source": [
        "import optuna\n",
        "from optuna.trial import TrialState\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "def objective(trial):\n",
        "    x_tri, X_val, y_tri, y_val = train_test_split(X_train,y_train, test_size=0.2, shuffle=False)\n",
        "    params = {\n",
        "    # 'optimizer_name' : trial.suggest_categorical(\"optimizer\", [\"Adam\",\"RMSprop\"]),\n",
        "    # 'epochs' : trial.suggest_int(\"epochs\", 30, 60,step=10),\n",
        "    # 'batchsize' : trial.suggest_int(\"batchsize\", max_len, 8*max_len,step=max_len),\n",
        "    'learning_rate' : trial.suggest_uniform('learning_rate',0.00001,0.0001),\n",
        "    'recurrent_dropout' : trial.suggest_float('recurrent_dropout',0.1,0.7,step=0.1),\n",
        "    'dropout' : trial.suggest_float('dropout',0.1,0.7,step=0.1)\n",
        "    }\n",
        "    model = build_cnn_lstm2(params['recurrent_dropout'],params['dropout'])\n",
        "    \n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate = params['learning_rate'])\n",
        "\n",
        "    \n",
        "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "    callbacks = [EarlyStopping(monitor='val_loss', patience=10)]\n",
        "    history = model.fit(x_tri,y_tri,\n",
        "                epochs=40,callbacks=callbacks,\n",
        "              batch_size = 106, validation_split = 0.2,verbose=1)\n",
        "    \n",
        "    val_acc = model.evaluate(X_val,y_val)[1]\n",
        "    weights = model.get_weights()\n",
        "    # Handle pruning based on the intermediate value.\n",
        "    if trial.should_prune():\n",
        "        raise optuna.exceptions.TrialPruned()\n",
        "\n",
        "    trial.set_user_attr(key=\"best_model_weights\", value=weights)\n",
        "    return val_acc\n",
        "\n",
        "def callback(study, trial):\n",
        "    if study.best_trial.number == trial.number:\n",
        "        study.set_user_attr(key=\"best_model_weights\", \n",
        "                            value=trial.user_attrs[\"best_model_weights\"])\n",
        "\n",
        "study = optuna.create_study(direction=\"maximize\",sampler=optuna.samplers.TPESampler())\n",
        "study.optimize(objective, n_trials=20, timeout=None, callbacks=[callback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GFDm3pmsBdXW",
        "outputId": "e0c33466-83e5-4d74-8ba0-41fcd131beea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best trial :0.8759114146232605\n"
          ]
        }
      ],
      "source": [
        "best_params = study.best_trial.params\n",
        "print(f\"Best trial :{study.best_trial.value}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9vigO9OrBdXW",
        "outputId": "6ff113b7-30c1-4b2a-9529-162a93fd2cdc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'optimizer': 'Adam',\n",
              " 'epochs': 40,\n",
              " 'batchsize': 53,\n",
              " 'learning_rate': 8.382620250945622e-05}"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QXejllFxBdXX",
        "outputId": "ba0a310a-1179-4b21-98e6-c838f98f1660"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_18 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_19 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Epoch 1/40\n",
            " 3015/15102 [====>.........................] - ETA: 11:46 - loss: 2.0122 - accuracy: 0.5416"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-47-f51b8d909070>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'categorical_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbest_params\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'epochs'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbest_params\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'batchsize'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1382\u001b[0m                 _r=1):\n\u001b[0;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1384\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1385\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    945\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    948\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2954\u001b[0m       (graph_function,\n\u001b[0;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2956\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2957\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2958\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1851\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1852\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1853\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1854\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 499\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    500\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "model = build_cnn_lstm2()\n",
        "\n",
        "if best_params['optimizer'] == \"Adam\":\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate = best_params['learning_rate'])\n",
        "else :\n",
        "    optimizer = tf.keras.optimizers.RMSprop(learning_rate = best_params['learning_rate'])\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "callbacks = [EarlyStopping(monitor='val_loss', patience=10)]\n",
        "history = model.fit(X_train,y_train, epochs=best_params['epochs'],callbacks=callbacks,batch_size = best_params['batchsize'],recurrent_dropout=best_params['recurrent_dropout'], validation_split = 0.2,verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "txrAu1UIBdXX"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.title('Loss')\n",
        "plt.plot(history.history['loss'], label='train')\n",
        "plt.plot(history.history['val_loss'], label='test')\n",
        "plt.legend()\n",
        "plt.show();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s4UW3ItwBdXY"
      },
      "outputs": [],
      "source": [
        "plt.title('Accuracy')\n",
        "plt.plot(history.history['accuracy'], label='train')\n",
        "plt.plot(history.history['val_accuracy'], label='test')\n",
        "plt.legend()\n",
        "plt.show();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xT6rjuLBdXY"
      },
      "source": [
        "# test padding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MM6L7bt8BdXZ"
      },
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(test)\n",
        "X_encoded = tokenizer.texts_to_sequences(test)\n",
        "#print('정수 인코딩 결과 :',X_encoded.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZBWWxnnQBdXZ"
      },
      "outputs": [],
      "source": [
        "X_test = pad_sequences(X_encoded, maxlen=max_len, padding='post')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QRLaw3NR96eX",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "y_pred = model.predict(X_test)\n",
        "predicted = y_pred.argmax(axis=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "karvKIepBdXZ"
      },
      "outputs": [],
      "source": [
        "digit_1_index = [1.0, 5.0, 10.0, 35.0, 36.0, 41.0, 45.0, 49.0, 55.0, 58.0, 64.0, 68.0, 70.0, 74.0, 84.0, 85.0, 86.0, 90.0, 94.0, 97.0, 99.0]\n",
        "digit_1_value = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M','N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U']\n",
        "\n",
        "dsa = [ i for i in range(100)]\n",
        "def search_digit_1(i):\n",
        "    ans = 0\n",
        "    if i <=digit_1_index[0]:\n",
        "        ans = digit_1_value[0]\n",
        "    elif i <=digit_1_index[1]:\n",
        "        ans=digit_1_value[1]\n",
        "    elif i <=digit_1_index[2]:\n",
        "        ans=digit_1_value[2]\n",
        "\n",
        "    elif i <=digit_1_index[3]:\n",
        "        ans=digit_1_value[3]\n",
        "    elif i <=digit_1_index[4]:\n",
        "        ans=digit_1_value[4]\n",
        "\n",
        "    elif i <=digit_1_index[5]:\n",
        "        ans=digit_1_value[5]\n",
        "    elif i <=digit_1_index[6]:\n",
        "        ans=digit_1_value[6]\n",
        "\n",
        "    elif i <=digit_1_index[7]:\n",
        "        ans=digit_1_value[7]\n",
        "    elif i <=digit_1_index[8]:\n",
        "        ans=digit_1_value[8]\n",
        "    elif i <=digit_1_index[9]:\n",
        "        ans=digit_1_value[9]\n",
        "    elif i <=digit_1_index[10]:\n",
        "        ans=digit_1_value[10]\n",
        "    elif i <=digit_1_index[11]:\n",
        "        ans=digit_1_value[11]\n",
        "\n",
        "    elif i <=digit_1_index[12]:\n",
        "        ans=digit_1_value[12]\n",
        "    elif i <=digit_1_index[13]:\n",
        "        ans=digit_1_value[13]\n",
        "\n",
        "    elif i <=digit_1_index[14]:\n",
        "        ans=digit_1_value[14]\n",
        "    elif i <=digit_1_index[15]:\n",
        "        ans=digit_1_value[15]\n",
        "\n",
        "    elif i <=digit_1_index[16]:\n",
        "        ans=digit_1_value[16]\n",
        "    elif i <=digit_1_index[17]:\n",
        "        ans=digit_1_value[17]\n",
        "\n",
        "    elif i <=digit_1_index[18]:\n",
        "        ans=digit_1_value[18]\n",
        "    elif i <=digit_1_index[19]:\n",
        "        ans=digit_1_value[19]\n",
        "\n",
        "    elif i <=digit_1_index[20]:\n",
        "        ans=digit_1_value[20]\n",
        "    return ans"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s4Ble0YSBdXa"
      },
      "outputs": [],
      "source": [
        "for i in range(len(predicted)):\n",
        "    if len(i) == 2:\n",
        "        submission['digit_3'][i] = int(labels[predicted[i]])\n",
        "        submission['digit_2'][i] = int(labels[predicted[i]][0])\n",
        "        submission['digit_1'][i] = search_digit_1(int(labels[predicted[i]][0]))\n",
        "    submission['digit_3'][i] = int(labels[predicted[i]])\n",
        "    submission['digit_2'][i] = int(labels[predicted[i]][:2])\n",
        "    submission['digit_1'][i] = search_digit_1(int(labels[predicted[i]][0])\n",
        "submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Y-iGncEBdXb"
      },
      "outputs": [],
      "source": [
        "submission[['digit_2','digit_3']] = submission[['digit_2','digit_3']].astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-BIiuV3i-If4"
      },
      "outputs": [],
      "source": [
        "submission.to_csv('C:/Users/SEO/OneDrive - 숭실대학교 - Soongsil University/바탕 화면/통계청 ai 경진대회/final/data/sub1_optuna.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y_hQ9oNPBdXb",
        "outputId": "c5b5833c-b4b5-45d0-f757-6ece41e77c65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.utils import plot_model\n",
        "plot_model(model)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "model.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}